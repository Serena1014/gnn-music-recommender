{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T14:28:30.007942Z",
     "start_time": "2025-08-16T20:19:19.724310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Enhanced LightGCN Experiments with Comprehensive Result Saving\n",
    "===============================================================\n",
    "\n",
    "A clean, well-organized implementation of LightGCN experiments with:\n",
    "- Phase 1: Graph Structure Ablation Analysis\n",
    "- Phase 2: Feature Importance Analysis\n",
    "- Comprehensive result saving and statistical analysis\n",
    "\n",
    "Author: Enhanced from original implementation\n",
    "Date: 2024\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import gc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from scipy import stats as scipy_stats\n",
    "from collections import Counter, defaultdict\n",
    "from typing import Dict, List, Tuple, Set\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 1. UTILITY FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def set_all_seeds(seed=42, use_deterministic=True):\n",
    "    \"\"\"Set random seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    if use_deterministic:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    \"\"\"Worker function for DataLoader\"\"\"\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2. RESULT SAVING SYSTEM\n",
    "# =============================================================================\n",
    "\n",
    "class ResultSaver:\n",
    "    \"\"\"Centralized system for saving all experiment results\"\"\"\n",
    "\n",
    "    def __init__(self, results_dir):\n",
    "        self.results_dir = results_dir\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "        # Create organized subdirectories\n",
    "        self.model_dir = os.path.join(results_dir, \"models\")\n",
    "        self.metrics_dir = os.path.join(results_dir, \"metrics\")\n",
    "        self.plots_dir = os.path.join(results_dir, \"plots\")\n",
    "        self.logs_dir = os.path.join(results_dir, \"logs\")\n",
    "\n",
    "        for directory in [self.model_dir, self.metrics_dir, self.plots_dir, self.logs_dir]:\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "        print(f\"üìÅ Result directories created in: {results_dir}\")\n",
    "\n",
    "    def save_training_run(self, config_name, seed, training_result, test_metrics, timestamp=None):\n",
    "        \"\"\"Save individual training run results\"\"\"\n",
    "        if timestamp is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "        run_data = {\n",
    "            'config_name': config_name,\n",
    "            'seed': seed,\n",
    "            'timestamp': timestamp,\n",
    "            'training_time': training_result['training_time'],\n",
    "            'final_loss': training_result['final_loss'],\n",
    "            'best_val_loss': training_result.get('best_val_loss', float('inf')),\n",
    "            'training_losses': training_result.get('training_losses', []),\n",
    "            'test_metrics': test_metrics\n",
    "        }\n",
    "\n",
    "        run_file = os.path.join(self.logs_dir, f\"{config_name}_seed{seed}_{timestamp}.json\")\n",
    "        with open(run_file, 'w') as f:\n",
    "            json.dump(run_data, f, indent=2)\n",
    "\n",
    "        return run_file\n",
    "\n",
    "    def save_model_checkpoint(self, model, config_name, seed, timestamp=None):\n",
    "        \"\"\"Save model checkpoint\"\"\"\n",
    "        if timestamp is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "        model_file = os.path.join(self.model_dir, f\"{config_name}_seed{seed}_{timestamp}.pth\")\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'config_name': config_name,\n",
    "            'seed': seed,\n",
    "            'timestamp': timestamp\n",
    "        }, model_file)\n",
    "\n",
    "        print(f\"   ü§ñ Saved model checkpoint: {os.path.basename(model_file)}\")\n",
    "        return model_file\n",
    "\n",
    "    def save_config_results(self, config_name, config_results, timestamp=None):\n",
    "        \"\"\"Save results for a specific configuration\"\"\"\n",
    "        if timestamp is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "        # Save as JSON\n",
    "        results_file = os.path.join(self.metrics_dir, f\"{config_name}_results_{timestamp}.json\")\n",
    "        serializable_results = {\n",
    "            'config_name': config_name,\n",
    "            'timestamp': timestamp,\n",
    "            'statistics': config_results.get('statistics', {}),\n",
    "            'runs': []\n",
    "        }\n",
    "\n",
    "        for run in config_results.get('runs', []):\n",
    "            serializable_run = {\n",
    "                'seed': run['seed'],\n",
    "                'metrics': run['metrics'],\n",
    "                'training_time': run['training_time'],\n",
    "                'final_loss': run['final_loss'],\n",
    "                'best_val_loss': run['best_val_loss']\n",
    "            }\n",
    "            serializable_results['runs'].append(serializable_run)\n",
    "\n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(serializable_results, f, indent=2)\n",
    "\n",
    "        # Save as pickle for easier loading\n",
    "        pickle_file = os.path.join(self.metrics_dir, f\"{config_name}_results_{timestamp}.pkl\")\n",
    "        with open(pickle_file, 'wb') as f:\n",
    "            pickle.dump(config_results, f)\n",
    "\n",
    "        print(f\"   üíæ Saved {config_name} results\")\n",
    "        return results_file, pickle_file\n",
    "\n",
    "    def save_complete_results(self, all_results, timestamp=None):\n",
    "        \"\"\"Save complete experiment results\"\"\"\n",
    "        if timestamp is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "        # Prepare serializable data\n",
    "        serializable_complete = {}\n",
    "        for config_name, config_data in all_results.items():\n",
    "            serializable_complete[config_name] = {\n",
    "                'config': config_data.get('config', {}),\n",
    "                'statistics': config_data.get('statistics', {}),\n",
    "                'run_count': len(config_data.get('runs', []))\n",
    "            }\n",
    "\n",
    "            serializable_complete[config_name]['runs_summary'] = []\n",
    "            for run in config_data.get('runs', []):\n",
    "                run_summary = {\n",
    "                    'seed': run['seed'],\n",
    "                    'metrics': run['metrics'],\n",
    "                    'training_time': run['training_time']\n",
    "                }\n",
    "                serializable_complete[config_name]['runs_summary'].append(run_summary)\n",
    "\n",
    "        # Save JSON\n",
    "        complete_file = os.path.join(self.results_dir, f\"complete_results_{timestamp}.json\")\n",
    "        with open(complete_file, 'w') as f:\n",
    "            json.dump(serializable_complete, f, indent=2)\n",
    "\n",
    "        # Save pickle\n",
    "        pickle_file = os.path.join(self.results_dir, f\"complete_results_{timestamp}.pkl\")\n",
    "        with open(pickle_file, 'wb') as f:\n",
    "            pickle.dump(all_results, f)\n",
    "\n",
    "        print(f\"üì¶ Complete results saved: {os.path.basename(complete_file)}\")\n",
    "        return complete_file, pickle_file\n",
    "\n",
    "    def save_analysis_results(self, analysis_results, timestamp=None):\n",
    "        \"\"\"Save statistical analysis results\"\"\"\n",
    "        if timestamp is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "        analysis_file = os.path.join(self.metrics_dir, f\"analysis_results_{timestamp}.json\")\n",
    "        with open(analysis_file, 'w') as f:\n",
    "            json.dump(analysis_results, f, indent=2)\n",
    "\n",
    "        print(f\"üìä Analysis results saved: {os.path.basename(analysis_file)}\")\n",
    "        return analysis_file\n",
    "\n",
    "    def create_experiment_summary(self, all_results, timestamp=None):\n",
    "        \"\"\"Create comprehensive experiment summary report\"\"\"\n",
    "        if timestamp is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "        summary_file = os.path.join(self.results_dir, f\"experiment_summary_{timestamp}.txt\")\n",
    "\n",
    "        with open(summary_file, 'w') as f:\n",
    "            f.write(\"=\"*80 + \"\\n\")\n",
    "            f.write(\"LIGHTGCN EXPERIMENT SUMMARY REPORT\\n\")\n",
    "            f.write(\"=\"*80 + \"\\n\")\n",
    "            f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(f\"Timestamp: {timestamp}\\n\\n\")\n",
    "\n",
    "            # Overall summary\n",
    "            f.write(\"EXPERIMENT OVERVIEW:\\n\")\n",
    "            f.write(\"-\"*50 + \"\\n\")\n",
    "            f.write(f\"Total configurations tested: {len(all_results)}\\n\")\n",
    "\n",
    "            if all_results:\n",
    "                best_config = max(all_results.items(),\n",
    "                                key=lambda x: x[1]['statistics'].get('ndcg@10', {}).get('mean', 0))\n",
    "                f.write(f\"Best configuration: {best_config[0]}\\n\")\n",
    "                f.write(f\"Best NDCG@10: {best_config[1]['statistics']['ndcg@10']['mean']:.4f}\\n\\n\")\n",
    "\n",
    "            # Configuration results table\n",
    "            f.write(\"CONFIGURATION RESULTS:\\n\")\n",
    "            f.write(\"-\"*50 + \"\\n\")\n",
    "            f.write(f\"{'Configuration':<25} {'NDCG@10':<15} {'AUC':<15} {'Time(s)':<10}\\n\")\n",
    "            f.write(\"-\"*65 + \"\\n\")\n",
    "\n",
    "            for config_name, result in all_results.items():\n",
    "                stats = result['statistics']\n",
    "                ndcg_mean = stats.get('ndcg@10', {}).get('mean', 0)\n",
    "                auc_mean = stats.get('auc', {}).get('mean', 0)\n",
    "                avg_time = np.mean([run['training_time'] for run in result['runs']]) if result['runs'] else 0\n",
    "                f.write(f\"{config_name:<25} {ndcg_mean:<15.4f} {auc_mean:<15.4f} {avg_time:<10.1f}\\n\")\n",
    "\n",
    "            f.write(f\"\\n\")\n",
    "            f.write(\"FILES GENERATED:\\n\")\n",
    "            f.write(\"-\"*50 + \"\\n\")\n",
    "            f.write(f\"- Complete results: complete_results_{timestamp}.json/.pkl\\n\")\n",
    "            f.write(f\"- Analysis results: analysis_results_{timestamp}.json\\n\")\n",
    "            f.write(f\"- Individual config results: {self.metrics_dir}/\\n\")\n",
    "            f.write(f\"- Training logs: {self.logs_dir}/\\n\")\n",
    "            f.write(f\"- Model checkpoints: {self.model_dir}/\\n\")\n",
    "\n",
    "        print(f\"üìã Experiment summary saved: {os.path.basename(summary_file)}\")\n",
    "        return summary_file\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 3. CONFIGURATION MANAGEMENT\n",
    "# =============================================================================\n",
    "\n",
    "class ExperimentConfig:\n",
    "    \"\"\"Centralized experiment configuration\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Experiment settings\n",
    "        self.random_seeds = [42, 123, 456, 789, 999]\n",
    "        self.target_playlists = 1500\n",
    "        self.data_dir = \"../data/processed/gnn_ready\"\n",
    "        self.results_dir = \"../results/lightgcn_experiments_enhanced\"\n",
    "\n",
    "        # Model architecture\n",
    "        self.embedding_dim = 128\n",
    "        self.n_layers = 2\n",
    "        self.dropout = 0.2\n",
    "\n",
    "        # Training parameters\n",
    "        self.batch_size = 256\n",
    "        self.learning_rate = 0.0005\n",
    "        self.epochs = 200\n",
    "        self.early_stopping_patience = 15\n",
    "        self.val_every = 10\n",
    "        self.reg_weight = 1e-3\n",
    "\n",
    "        # Data sampling\n",
    "        self.max_train_edges = 50000\n",
    "        self.num_neg_samples = 1\n",
    "\n",
    "        # Evaluation parameters\n",
    "        self.k_values = [5, 10, 20]\n",
    "        self.eval_sample_size = 500\n",
    "\n",
    "        # Setup\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        os.makedirs(self.results_dir, exist_ok=True)\n",
    "        self.result_saver = ResultSaver(self.results_dir)\n",
    "\n",
    "        self._print_config()\n",
    "\n",
    "    def _print_config(self):\n",
    "        \"\"\"Print configuration summary\"\"\"\n",
    "        print(f\"üéØ Experiment Configuration:\")\n",
    "        print(f\"   üì± Device: {self.device}\")\n",
    "        print(f\"   üé≤ Seeds: {len(self.random_seeds)} seeds\")\n",
    "        print(f\"   üìä Target playlists: {self.target_playlists:,}\")\n",
    "        print(f\"   üß† Embedding dim: {self.embedding_dim}\")\n",
    "        print(f\"   ‚ö° Learning rate: {self.learning_rate}\")\n",
    "        print(f\"   üõ°Ô∏è Regularization: {self.reg_weight}\")\n",
    "        print(f\"   üíæ Results dir: {self.results_dir}\")\n",
    "\n",
    "    def get_experiment_configs(self):\n",
    "        \"\"\"Get all experimental configurations\"\"\"\n",
    "        return {\n",
    "            # Phase 1: Graph Structure Ablation\n",
    "            \"baseline\": {\n",
    "                \"name\": \"Baseline\",\n",
    "                \"description\": \"Playlist-track edges only\",\n",
    "                \"edge_types\": [\"playlist_track\"],\n",
    "                \"use_features\": False,\n",
    "                \"feature_types\": [],\n",
    "                \"use_playlist_features\": False,\n",
    "                \"use_track_features\": False,\n",
    "                \"use_user_features\": False\n",
    "            },\n",
    "            \"with_artists\": {\n",
    "                \"name\": \"With Artists\",\n",
    "                \"description\": \"Add track-artist relationships\",\n",
    "                \"edge_types\": [\"playlist_track\", \"track_artist\"],\n",
    "                \"use_features\": False,\n",
    "                \"feature_types\": [],\n",
    "                \"use_playlist_features\": False,\n",
    "                \"use_track_features\": False,\n",
    "                \"use_user_features\": False\n",
    "            },\n",
    "            \"with_users\": {\n",
    "                \"name\": \"With Users\",\n",
    "                \"description\": \"Add user-playlist relationships\",\n",
    "                \"edge_types\": [\"playlist_track\", \"user_playlist\"],\n",
    "                \"use_features\": False,\n",
    "                \"feature_types\": [],\n",
    "                \"use_playlist_features\": False,\n",
    "                \"use_track_features\": False,\n",
    "                \"use_user_features\": False\n",
    "            },\n",
    "            \"full_graph\": {\n",
    "                \"name\": \"Full Graph\",\n",
    "                \"description\": \"All edge types\",\n",
    "                \"edge_types\": [\"playlist_track\", \"track_artist\", \"user_playlist\", \"track_album\"],\n",
    "                \"use_features\": False,\n",
    "                \"feature_types\": [],\n",
    "                \"use_playlist_features\": False,\n",
    "                \"use_track_features\": False,\n",
    "                \"use_user_features\": False\n",
    "            },\n",
    "\n",
    "            # Phase 2: Feature Importance Analysis (all on baseline graph)\n",
    "            \"playlist_features\": {\n",
    "                \"name\": \"Playlist Features\",\n",
    "                \"description\": \"Only playlist features (6D) on baseline graph\",\n",
    "                \"edge_types\": [\"playlist_track\"],\n",
    "                \"use_features\": True,\n",
    "                \"feature_types\": [\"playlist\"],\n",
    "                \"use_playlist_features\": True,\n",
    "                \"use_track_features\": False,\n",
    "                \"use_user_features\": False\n",
    "            },\n",
    "            \"track_features\": {\n",
    "                \"name\": \"Track Features\",\n",
    "                \"description\": \"Only track features (4D) on baseline graph\",\n",
    "                \"edge_types\": [\"playlist_track\"],\n",
    "                \"use_features\": True,\n",
    "                \"feature_types\": [\"track\"],\n",
    "                \"use_playlist_features\": False,\n",
    "                \"use_track_features\": True,\n",
    "                \"use_user_features\": False\n",
    "            },\n",
    "            \"user_features\": {\n",
    "                \"name\": \"User Features\",\n",
    "                \"description\": \"Only user features (4D) on baseline graph\",\n",
    "                \"edge_types\": [\"playlist_track\"],\n",
    "                \"use_features\": True,\n",
    "                \"feature_types\": [\"user\"],\n",
    "                \"use_playlist_features\": False,\n",
    "                \"use_track_features\": False,\n",
    "                \"use_user_features\": True\n",
    "            },\n",
    "            \"all_features\": {\n",
    "                \"name\": \"All Features\",\n",
    "                \"description\": \"All feature types combined on baseline graph\",\n",
    "                \"edge_types\": [\"playlist_track\"],\n",
    "                \"use_features\": True,\n",
    "                \"feature_types\": [\"playlist\", \"track\", \"user\"],\n",
    "                \"use_playlist_features\": True,\n",
    "                \"use_track_features\": True,\n",
    "                \"use_user_features\": True\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 4. DATA PROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "class SpotifyDataProcessor:\n",
    "    \"\"\"Process real Spotify data for experiments\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "\n",
    "    def load_and_process_data(self, data_path: str, seed: int = 42) -> Dict:\n",
    "        \"\"\"Load and process Spotify data\"\"\"\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        print(f\"üéµ Loading Spotify data from: {data_path}\")\n",
    "\n",
    "        with open(data_path, 'r') as f:\n",
    "            spotify_data = json.load(f)\n",
    "\n",
    "        playlists = spotify_data.get('playlists', [])\n",
    "        print(f\"‚úÖ Loaded {len(playlists):,} playlists\")\n",
    "\n",
    "        # Extract entities and create mappings\n",
    "        entity_mappings = self._create_entity_mappings(playlists)\n",
    "        entity_counts = {k: len(v) for k, v in entity_mappings.items()}\n",
    "\n",
    "        print(f\"üìä Dataset statistics:\")\n",
    "        for entity_type, count in entity_counts.items():\n",
    "            print(f\"   ‚Ä¢ {entity_type.title()}: {count:,}\")\n",
    "\n",
    "        # Calculate node offsets\n",
    "        node_offsets = self._calculate_node_offsets(entity_counts)\n",
    "        total_nodes = sum(entity_counts.values())\n",
    "\n",
    "        # Extract edges\n",
    "        edges = self._extract_edges(playlists, entity_mappings, node_offsets)\n",
    "\n",
    "        # Create data splits\n",
    "        splits = self._create_data_splits(edges['playlist_track'], seed=seed)\n",
    "\n",
    "        # Generate features\n",
    "        features = self._generate_features(playlists, entity_mappings, entity_counts, seed=seed)\n",
    "\n",
    "        return {\n",
    "            'entity_counts': entity_counts,\n",
    "            'node_offsets': node_offsets,\n",
    "            'total_nodes': total_nodes,\n",
    "            'edges': edges,\n",
    "            'splits': splits,\n",
    "            'features': features\n",
    "        }\n",
    "\n",
    "    def _create_entity_mappings(self, playlists: List[Dict]) -> Dict[str, Dict]:\n",
    "        \"\"\"Extract and map all entities\"\"\"\n",
    "        playlist_ids = set()\n",
    "        track_uris = set()\n",
    "        artist_uris = set()\n",
    "        album_uris = set()\n",
    "        user_ids = set()\n",
    "\n",
    "        for playlist in playlists:\n",
    "            pid = playlist.get('pid')\n",
    "            if pid is not None:\n",
    "                playlist_ids.add(pid)\n",
    "\n",
    "            # Extract user ID from playlist name\n",
    "            name = playlist.get('name', '').strip()\n",
    "            user_id = name.split()[0] if name else f\"user_{pid}\"\n",
    "            user_ids.add(user_id)\n",
    "\n",
    "            # Extract track info\n",
    "            for track in playlist.get('tracks', []):\n",
    "                track_uri = track.get('track_uri', '')\n",
    "                artist_uri = track.get('artist_uri', '')\n",
    "                album_uri = track.get('album_uri', '')\n",
    "\n",
    "                if track_uri:\n",
    "                    track_uris.add(track_uri)\n",
    "                if artist_uri:\n",
    "                    artist_uris.add(artist_uri)\n",
    "                if album_uri:\n",
    "                    album_uris.add(album_uri)\n",
    "\n",
    "        # Create mappings\n",
    "        entity_mappings = {\n",
    "            'playlists': {pid: i for i, pid in enumerate(sorted(playlist_ids))},\n",
    "            'tracks': {uri: i for i, uri in enumerate(sorted(track_uris))},\n",
    "            'artists': {uri: i for i, uri in enumerate(sorted(artist_uris))},\n",
    "            'albums': {uri: i for i, uri in enumerate(sorted(album_uris))},\n",
    "            'users': {uid: i for i, uid in enumerate(sorted(user_ids))}\n",
    "        }\n",
    "\n",
    "        return entity_mappings\n",
    "\n",
    "    def _calculate_node_offsets(self, entity_counts: Dict[str, int]) -> Dict[str, int]:\n",
    "        \"\"\"Calculate node offsets for heterogeneous graph\"\"\"\n",
    "        node_offsets = {}\n",
    "        current_offset = 0\n",
    "\n",
    "        for entity_type in ['playlists', 'tracks', 'artists', 'albums', 'users']:\n",
    "            node_offsets[entity_type] = current_offset\n",
    "            current_offset += entity_counts[entity_type]\n",
    "\n",
    "        return node_offsets\n",
    "\n",
    "    def _extract_edges(self, playlists: List[Dict], entity_mappings: Dict, node_offsets: Dict) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Extract all edge types from data\"\"\"\n",
    "        playlist_track_edges = []\n",
    "        track_artist_edges = []\n",
    "        user_playlist_edges = []\n",
    "        track_album_edges = []\n",
    "\n",
    "        for playlist in playlists:\n",
    "            pid = playlist.get('pid')\n",
    "            if pid not in entity_mappings['playlists']:\n",
    "                continue\n",
    "\n",
    "            playlist_node = node_offsets['playlists'] + entity_mappings['playlists'][pid]\n",
    "\n",
    "            # User-playlist edges\n",
    "            name = playlist.get('name', '').strip()\n",
    "            user_id = name.split()[0] if name else f\"user_{pid}\"\n",
    "            if user_id in entity_mappings['users']:\n",
    "                user_node = node_offsets['users'] + entity_mappings['users'][user_id]\n",
    "                user_playlist_edges.append([user_node, playlist_node])\n",
    "\n",
    "            # Track-related edges\n",
    "            for track in playlist.get('tracks', []):\n",
    "                track_uri = track.get('track_uri', '')\n",
    "                artist_uri = track.get('artist_uri', '')\n",
    "                album_uri = track.get('album_uri', '')\n",
    "\n",
    "                if track_uri in entity_mappings['tracks']:\n",
    "                    track_node = node_offsets['tracks'] + entity_mappings['tracks'][track_uri]\n",
    "\n",
    "                    # Playlist-track edge\n",
    "                    playlist_track_edges.append([playlist_node, track_node])\n",
    "\n",
    "                    # Track-artist edge\n",
    "                    if artist_uri in entity_mappings['artists']:\n",
    "                        artist_node = node_offsets['artists'] + entity_mappings['artists'][artist_uri]\n",
    "                        track_artist_edges.append([track_node, artist_node])\n",
    "\n",
    "                    # Track-album edge\n",
    "                    if album_uri in entity_mappings['albums']:\n",
    "                        album_node = node_offsets['albums'] + entity_mappings['albums'][album_uri]\n",
    "                        track_album_edges.append([track_node, album_node])\n",
    "\n",
    "        # Convert to numpy arrays and remove duplicates\n",
    "        edges = {}\n",
    "        edge_lists = {\n",
    "            'playlist_track': playlist_track_edges,\n",
    "            'track_artist': track_artist_edges,\n",
    "            'user_playlist': user_playlist_edges,\n",
    "            'track_album': track_album_edges\n",
    "        }\n",
    "\n",
    "        for edge_type, edge_list in edge_lists.items():\n",
    "            if edge_list:\n",
    "                edges[edge_type] = np.unique(np.array(edge_list), axis=0)\n",
    "\n",
    "        print(f\"üìà Extracted edges:\")\n",
    "        for edge_type, edge_array in edges.items():\n",
    "            print(f\"   ‚Ä¢ {edge_type}: {len(edge_array):,} edges\")\n",
    "\n",
    "        return edges\n",
    "\n",
    "    def _create_data_splits(self, playlist_track_edges: np.ndarray, seed: int = 42) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Create train/val/test splits\"\"\"\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        shuffled_edges = playlist_track_edges.copy()\n",
    "        np.random.shuffle(shuffled_edges)\n",
    "\n",
    "        total_edges = len(shuffled_edges)\n",
    "        train_size = int(0.7 * total_edges)\n",
    "        val_size = int(0.15 * total_edges)\n",
    "\n",
    "        train_edges = shuffled_edges[:train_size]\n",
    "        val_edges = shuffled_edges[train_size:train_size + val_size]\n",
    "        test_edges = shuffled_edges[train_size + val_size:]\n",
    "\n",
    "        print(f\"üìã Data splits:\")\n",
    "        print(f\"   ‚Ä¢ Train: {len(train_edges):,} edges ({len(train_edges)/total_edges:.1%})\")\n",
    "        print(f\"   ‚Ä¢ Validation: {len(val_edges):,} edges ({len(val_edges)/total_edges:.1%})\")\n",
    "        print(f\"   ‚Ä¢ Test: {len(test_edges):,} edges ({len(test_edges)/total_edges:.1%})\")\n",
    "\n",
    "        return {\n",
    "            'train_edges': train_edges,\n",
    "            'val_edges': val_edges,\n",
    "            'test_edges': test_edges\n",
    "        }\n",
    "\n",
    "    def _generate_features(self, playlists: List[Dict], entity_mappings: Dict,\n",
    "                          entity_counts: Dict, seed: int = 42) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Generate features based on real data patterns\"\"\"\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # Extract real statistics\n",
    "        playlist_lengths = []\n",
    "        track_frequencies = Counter()\n",
    "        user_playlist_counts = Counter()\n",
    "\n",
    "        for playlist in playlists:\n",
    "            playlist_lengths.append(len(playlist.get('tracks', [])))\n",
    "\n",
    "            name = playlist.get('name', '').strip()\n",
    "            user_id = name.split()[0] if name else f\"user_{playlist.get('pid')}\"\n",
    "            user_playlist_counts[user_id] += 1\n",
    "\n",
    "            for track in playlist.get('tracks', []):\n",
    "                track_uri = track.get('track_uri', '')\n",
    "                if track_uri:\n",
    "                    track_frequencies[track_uri] += 1\n",
    "\n",
    "        features = {}\n",
    "\n",
    "        # Playlist features (6 dimensions)\n",
    "        playlist_features = []\n",
    "        for pid in sorted(entity_mappings['playlists'].keys()):\n",
    "            playlist_data = next((p for p in playlists if p.get('pid') == pid), None)\n",
    "\n",
    "            if playlist_data:\n",
    "                length = len(playlist_data.get('tracks', []))\n",
    "                collaborative = 1.0 if length > np.median(playlist_lengths) else 0.0\n",
    "                followers = max(0, int(np.random.exponential(scale=length/10)))\n",
    "                length_norm = length / max(playlist_lengths) if playlist_lengths else 0\n",
    "                followers_norm = min(1.0, followers / 1000)\n",
    "\n",
    "                playlist_features.append([\n",
    "                    length_norm, collaborative, followers_norm,\n",
    "                    np.random.random(), np.random.random(), np.random.random()\n",
    "                ])\n",
    "            else:\n",
    "                playlist_features.append([0, 0, 0, 0, 0, 0])\n",
    "\n",
    "        features['playlist'] = np.array(playlist_features, dtype=np.float32)\n",
    "\n",
    "        # Track features (4 dimensions)\n",
    "        track_features = []\n",
    "        for track_uri in sorted(entity_mappings['tracks'].keys()):\n",
    "            frequency = track_frequencies.get(track_uri, 1)\n",
    "            popularity = min(1.0, np.log1p(frequency) / 10)\n",
    "            track_features.append([\n",
    "                popularity,\n",
    "                np.random.random(),\n",
    "                np.random.random(),\n",
    "                np.random.random()\n",
    "            ])\n",
    "\n",
    "        features['track'] = np.array(track_features, dtype=np.float32)\n",
    "\n",
    "        # User features (4 dimensions)\n",
    "        user_features = []\n",
    "        for user_id in sorted(entity_mappings['users'].keys()):\n",
    "            playlist_count = user_playlist_counts.get(user_id, 1)\n",
    "            activity = min(1.0, np.log1p(playlist_count) / 5)\n",
    "            user_features.append([\n",
    "                activity,\n",
    "                np.random.random(),\n",
    "                np.random.random(),\n",
    "                np.random.random()\n",
    "            ])\n",
    "\n",
    "        features['user'] = np.array(user_features, dtype=np.float32)\n",
    "\n",
    "        # Artist and Album features (random placeholders)\n",
    "        features['artist'] = np.random.randn(entity_counts['artists'], 4).astype(np.float32)\n",
    "        features['album'] = np.random.randn(entity_counts['albums'], 4).astype(np.float32)\n",
    "\n",
    "        print(f\"üé® Generated features:\")\n",
    "        for entity_type, feature_matrix in features.items():\n",
    "            print(f\"   ‚Ä¢ {entity_type}: {feature_matrix.shape}\")\n",
    "\n",
    "        return features\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 5. MODEL ARCHITECTURE\n",
    "# =============================================================================\n",
    "\n",
    "class LightGCN(nn.Module):\n",
    "    \"\"\"LightGCN model with feature integration\"\"\"\n",
    "\n",
    "    def __init__(self, total_nodes, playlist_count, track_count, user_count, embedding_dim, n_layers,\n",
    "                 playlist_features=None, track_features=None, user_features=None, dropout=0.0, node_offsets=None):\n",
    "        super(LightGCN, self).__init__()\n",
    "\n",
    "        self.total_nodes = total_nodes\n",
    "        self.playlist_count = playlist_count\n",
    "        self.track_count = track_count\n",
    "        self.user_count = user_count\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.node_offsets = node_offsets or {}\n",
    "\n",
    "        # Core embeddings\n",
    "        self.node_embedding = nn.Embedding(total_nodes, embedding_dim)\n",
    "\n",
    "        # Feature integration\n",
    "        self.use_playlist_features = playlist_features is not None\n",
    "        self.use_track_features = track_features is not None\n",
    "        self.use_user_features = user_features is not None\n",
    "\n",
    "        if self.use_playlist_features:\n",
    "            self.playlist_features = playlist_features\n",
    "            self.playlist_feature_transform = self._create_feature_transform(playlist_features.size(1))\n",
    "\n",
    "        if self.use_track_features:\n",
    "            self.track_features = track_features\n",
    "            self.track_feature_transform = self._create_feature_transform(track_features.size(1))\n",
    "\n",
    "        if self.use_user_features:\n",
    "            self.user_features = user_features\n",
    "            self.user_feature_transform = self._create_feature_transform(user_features.size(1))\n",
    "\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        self._init_embeddings()\n",
    "\n",
    "        print(f\"   üß† LightGCN initialized:\")\n",
    "        print(f\"      üìè Nodes: {total_nodes:,}, Embedding: {embedding_dim}, Layers: {n_layers}\")\n",
    "        print(f\"      üé® Features: P:{self.use_playlist_features}, T:{self.use_track_features}, U:{self.use_user_features}\")\n",
    "\n",
    "    def _create_feature_transform(self, feature_dim):\n",
    "        \"\"\"Create feature transformation network\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.BatchNorm1d(feature_dim),\n",
    "            nn.Linear(feature_dim, self.embedding_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.Linear(self.embedding_dim // 2, self.embedding_dim),\n",
    "            nn.BatchNorm1d(self.embedding_dim)\n",
    "        )\n",
    "\n",
    "    def _init_embeddings(self):\n",
    "        \"\"\"Initialize embeddings with Xavier uniform\"\"\"\n",
    "        nn.init.xavier_uniform_(self.node_embedding.weight)\n",
    "        self.node_embedding.weight.data *= 0.1\n",
    "\n",
    "    def forward(self, adj_matrix):\n",
    "        \"\"\"Forward pass with feature integration and message passing\"\"\"\n",
    "        all_embeddings = self.node_embedding.weight.clone()\n",
    "\n",
    "        # Integrate features\n",
    "        if self.use_playlist_features:\n",
    "            playlist_feat = self.playlist_feature_transform(self.playlist_features)\n",
    "            playlist_start = self.node_offsets.get('playlists', 0)\n",
    "            playlist_end = playlist_start + self.playlist_count\n",
    "            all_embeddings[playlist_start:playlist_end] = (\n",
    "                0.9 * all_embeddings[playlist_start:playlist_end] + 0.1 * playlist_feat\n",
    "            )\n",
    "\n",
    "        if self.use_track_features:\n",
    "            track_feat = self.track_feature_transform(self.track_features)\n",
    "            track_start = self.node_offsets.get('tracks', self.playlist_count)\n",
    "            track_end = track_start + self.track_count\n",
    "            all_embeddings[track_start:track_end] = (\n",
    "                0.9 * all_embeddings[track_start:track_end] + 0.1 * track_feat\n",
    "            )\n",
    "\n",
    "        if self.use_user_features:\n",
    "            user_feat = self.user_feature_transform(self.user_features)\n",
    "            user_start = self.node_offsets.get('users', 0)\n",
    "            user_end = user_start + self.user_count\n",
    "            all_embeddings[user_start:user_end] = (\n",
    "                0.9 * all_embeddings[user_start:user_end] + 0.1 * user_feat\n",
    "            )\n",
    "\n",
    "        # Message passing layers\n",
    "        embeddings_layers = [all_embeddings]\n",
    "        current_embeddings = all_embeddings\n",
    "\n",
    "        for layer in range(self.n_layers):\n",
    "            if adj_matrix.device != current_embeddings.device:\n",
    "                adj_matrix = adj_matrix.to(current_embeddings.device)\n",
    "\n",
    "            new_embeddings = torch.sparse.mm(adj_matrix, current_embeddings)\n",
    "\n",
    "            if self.dropout > 0:\n",
    "                new_embeddings = self.dropout_layer(new_embeddings)\n",
    "\n",
    "            embeddings_layers.append(new_embeddings)\n",
    "            current_embeddings = new_embeddings\n",
    "\n",
    "        # Average all layers\n",
    "        final_embeddings = torch.mean(torch.stack(embeddings_layers), dim=0)\n",
    "        return final_embeddings\n",
    "\n",
    "    def predict(self, playlist_indices, track_indices, all_embeddings=None):\n",
    "        \"\"\"Predict scores for playlist-track pairs\"\"\"\n",
    "        if all_embeddings is None:\n",
    "            raise ValueError(\"all_embeddings must be provided\")\n",
    "\n",
    "        playlist_embs = all_embeddings[playlist_indices]\n",
    "        track_embs = all_embeddings[track_indices]\n",
    "\n",
    "        # Normalized cosine similarity\n",
    "        playlist_embs = F.normalize(playlist_embs, p=2, dim=1)\n",
    "        track_embs = F.normalize(track_embs, p=2, dim=1)\n",
    "\n",
    "        scores = (playlist_embs * track_embs).sum(dim=1)\n",
    "        return scores\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 6. DATA LOADING\n",
    "# =============================================================================\n",
    "\n",
    "class MusicRecommendationDataset(Dataset):\n",
    "    \"\"\"Dataset for music recommendation with improved negative sampling\"\"\"\n",
    "\n",
    "    def __init__(self, positive_edges, playlist_count, track_count, track_offset,\n",
    "                 max_edges=None, num_neg_samples=1, seed=None):\n",
    "        self.seed = seed\n",
    "        if seed is not None:\n",
    "            set_all_seeds(seed)\n",
    "\n",
    "        # Convert edges to playlist-track pairs\n",
    "        self.positive_pairs = []\n",
    "        for edge in positive_edges:\n",
    "            playlist_node, track_node = edge\n",
    "            playlist_id = playlist_node\n",
    "            track_id = track_node - track_offset\n",
    "\n",
    "            if 0 <= playlist_id < playlist_count and 0 <= track_id < track_count:\n",
    "                self.positive_pairs.append((playlist_id, track_id))\n",
    "\n",
    "        # Sample training data if needed\n",
    "        if max_edges and len(self.positive_pairs) > max_edges:\n",
    "            np.random.seed(seed if seed is not None else 42)\n",
    "            indices = np.random.choice(len(self.positive_pairs), max_edges, replace=False)\n",
    "            self.positive_pairs = [self.positive_pairs[i] for i in indices]\n",
    "\n",
    "        self.playlist_count = playlist_count\n",
    "        self.track_count = track_count\n",
    "        self.track_offset = track_offset\n",
    "        self.num_neg_samples = num_neg_samples\n",
    "\n",
    "        # Build interaction sets for negative sampling\n",
    "        self.user_items = defaultdict(set)\n",
    "        for playlist_id, track_id in self.positive_pairs:\n",
    "            self.user_items[playlist_id].add(track_id)\n",
    "\n",
    "        # Create popularity-based negative sampling distribution\n",
    "        track_popularity = defaultdict(int)\n",
    "        for _, track_id in self.positive_pairs:\n",
    "            track_popularity[track_id] += 1\n",
    "\n",
    "        all_tracks = list(range(track_count))\n",
    "        track_counts = [track_popularity.get(track_id, 0) for track_id in all_tracks]\n",
    "        max_count = max(track_counts) if track_counts else 1\n",
    "        inv_popularity = [max_count - count + 1 for count in track_counts]\n",
    "\n",
    "        self.neg_sampling_probs = np.array(inv_popularity, dtype=float)\n",
    "        self.neg_sampling_probs = self.neg_sampling_probs / self.neg_sampling_probs.sum()\n",
    "        self.rng = np.random.RandomState(seed if seed is not None else 42)\n",
    "\n",
    "        print(f\"      üìä Dataset: {len(self.positive_pairs):,} positive pairs\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.positive_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        playlist_id, track_id = self.positive_pairs[idx]\n",
    "\n",
    "        playlist_node = playlist_id\n",
    "        track_node = track_id + self.track_offset\n",
    "\n",
    "        # Negative sampling\n",
    "        neg_tracks = []\n",
    "        max_attempts = 100\n",
    "        attempts = 0\n",
    "\n",
    "        while len(neg_tracks) < self.num_neg_samples and attempts < max_attempts:\n",
    "            neg_track_id = self.rng.choice(self.track_count, p=self.neg_sampling_probs)\n",
    "            if neg_track_id not in self.user_items[playlist_id]:\n",
    "                neg_track_node = neg_track_id + self.track_offset\n",
    "                neg_tracks.append(neg_track_node)\n",
    "            attempts += 1\n",
    "\n",
    "        # Fill remaining with random\n",
    "        while len(neg_tracks) < self.num_neg_samples:\n",
    "            neg_track_id = self.rng.randint(0, self.track_count)\n",
    "            neg_track_node = neg_track_id + self.track_offset\n",
    "            neg_tracks.append(neg_track_node)\n",
    "\n",
    "        return {\n",
    "            'playlist': torch.LongTensor([playlist_node]),\n",
    "            'pos_track': torch.LongTensor([track_node]),\n",
    "            'neg_tracks': torch.LongTensor(neg_tracks)\n",
    "        }\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 7. GRAPH BUILDING\n",
    "# =============================================================================\n",
    "\n",
    "class GraphBuilder:\n",
    "    \"\"\"Build heterogeneous graphs with improved normalization\"\"\"\n",
    "\n",
    "    def __init__(self, data, config):\n",
    "        self.data = data\n",
    "        self.config = config\n",
    "        self.entity_counts = data['entity_counts']\n",
    "        self.node_offsets = data['node_offsets']\n",
    "        self.total_nodes = data['total_nodes']\n",
    "\n",
    "    def build_adjacency_matrix(self, edge_types, device, seed=None):\n",
    "        \"\"\"Build normalized adjacency matrix\"\"\"\n",
    "        if seed is not None:\n",
    "            set_all_seeds(seed)\n",
    "\n",
    "        print(f\"   üîó Building adjacency matrix: {edge_types}\")\n",
    "\n",
    "        row_indices = []\n",
    "        col_indices = []\n",
    "        edge_count = 0\n",
    "\n",
    "        # Add edges for each type\n",
    "        for edge_type in edge_types:\n",
    "            if edge_type in self.data['edges']:\n",
    "                edges = self.data['edges'][edge_type]\n",
    "                print(f\"      üìä Adding {edge_type}: {len(edges):,} edges\")\n",
    "\n",
    "                # Add bidirectional edges\n",
    "                for edge in edges:\n",
    "                    src, dst = edge\n",
    "                    row_indices.extend([src, dst])\n",
    "                    col_indices.extend([dst, src])\n",
    "                    edge_count += 2\n",
    "\n",
    "        if not row_indices:\n",
    "            print(\"      ‚ùå No valid edges found!\")\n",
    "            return None\n",
    "\n",
    "        print(f\"      ‚úÖ Total edges: {edge_count:,}\")\n",
    "\n",
    "        # Create and normalize adjacency matrix\n",
    "        values = np.ones(len(row_indices), dtype=np.float32)\n",
    "        adj_coo = coo_matrix(\n",
    "            (values, (row_indices, col_indices)),\n",
    "            shape=(self.total_nodes, self.total_nodes),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        adj_normalized = self._symmetric_normalize(adj_coo.tocsr())\n",
    "        adj_tensor = self._to_torch_sparse(adj_normalized, device)\n",
    "\n",
    "        print(f\"      ‚úÖ Adjacency matrix: {adj_tensor.shape}, nnz: {adj_tensor._nnz()}\")\n",
    "        return adj_tensor\n",
    "\n",
    "    def _symmetric_normalize(self, adj_matrix):\n",
    "        \"\"\"Symmetric normalization with numerical stability\"\"\"\n",
    "        # Add self-loops\n",
    "        adj_matrix = adj_matrix + csr_matrix(np.eye(adj_matrix.shape[0]))\n",
    "\n",
    "        # Compute degrees\n",
    "        degrees = np.array(adj_matrix.sum(axis=1)).flatten()\n",
    "        degrees_inv_sqrt = np.power(degrees + 1e-10, -0.5)\n",
    "        degrees_inv_sqrt[np.isinf(degrees_inv_sqrt)] = 0.\n",
    "        degrees_inv_sqrt[np.isnan(degrees_inv_sqrt)] = 0.\n",
    "\n",
    "        # Create degree matrix\n",
    "        diag_indices = np.arange(len(degrees_inv_sqrt))\n",
    "        degree_matrix = csr_matrix(\n",
    "            (degrees_inv_sqrt, (diag_indices, diag_indices)),\n",
    "            shape=(len(degrees_inv_sqrt), len(degrees_inv_sqrt))\n",
    "        )\n",
    "\n",
    "        # Apply normalization\n",
    "        adj_normalized = degree_matrix @ adj_matrix @ degree_matrix\n",
    "        return adj_normalized\n",
    "\n",
    "    def _to_torch_sparse(self, scipy_matrix, device):\n",
    "        \"\"\"Convert scipy sparse matrix to PyTorch sparse tensor\"\"\"\n",
    "        coo = scipy_matrix.tocoo()\n",
    "        indices = torch.LongTensor(np.vstack([coo.row, coo.col]))\n",
    "        values = torch.FloatTensor(coo.data)\n",
    "\n",
    "        sparse_tensor = torch.sparse_coo_tensor(\n",
    "            indices, values, coo.shape, device=device\n",
    "        ).coalesce()\n",
    "\n",
    "        return sparse_tensor\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 8. FEATURE PROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "class FeatureProcessor:\n",
    "    \"\"\"Process and build feature matrices\"\"\"\n",
    "\n",
    "    def __init__(self, data, config):\n",
    "        self.data = data\n",
    "        self.config = config\n",
    "        self.features = data['features']\n",
    "        self.entity_counts = data['entity_counts']\n",
    "\n",
    "    def build_feature_matrices(self, feature_types, device, seed=None):\n",
    "        \"\"\"Build feature matrices for specified types\"\"\"\n",
    "        if seed is not None:\n",
    "            set_all_seeds(seed)\n",
    "\n",
    "        if not feature_types:\n",
    "            return None, None, None\n",
    "\n",
    "        print(f\"   üîß Building features: {feature_types}\")\n",
    "\n",
    "        playlist_features = None\n",
    "        track_features = None\n",
    "        user_features = None\n",
    "\n",
    "        if \"playlist\" in feature_types:\n",
    "            playlist_features = self._build_feature_matrix('playlist', device, expected_dim=6)\n",
    "\n",
    "        if \"track\" in feature_types:\n",
    "            track_features = self._build_feature_matrix('track', device, expected_dim=4)\n",
    "\n",
    "        if \"user\" in feature_types:\n",
    "            user_features = self._build_feature_matrix('user', device, expected_dim=4)\n",
    "\n",
    "        return playlist_features, track_features, user_features\n",
    "\n",
    "    def _build_feature_matrix(self, feature_type, device, expected_dim):\n",
    "        \"\"\"Build feature matrix for a specific type\"\"\"\n",
    "        print(f\"      üé® Building {feature_type} features...\")\n",
    "\n",
    "        if feature_type not in self.features:\n",
    "            print(f\"      ‚ùå No {feature_type} features found\")\n",
    "            return None\n",
    "\n",
    "        feature_array = self.features[feature_type]\n",
    "\n",
    "        if len(feature_array.shape) != 2 or feature_array.shape[1] != expected_dim:\n",
    "            print(f\"      ‚ùå Unexpected {feature_type} feature shape: {feature_array.shape}\")\n",
    "            return None\n",
    "\n",
    "        feature_tensor = torch.FloatTensor(feature_array).to(device)\n",
    "        print(f\"      ‚úÖ {feature_type.title()} features: {feature_tensor.shape}\")\n",
    "        return feature_tensor\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 9. TRAINING AND EVALUATION\n",
    "# =============================================================================\n",
    "\n",
    "class ModelTrainer:\n",
    "    \"\"\"Handle model training and evaluation with result saving\"\"\"\n",
    "\n",
    "    def __init__(self, config, data):\n",
    "        self.config = config\n",
    "        self.data = data\n",
    "        self.device = config.device\n",
    "\n",
    "        # Extract data info\n",
    "        self.entity_counts = data['entity_counts']\n",
    "        self.node_offsets = data['node_offsets']\n",
    "        self.total_nodes = data['total_nodes']\n",
    "        self.playlist_count = self.entity_counts['playlists']\n",
    "        self.track_count = self.entity_counts['tracks']\n",
    "        self.user_count = self.entity_counts['users']\n",
    "        self.track_offset = self.node_offsets['tracks']\n",
    "\n",
    "        print(f\"üéØ Model Trainer initialized:\")\n",
    "        print(f\"   üë• Playlists: {self.playlist_count:,}\")\n",
    "        print(f\"   üéµ Tracks: {self.track_count:,}\")\n",
    "        print(f\"   üë§ Users: {self.user_count:,}\")\n",
    "\n",
    "    def train_model(self, config_spec, seed=None, save_model=True):\n",
    "        \"\"\"Train model with given configuration\"\"\"\n",
    "        print(f\"\\nüöÄ Training: {config_spec['name']} (seed={seed})\")\n",
    "        print(f\"   üìù {config_spec['description']}\")\n",
    "\n",
    "        if seed is not None:\n",
    "            set_all_seeds(seed)\n",
    "\n",
    "        start_time = time.time()\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "        try:\n",
    "            # Build graph\n",
    "            graph_builder = GraphBuilder(self.data, self.config)\n",
    "            adj_matrix = graph_builder.build_adjacency_matrix(\n",
    "                config_spec['edge_types'], self.device, seed=seed\n",
    "            )\n",
    "\n",
    "            if adj_matrix is None:\n",
    "                print(\"   ‚ùå Failed to build adjacency matrix\")\n",
    "                return None\n",
    "\n",
    "            # Build features\n",
    "            playlist_features = None\n",
    "            track_features = None\n",
    "            user_features = None\n",
    "\n",
    "            if config_spec.get('use_features', False) and config_spec.get('feature_types'):\n",
    "                feature_processor = FeatureProcessor(self.data, self.config)\n",
    "                playlist_features, track_features, user_features = feature_processor.build_feature_matrices(\n",
    "                    config_spec['feature_types'], self.device, seed=seed\n",
    "                )\n",
    "\n",
    "            # Initialize model\n",
    "            model = LightGCN(\n",
    "                total_nodes=self.total_nodes,\n",
    "                playlist_count=self.playlist_count,\n",
    "                track_count=self.track_count,\n",
    "                user_count=self.user_count,\n",
    "                embedding_dim=self.config.embedding_dim,\n",
    "                n_layers=self.config.n_layers,\n",
    "                playlist_features=playlist_features,\n",
    "                track_features=track_features,\n",
    "                user_features=user_features,\n",
    "                dropout=self.config.dropout,\n",
    "                node_offsets=self.node_offsets\n",
    "            ).to(self.device)\n",
    "\n",
    "            # Train\n",
    "            train_result = self._train_loop(model, adj_matrix, seed)\n",
    "            if train_result is None:\n",
    "                return None\n",
    "\n",
    "            training_time = time.time() - start_time\n",
    "\n",
    "            # Save model if requested\n",
    "            model_file = None\n",
    "            if save_model:\n",
    "                model_file = self.config.result_saver.save_model_checkpoint(\n",
    "                    model, config_spec['name'], seed, timestamp\n",
    "                )\n",
    "\n",
    "            return {\n",
    "                'model': model,\n",
    "                'adj_matrix': adj_matrix,\n",
    "                'training_losses': train_result['losses'],\n",
    "                'training_time': training_time,\n",
    "                'final_loss': train_result['final_loss'],\n",
    "                'best_val_loss': train_result.get('best_val_loss', float('inf')),\n",
    "                'seed': seed,\n",
    "                'config': config_spec,\n",
    "                'model_file': model_file,\n",
    "                'timestamp': timestamp\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Training failed: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "\n",
    "    def _train_loop(self, model, adj_matrix, seed):\n",
    "        \"\"\"Main training loop with validation and early stopping\"\"\"\n",
    "        # Prepare datasets\n",
    "        train_dataset = MusicRecommendationDataset(\n",
    "            self.data['splits']['train_edges'],\n",
    "            self.playlist_count, self.track_count, self.track_offset,\n",
    "            max_edges=self.config.max_train_edges,\n",
    "            num_neg_samples=self.config.num_neg_samples, seed=seed\n",
    "        )\n",
    "\n",
    "        val_dataset = MusicRecommendationDataset(\n",
    "            self.data['splits']['val_edges'],\n",
    "            self.playlist_count, self.track_count, self.track_offset,\n",
    "            max_edges=5000, num_neg_samples=self.config.num_neg_samples,\n",
    "            seed=seed + 1 if seed else 43\n",
    "        )\n",
    "\n",
    "        # Create data loaders\n",
    "        generator = torch.Generator()\n",
    "        if seed is not None:\n",
    "            generator.manual_seed(seed)\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, batch_size=self.config.batch_size, shuffle=True,\n",
    "            num_workers=0, worker_init_fn=seed_worker, generator=generator, drop_last=True\n",
    "        )\n",
    "\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset, batch_size=self.config.batch_size, shuffle=False,\n",
    "            num_workers=0, drop_last=False\n",
    "        )\n",
    "\n",
    "        # Optimizer and scheduler\n",
    "        optimizer = optim.AdamW(\n",
    "            model.parameters(), lr=self.config.learning_rate,\n",
    "            weight_decay=self.config.reg_weight, betas=(0.9, 0.999), eps=1e-8\n",
    "        )\n",
    "\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.7, patience=8, verbose=False, min_lr=1e-6\n",
    "        )\n",
    "\n",
    "        # Training variables\n",
    "        training_losses = []\n",
    "        validation_losses = []\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "\n",
    "        print(f\"   üèÉ Training: {len(train_dataset):,} samples, validating: {len(val_dataset):,}\")\n",
    "\n",
    "        for epoch in range(self.config.epochs):\n",
    "            # Training phase\n",
    "            model.train()\n",
    "            epoch_loss = 0\n",
    "            num_batches = 0\n",
    "\n",
    "            for batch in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                playlists = batch['playlist'].squeeze().to(self.device)\n",
    "                pos_tracks = batch['pos_track'].squeeze().to(self.device)\n",
    "                neg_tracks = batch['neg_tracks'].to(self.device)\n",
    "\n",
    "                # Validate indices\n",
    "                if (playlists.max() >= self.total_nodes or\n",
    "                    pos_tracks.max() >= self.total_nodes or\n",
    "                    neg_tracks.max() >= self.total_nodes):\n",
    "                    continue\n",
    "\n",
    "                # Forward pass\n",
    "                all_embeddings = model(adj_matrix)\n",
    "                pos_scores = model.predict(playlists, pos_tracks, all_embeddings)\n",
    "\n",
    "                # Negative scores\n",
    "                batch_size = playlists.size(0)\n",
    "                neg_samples = neg_tracks.size(1)\n",
    "                playlists_expanded = playlists.unsqueeze(1).expand(-1, neg_samples).contiguous().view(-1)\n",
    "                neg_tracks_flat = neg_tracks.view(-1)\n",
    "                neg_scores = model.predict(playlists_expanded, neg_tracks_flat, all_embeddings)\n",
    "                neg_scores = neg_scores.view(batch_size, neg_samples)\n",
    "\n",
    "                # BPR loss\n",
    "                loss = self._bpr_loss(pos_scores, neg_scores)\n",
    "\n",
    "                # Regularization\n",
    "                reg_loss = 0\n",
    "                for name, param in model.named_parameters():\n",
    "                    if 'embedding' in name or 'transform' in name:\n",
    "                        reg_loss += torch.norm(param, p=2)\n",
    "\n",
    "                total_loss = loss + self.config.reg_weight * reg_loss\n",
    "\n",
    "                if torch.isnan(total_loss) or torch.isinf(total_loss):\n",
    "                    continue\n",
    "\n",
    "                total_loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += total_loss.item()\n",
    "                num_batches += 1\n",
    "\n",
    "            if num_batches == 0:\n",
    "                break\n",
    "\n",
    "            avg_train_loss = epoch_loss / num_batches\n",
    "            training_losses.append(avg_train_loss)\n",
    "\n",
    "            # Validation phase\n",
    "            if (epoch + 1) % self.config.val_every == 0:\n",
    "                model.eval()\n",
    "                val_loss = 0\n",
    "                val_batches = 0\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for batch in val_loader:\n",
    "                        playlists = batch['playlist'].squeeze().to(self.device)\n",
    "                        pos_tracks = batch['pos_track'].squeeze().to(self.device)\n",
    "                        neg_tracks = batch['neg_tracks'].to(self.device)\n",
    "\n",
    "                        if (playlists.max() >= self.total_nodes or\n",
    "                            pos_tracks.max() >= self.total_nodes or\n",
    "                            neg_tracks.max() >= self.total_nodes):\n",
    "                            continue\n",
    "\n",
    "                        all_embeddings = model(adj_matrix)\n",
    "                        pos_scores = model.predict(playlists, pos_tracks, all_embeddings)\n",
    "\n",
    "                        batch_size = playlists.size(0)\n",
    "                        neg_samples = neg_tracks.size(1)\n",
    "                        playlists_expanded = playlists.unsqueeze(1).expand(-1, neg_samples).contiguous().view(-1)\n",
    "                        neg_tracks_flat = neg_tracks.view(-1)\n",
    "                        neg_scores = model.predict(playlists_expanded, neg_tracks_flat, all_embeddings)\n",
    "                        neg_scores = neg_scores.view(batch_size, neg_samples)\n",
    "\n",
    "                        batch_val_loss = self._bpr_loss(pos_scores, neg_scores)\n",
    "                        val_loss += batch_val_loss.item()\n",
    "                        val_batches += 1\n",
    "\n",
    "                if val_batches > 0:\n",
    "                    avg_val_loss = val_loss / val_batches\n",
    "                    validation_losses.append(avg_val_loss)\n",
    "                    scheduler.step(avg_val_loss)\n",
    "\n",
    "                    # Early stopping\n",
    "                    if avg_val_loss < best_val_loss:\n",
    "                        best_val_loss = avg_val_loss\n",
    "                        patience_counter = 0\n",
    "                    else:\n",
    "                        patience_counter += 1\n",
    "\n",
    "                    if patience_counter >= self.config.early_stopping_patience:\n",
    "                        print(f\"      ‚è∞ Early stopping at epoch {epoch + 1}\")\n",
    "                        break\n",
    "\n",
    "                    if (epoch + 1) % 50 == 0:\n",
    "                        print(f\"      Epoch {epoch + 1}: Train={avg_train_loss:.4f}, Val={avg_val_loss:.4f}\")\n",
    "\n",
    "        return {\n",
    "            'losses': training_losses,\n",
    "            'val_losses': validation_losses,\n",
    "            'final_loss': training_losses[-1] if training_losses else float('inf'),\n",
    "            'best_val_loss': best_val_loss\n",
    "        }\n",
    "\n",
    "    def _bpr_loss(self, pos_scores, neg_scores):\n",
    "        \"\"\"Bayesian Personalized Ranking loss\"\"\"\n",
    "        pos_scores_expanded = pos_scores.unsqueeze(1)\n",
    "        diff = pos_scores_expanded - neg_scores\n",
    "        diff = torch.clamp(diff, min=-15, max=15)\n",
    "        loss = -torch.log(torch.sigmoid(diff) + 1e-8).mean()\n",
    "        return loss\n",
    "\n",
    "    def evaluate_model(self, model, adj_matrix, split='test', seed=None):\n",
    "        \"\"\"Evaluate model on test/validation set\"\"\"\n",
    "        if seed is not None:\n",
    "            set_all_seeds(seed)\n",
    "\n",
    "        print(f\"   üìä Evaluating on {split} set...\")\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            all_embeddings = model(adj_matrix)\n",
    "\n",
    "            if split == 'test':\n",
    "                test_edges = self.data['splits']['test_edges']\n",
    "            else:\n",
    "                test_edges = self.data['splits']['val_edges']\n",
    "\n",
    "            metrics = self._calculate_metrics(all_embeddings, test_edges, seed)\n",
    "\n",
    "        model.train()\n",
    "        return metrics\n",
    "\n",
    "    def _calculate_metrics(self, all_embeddings, test_edges, seed):\n",
    "        \"\"\"Calculate recommendation metrics\"\"\"\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        # Convert test edges to playlist-track pairs\n",
    "        test_pairs = []\n",
    "        for edge in test_edges:\n",
    "            playlist_node, track_node = edge\n",
    "            playlist_id = playlist_node\n",
    "            track_id = track_node - self.track_offset\n",
    "\n",
    "            if 0 <= playlist_id < self.playlist_count and 0 <= track_id < self.track_count:\n",
    "                test_pairs.append((playlist_id, track_id))\n",
    "\n",
    "        # Group by playlist\n",
    "        playlist_test_tracks = defaultdict(set)\n",
    "        for playlist_id, track_id in test_pairs:\n",
    "            playlist_test_tracks[playlist_id].add(track_id)\n",
    "\n",
    "        # Filter valid playlists\n",
    "        valid_playlists = [p for p, tracks in playlist_test_tracks.items()\n",
    "                          if len(tracks) >= 2 and p < self.playlist_count]\n",
    "\n",
    "        if len(valid_playlists) > self.config.eval_sample_size:\n",
    "            valid_playlists = np.random.choice(\n",
    "                valid_playlists, self.config.eval_sample_size, replace=False\n",
    "            )\n",
    "\n",
    "        # Calculate metrics\n",
    "        all_precisions = {k: [] for k in self.config.k_values}\n",
    "        all_recalls = {k: [] for k in self.config.k_values}\n",
    "        all_ndcgs = {k: [] for k in self.config.k_values}\n",
    "        all_auc_scores = []\n",
    "        valid_evaluations = 0\n",
    "\n",
    "        for playlist_id in valid_playlists:\n",
    "            pos_tracks = list(playlist_test_tracks[playlist_id])\n",
    "            if len(pos_tracks) < 2:\n",
    "                continue\n",
    "\n",
    "            # Sample negative tracks\n",
    "            all_tracks = set(range(self.track_count))\n",
    "            available_negatives = list(all_tracks - playlist_test_tracks[playlist_id])\n",
    "\n",
    "            if len(available_negatives) >= 99:\n",
    "                neg_tracks = np.random.choice(available_negatives, 99, replace=False)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            # Calculate scores\n",
    "            all_candidate_tracks = pos_tracks + list(neg_tracks)\n",
    "            playlist_emb = all_embeddings[playlist_id]\n",
    "            track_nodes = [tid + self.track_offset for tid in all_candidate_tracks]\n",
    "            track_embs = all_embeddings[track_nodes]\n",
    "\n",
    "            # Normalized scores\n",
    "            playlist_emb_norm = F.normalize(playlist_emb.unsqueeze(0), p=2, dim=1)\n",
    "            track_embs_norm = F.normalize(track_embs, p=2, dim=1)\n",
    "            scores = torch.matmul(playlist_emb_norm, track_embs_norm.t()).squeeze().cpu().numpy()\n",
    "\n",
    "            # Ground truth\n",
    "            ground_truth = np.array([1] * len(pos_tracks) + [0] * len(neg_tracks))\n",
    "\n",
    "            # AUC\n",
    "            try:\n",
    "                if len(np.unique(ground_truth)) > 1 and len(np.unique(scores)) > 1:\n",
    "                    auc = roc_auc_score(ground_truth, scores)\n",
    "                    all_auc_scores.append(auc)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            # Ranking metrics\n",
    "            sorted_indices = np.argsort(scores)[::-1]\n",
    "            sorted_tracks = [all_candidate_tracks[i] for i in sorted_indices]\n",
    "            relevant_tracks = set(pos_tracks)\n",
    "\n",
    "            for k in self.config.k_values:\n",
    "                if k > len(sorted_tracks):\n",
    "                    continue\n",
    "\n",
    "                top_k_tracks = sorted_tracks[:k]\n",
    "                recommended_relevant = set(top_k_tracks) & relevant_tracks\n",
    "\n",
    "                # Precision@K\n",
    "                precision = len(recommended_relevant) / k if k > 0 else 0\n",
    "                all_precisions[k].append(precision)\n",
    "\n",
    "                # Recall@K\n",
    "                recall = len(recommended_relevant) / len(relevant_tracks) if len(relevant_tracks) > 0 else 0\n",
    "                all_recalls[k].append(recall)\n",
    "\n",
    "                # NDCG@K\n",
    "                ndcg = self._calculate_ndcg(top_k_tracks, relevant_tracks, k)\n",
    "                all_ndcgs[k].append(ndcg)\n",
    "\n",
    "            valid_evaluations += 1\n",
    "\n",
    "        # Aggregate metrics\n",
    "        metrics = {}\n",
    "        if valid_evaluations == 0:\n",
    "            print(\"      ‚ùå No valid evaluations!\")\n",
    "            return {f'{metric}@{k}': 0.0 for metric in ['precision', 'recall', 'ndcg'] for k in self.config.k_values}\n",
    "\n",
    "        for k in self.config.k_values:\n",
    "            metrics[f'precision@{k}'] = np.mean(all_precisions[k]) if all_precisions[k] else 0.0\n",
    "            metrics[f'recall@{k}'] = np.mean(all_recalls[k]) if all_recalls[k] else 0.0\n",
    "            metrics[f'ndcg@{k}'] = np.mean(all_ndcgs[k]) if all_ndcgs[k] else 0.0\n",
    "\n",
    "        metrics['auc'] = np.mean(all_auc_scores) if all_auc_scores else 0.0\n",
    "\n",
    "        print(f\"      ‚úÖ Evaluated {valid_evaluations} playlists\")\n",
    "        print(f\"      üìä NDCG@10: {metrics.get('ndcg@10', 0):.4f}, AUC: {metrics.get('auc', 0):.4f}\")\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def _calculate_ndcg(self, ranked_list, relevant_items, k):\n",
    "        \"\"\"Calculate NDCG@K\"\"\"\n",
    "        if k == 0 or not relevant_items:\n",
    "            return 0.0\n",
    "\n",
    "        # DCG\n",
    "        dcg = 0.0\n",
    "        for i, item in enumerate(ranked_list[:k]):\n",
    "            if item in relevant_items:\n",
    "                dcg += 1.0 / math.log2(i + 2)\n",
    "\n",
    "        # IDCG\n",
    "        idcg = 0.0\n",
    "        for i in range(min(k, len(relevant_items))):\n",
    "            idcg += 1.0 / math.log2(i + 2)\n",
    "\n",
    "        return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 10. EXPERIMENT ORCHESTRATION\n",
    "# =============================================================================\n",
    "\n",
    "class ExperimentRunner:\n",
    "    \"\"\"Main experiment orchestrator with comprehensive result saving\"\"\"\n",
    "\n",
    "    def __init__(self, config, data):\n",
    "        self.config = config\n",
    "        self.data = data\n",
    "        self.trainer = ModelTrainer(config, data)\n",
    "        self.experiment_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "        print(\"üéØ EXPERIMENT RUNNER INITIALIZED\")\n",
    "        print(f\"   üìä Dataset: {data['entity_counts']['playlists']:,} playlists\")\n",
    "        print(f\"   üé≤ Seeds per config: {len(config.random_seeds)}\")\n",
    "        print(f\"   üìÅ Results dir: {config.results_dir}\")\n",
    "        print(f\"   üïê Timestamp: {self.experiment_timestamp}\")\n",
    "\n",
    "    def run_all_experiments(self):\n",
    "        \"\"\"Run all experiments with comprehensive result saving\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üî¨ STARTING LIGHTGCN EXPERIMENTS WITH RESULT SAVING\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        experiment_configs = self.config.get_experiment_configs()\n",
    "        results = {}\n",
    "\n",
    "        print(f\"\\nüî¨ Running {len(experiment_configs)} configurations:\")\n",
    "        for name, config in experiment_configs.items():\n",
    "            print(f\"   ‚Ä¢ {name}: {config['description']}\")\n",
    "\n",
    "        # Save experiment configuration\n",
    "        self._save_experiment_config(experiment_configs)\n",
    "\n",
    "        # Run each configuration\n",
    "        for config_name, config_spec in experiment_configs.items():\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"üß™ Configuration: {config_spec['name']}\")\n",
    "            print(f\"üìù {config_spec['description']}\")\n",
    "\n",
    "            config_results = self._run_single_config(config_name, config_spec)\n",
    "\n",
    "            if config_results:\n",
    "                results[config_name] = config_results\n",
    "                # Save configuration results immediately\n",
    "                self.config.result_saver.save_config_results(\n",
    "                    config_name, config_results, self.experiment_timestamp\n",
    "                )\n",
    "\n",
    "        # Save complete results and analysis\n",
    "        if results:\n",
    "            self.config.result_saver.save_complete_results(results, self.experiment_timestamp)\n",
    "            self._print_final_results(results)\n",
    "            analysis_results = self._perform_statistical_analysis(results)\n",
    "            self.config.result_saver.save_analysis_results(analysis_results, self.experiment_timestamp)\n",
    "            self.config.result_saver.create_experiment_summary(results, self.experiment_timestamp)\n",
    "\n",
    "            print(f\"\\nüéâ ALL RESULTS SAVED TO: {self.config.results_dir}\")\n",
    "            print(f\"üìÅ Experiment timestamp: {self.experiment_timestamp}\")\n",
    "\n",
    "        return results\n",
    "\n",
    "    def _save_experiment_config(self, experiment_configs):\n",
    "        \"\"\"Save experiment configuration\"\"\"\n",
    "        config_info = {\n",
    "            'timestamp': self.experiment_timestamp,\n",
    "            'configurations': experiment_configs,\n",
    "            'settings': {\n",
    "                'random_seeds': self.config.random_seeds,\n",
    "                'target_playlists': self.config.target_playlists,\n",
    "                'embedding_dim': self.config.embedding_dim,\n",
    "                'n_layers': self.config.n_layers,\n",
    "                'learning_rate': self.config.learning_rate,\n",
    "                'epochs': self.config.epochs,\n",
    "                'batch_size': self.config.batch_size,\n",
    "                'k_values': self.config.k_values\n",
    "            },\n",
    "            'dataset_info': {\n",
    "                'entity_counts': self.data['entity_counts'],\n",
    "                'node_offsets': self.data['node_offsets'],\n",
    "                'total_nodes': self.data['total_nodes']\n",
    "            }\n",
    "        }\n",
    "\n",
    "        config_file = os.path.join(self.config.results_dir, f\"experiment_config_{self.experiment_timestamp}.json\")\n",
    "        with open(config_file, 'w') as f:\n",
    "            json.dump(config_info, f, indent=2)\n",
    "        print(f\"üíæ Experiment configuration saved: {os.path.basename(config_file)}\")\n",
    "\n",
    "    def _run_single_config(self, config_name, config_spec):\n",
    "        \"\"\"Run all seeds for a single configuration\"\"\"\n",
    "        config_results = []\n",
    "\n",
    "        for seed_idx, seed in enumerate(self.config.random_seeds):\n",
    "            print(f\"\\nüé≤ Seed {seed_idx+1}/{len(self.config.random_seeds)} (seed={seed}):\")\n",
    "\n",
    "            # Train model\n",
    "            training_result = self.trainer.train_model(config_spec, seed=seed, save_model=True)\n",
    "\n",
    "            if training_result is None:\n",
    "                print(f\"   ‚ùå Training failed for seed {seed}\")\n",
    "                continue\n",
    "\n",
    "            # Evaluate model\n",
    "            test_metrics = self.trainer.evaluate_model(\n",
    "                training_result['model'],\n",
    "                training_result['adj_matrix'],\n",
    "                'test',\n",
    "                seed=seed\n",
    "            )\n",
    "\n",
    "            # Store results\n",
    "            run_result = {\n",
    "                'seed': seed,\n",
    "                'metrics': test_metrics,\n",
    "                'training_time': training_result['training_time'],\n",
    "                'final_loss': training_result['final_loss'],\n",
    "                'best_val_loss': training_result['best_val_loss'],\n",
    "                'model_file': training_result.get('model_file'),\n",
    "                'timestamp': training_result.get('timestamp')\n",
    "            }\n",
    "            config_results.append(run_result)\n",
    "\n",
    "            # Save individual run results\n",
    "            self.config.result_saver.save_training_run(\n",
    "                config_name, seed, training_result, test_metrics,\n",
    "                training_result.get('timestamp')\n",
    "            )\n",
    "\n",
    "            # Print immediate results\n",
    "            print(f\"      üìä NDCG@10: {test_metrics.get('ndcg@10', 0):.4f}\")\n",
    "            print(f\"      üìä AUC: {test_metrics.get('auc', 0):.4f}\")\n",
    "            print(f\"      ‚è±Ô∏è Time: {training_result['training_time']:.1f}s\")\n",
    "\n",
    "            # Memory cleanup\n",
    "            del training_result\n",
    "            gc.collect()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        # Calculate statistics\n",
    "        if config_results:\n",
    "            stats = self._calculate_statistics(config_results)\n",
    "            config_data = {\n",
    "                'config': config_spec,\n",
    "                'runs': config_results,\n",
    "                'statistics': stats\n",
    "            }\n",
    "\n",
    "            # Print configuration summary\n",
    "            ndcg_mean = stats.get('ndcg@10', {}).get('mean', 0)\n",
    "            ndcg_std = stats.get('ndcg@10', {}).get('std', 0)\n",
    "            print(f\"\\n   üìä CONFIGURATION SUMMARY: {config_spec['name']}\")\n",
    "            print(f\"      NDCG@10: {ndcg_mean:.4f} ¬± {ndcg_std:.4f}\")\n",
    "            print(f\"      ‚úÖ Results saved for {config_name}\")\n",
    "\n",
    "            return config_data\n",
    "\n",
    "        return None\n",
    "\n",
    "    def _calculate_statistics(self, config_results):\n",
    "        \"\"\"Calculate statistics for a configuration\"\"\"\n",
    "        if not config_results:\n",
    "            return {}\n",
    "\n",
    "        statistics = {}\n",
    "\n",
    "        # Get all metric names\n",
    "        all_metrics = set()\n",
    "        for run in config_results:\n",
    "            all_metrics.update(run['metrics'].keys())\n",
    "\n",
    "        # Calculate statistics for each metric\n",
    "        for metric in all_metrics:\n",
    "            values = [run['metrics'].get(metric, 0) for run in config_results]\n",
    "\n",
    "            if values and len(values) > 1:\n",
    "                mean_val = np.mean(values)\n",
    "                std_val = np.std(values, ddof=1)\n",
    "                n = len(values)\n",
    "\n",
    "                # Confidence intervals\n",
    "                if n > 2:\n",
    "                    t_value = scipy_stats.t.ppf(0.975, n-1)\n",
    "                    margin_error = t_value * std_val / np.sqrt(n)\n",
    "                    ci_lower = mean_val - margin_error\n",
    "                    ci_upper = mean_val + margin_error\n",
    "                else:\n",
    "                    ci_lower = mean_val\n",
    "                    ci_upper = mean_val\n",
    "\n",
    "                statistics[metric] = {\n",
    "                    'mean': mean_val,\n",
    "                    'std': std_val,\n",
    "                    'min': np.min(values),\n",
    "                    'max': np.max(values),\n",
    "                    'ci_lower': ci_lower,\n",
    "                    'ci_upper': ci_upper,\n",
    "                    'n': n\n",
    "                }\n",
    "            elif values:\n",
    "                statistics[metric] = {\n",
    "                    'mean': values[0],\n",
    "                    'std': 0.0,\n",
    "                    'min': values[0],\n",
    "                    'max': values[0],\n",
    "                    'ci_lower': values[0],\n",
    "                    'ci_upper': values[0],\n",
    "                    'n': 1\n",
    "                }\n",
    "\n",
    "        return statistics\n",
    "\n",
    "    def _print_final_results(self, results):\n",
    "        \"\"\"Print formatted final results\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üìä EXPERIMENTAL RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        if not results:\n",
    "            print(\"‚ùå No results to display\")\n",
    "            return\n",
    "\n",
    "        print(\"\\nConfiguration                    NDCG@10 (Mean¬±Std)      AUC (Mean¬±Std)       Time (s)\")\n",
    "        print(\"-\" * 85)\n",
    "\n",
    "        # Sort by NDCG@10 performance\n",
    "        sorted_results = sorted(results.items(),\n",
    "                              key=lambda x: x[1]['statistics'].get('ndcg@10', {}).get('mean', 0),\n",
    "                              reverse=True)\n",
    "\n",
    "        for config_name, result in sorted_results:\n",
    "            result_stats = result['statistics']\n",
    "\n",
    "            ndcg_mean = result_stats.get('ndcg@10', {}).get('mean', 0)\n",
    "            ndcg_std = result_stats.get('ndcg@10', {}).get('std', 0)\n",
    "            auc_mean = result_stats.get('auc', {}).get('mean', 0)\n",
    "            auc_std = result_stats.get('auc', {}).get('std', 0)\n",
    "            time_mean = np.mean([run['training_time'] for run in result['runs']]) if result['runs'] else 0\n",
    "\n",
    "            print(f\"{config_name:<30} {ndcg_mean:.4f}¬±{ndcg_std:.4f}        {auc_mean:.4f}¬±{auc_std:.4f}       {time_mean:.1f}\")\n",
    "\n",
    "        # Highlight best configuration\n",
    "        if sorted_results:\n",
    "            best_config = sorted_results[0]\n",
    "            best_result_stats = best_config[1]['statistics']['ndcg@10']\n",
    "            print(f\"\\nüèÜ BEST CONFIGURATION: {best_config[0]}\")\n",
    "            print(f\"   üìä NDCG@10: {best_result_stats['mean']:.4f} ¬± {best_result_stats['std']:.4f}\")\n",
    "            print(f\"   üîç 95% CI: [{best_result_stats['ci_lower']:.4f}, {best_result_stats['ci_upper']:.4f}]\")\n",
    "\n",
    "        # Performance insights\n",
    "        self._print_performance_insights(results)\n",
    "\n",
    "    def _print_performance_insights(self, results):\n",
    "        \"\"\"Print performance insights\"\"\"\n",
    "        print(f\"\\nüí° PERFORMANCE INSIGHTS:\")\n",
    "\n",
    "        feature_configs = [name for name in results.keys() if 'features' in name]\n",
    "        non_feature_configs = [name for name in results.keys() if 'features' not in name]\n",
    "\n",
    "        if feature_configs and non_feature_configs:\n",
    "            best_with_features = max(feature_configs,\n",
    "                                   key=lambda x: results[x]['statistics'].get('ndcg@10', {}).get('mean', 0))\n",
    "            best_without_features = max(non_feature_configs,\n",
    "                                      key=lambda x: results[x]['statistics'].get('ndcg@10', {}).get('mean', 0))\n",
    "\n",
    "            feat_performance = results[best_with_features]['statistics']['ndcg@10']['mean']\n",
    "            no_feat_performance = results[best_without_features]['statistics']['ndcg@10']['mean']\n",
    "            improvement = (feat_performance - no_feat_performance) / no_feat_performance * 100\n",
    "\n",
    "            print(f\"   üéØ Feature Impact: {improvement:+.1f}% improvement\")\n",
    "            print(f\"      Best w/ features: {best_with_features} ({feat_performance:.4f})\")\n",
    "            print(f\"      Best w/o features: {best_without_features} ({no_feat_performance:.4f})\")\n",
    "\n",
    "    def _perform_statistical_analysis(self, results):\n",
    "        \"\"\"Perform comprehensive statistical analysis\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üî¨ STATISTICAL SIGNIFICANCE ANALYSIS\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        analysis_results = {\n",
    "            'timestamp': self.experiment_timestamp,\n",
    "            'pairwise_comparisons': [],\n",
    "            'significant_differences': [],\n",
    "            'feature_importance_analysis': {},\n",
    "            'graph_structure_analysis': {}\n",
    "        }\n",
    "\n",
    "        if len(results) < 2:\n",
    "            print(\"‚ùå Need at least 2 configurations for statistical testing\")\n",
    "            return analysis_results\n",
    "\n",
    "        # Pairwise statistical tests\n",
    "        config_values = {}\n",
    "        for config_name, result in results.items():\n",
    "            values = [run['metrics'].get('ndcg@10', 0) for run in result['runs']]\n",
    "            config_values[config_name] = values\n",
    "\n",
    "        config_names = list(config_values.keys())\n",
    "        significant_pairs = []\n",
    "\n",
    "        print(\"\\nPairwise analysis (NDCG@10):\")\n",
    "        print(\"Configuration 1          vs Configuration 2          p-value    Effect Size  Significant\")\n",
    "        print(\"-\" * 95)\n",
    "\n",
    "        for i in range(len(config_names)):\n",
    "            for j in range(i+1, len(config_names)):\n",
    "                config1 = config_names[i]\n",
    "                config2 = config_names[j]\n",
    "                values1 = config_values[config1]\n",
    "                values2 = config_values[config2]\n",
    "\n",
    "                comparison_result = {\n",
    "                    'config1': config1,\n",
    "                    'config2': config2,\n",
    "                    'config1_mean': np.mean(values1) if values1 else 0,\n",
    "                    'config2_mean': np.mean(values2) if values2 else 0\n",
    "                }\n",
    "\n",
    "                if len(values1) > 1 and len(values2) > 1:\n",
    "                    # t-test\n",
    "                    t_stat, p_val = scipy_stats.ttest_ind(values1, values2)\n",
    "\n",
    "                    # Effect size (Cohen's d)\n",
    "                    pooled_std = np.sqrt(((len(values1) - 1) * np.var(values1, ddof=1) +\n",
    "                                        (len(values2) - 1) * np.var(values2, ddof=1)) /\n",
    "                                       (len(values1) + len(values2) - 2))\n",
    "\n",
    "                    cohens_d = abs(np.mean(values1) - np.mean(values2)) / pooled_std if pooled_std > 0 else 0\n",
    "\n",
    "                    comparison_result.update({\n",
    "                        'p_value': p_val,\n",
    "                        'cohens_d': cohens_d,\n",
    "                        't_statistic': t_stat\n",
    "                    })\n",
    "\n",
    "                    # Significance levels\n",
    "                    if p_val < 0.001:\n",
    "                        significance = \"***\"\n",
    "                        significant_pairs.append((config1, config2, p_val, cohens_d))\n",
    "                    elif p_val < 0.01:\n",
    "                        significance = \"**\"\n",
    "                        significant_pairs.append((config1, config2, p_val, cohens_d))\n",
    "                    elif p_val < 0.05:\n",
    "                        significance = \"*\"\n",
    "                        significant_pairs.append((config1, config2, p_val, cohens_d))\n",
    "                    else:\n",
    "                        significance = \"n.s.\"\n",
    "\n",
    "                    comparison_result['significance'] = significance\n",
    "\n",
    "                    effect_size = \"small\" if cohens_d < 0.2 else \"medium\" if cohens_d < 0.5 else \"large\" if cohens_d < 0.8 else \"very large\"\n",
    "                    comparison_result['effect_size_interpretation'] = effect_size\n",
    "\n",
    "                    print(f\"{config1:<25} vs {config2:<25} {p_val:.4f}      {cohens_d:.3f}({effect_size:<5}) {significance}\")\n",
    "                else:\n",
    "                    comparison_result.update({\n",
    "                        'p_value': None,\n",
    "                        'cohens_d': None,\n",
    "                        't_statistic': None,\n",
    "                        'significance': 'insufficient_data',\n",
    "                        'effect_size_interpretation': 'unknown'\n",
    "                    })\n",
    "                    print(f\"{config1:<25} vs {config2:<25} N/A        N/A            insufficient data\")\n",
    "\n",
    "                analysis_results['pairwise_comparisons'].append(comparison_result)\n",
    "\n",
    "        # Summary of significant differences\n",
    "        if significant_pairs:\n",
    "            print(f\"\\nüìä SIGNIFICANT DIFFERENCES FOUND:\")\n",
    "            for config1, config2, p_val, effect_size in significant_pairs:\n",
    "                mean1 = np.mean(config_values[config1])\n",
    "                mean2 = np.mean(config_values[config2])\n",
    "                better = config1 if mean1 > mean2 else config2\n",
    "                worse = config2 if mean1 > mean2 else config1\n",
    "                improvement = abs(mean1 - mean2) / min(mean1, mean2) * 100\n",
    "\n",
    "                significant_diff = {\n",
    "                    'better_config': better,\n",
    "                    'worse_config': worse,\n",
    "                    'improvement_percent': improvement,\n",
    "                    'p_value': p_val,\n",
    "                    'effect_size': effect_size\n",
    "                }\n",
    "                analysis_results['significant_differences'].append(significant_diff)\n",
    "\n",
    "                print(f\"   üî∏ {better} > {worse}\")\n",
    "                print(f\"      Improvement: {improvement:.1f}%, p={p_val:.4f}, effect size={effect_size:.3f}\")\n",
    "        else:\n",
    "            print(f\"\\nüìä NO SIGNIFICANT DIFFERENCES FOUND\")\n",
    "\n",
    "        # Feature and graph analysis\n",
    "        analysis_results['feature_importance_analysis'] = self._analyze_feature_importance(results)\n",
    "        analysis_results['graph_structure_analysis'] = self._analyze_graph_structure(results)\n",
    "\n",
    "        return analysis_results\n",
    "\n",
    "    def _analyze_feature_importance(self, results):\n",
    "        \"\"\"Analyze feature importance\"\"\"\n",
    "        analysis = {\n",
    "            'baseline_performance': None,\n",
    "            'individual_feature_impacts': {},\n",
    "            'combined_feature_effect': None,\n",
    "            'feature_ranking': [],\n",
    "            'synergy_analysis': None,\n",
    "            'recommendations': {}\n",
    "        }\n",
    "\n",
    "        # Check for required configurations\n",
    "        required_configs = ['playlist_features', 'track_features', 'user_features', 'all_features']\n",
    "        available_configs = [config for config in required_configs if config in results]\n",
    "\n",
    "        if not available_configs:\n",
    "            analysis['error'] = \"No feature configurations found\"\n",
    "            return analysis\n",
    "\n",
    "        # Get baseline performance\n",
    "        if 'baseline' in results:\n",
    "            baseline_performance = results['baseline']['statistics']['ndcg@10']['mean']\n",
    "            baseline_std = results['baseline']['statistics']['ndcg@10']['std']\n",
    "            analysis['baseline_performance'] = {\n",
    "                'ndcg_mean': baseline_performance,\n",
    "                'ndcg_std': baseline_std\n",
    "            }\n",
    "        else:\n",
    "            analysis['error'] = \"No baseline configuration found\"\n",
    "            return analysis\n",
    "\n",
    "        # Individual feature impacts\n",
    "        feature_configs = {\n",
    "            'playlist_features': 'Playlist Features (6D)',\n",
    "            'track_features': 'Track Features (4D)',\n",
    "            'user_features': 'User Features (4D)'\n",
    "        }\n",
    "\n",
    "        feature_improvements = {}\n",
    "\n",
    "        for config_name, description in feature_configs.items():\n",
    "            if config_name in results:\n",
    "                perf = results[config_name]['statistics']['ndcg@10']['mean']\n",
    "                std = results[config_name]['statistics']['ndcg@10']['std']\n",
    "                improvement = (perf - baseline_performance) / baseline_performance * 100\n",
    "                feature_improvements[config_name] = improvement\n",
    "\n",
    "                feature_impact = {\n",
    "                    'description': description,\n",
    "                    'ndcg_mean': perf,\n",
    "                    'ndcg_std': std,\n",
    "                    'improvement_percent': improvement\n",
    "                }\n",
    "\n",
    "                # Statistical significance\n",
    "                baseline_values = [run['metrics']['ndcg@10'] for run in results['baseline']['runs']]\n",
    "                feature_values = [run['metrics']['ndcg@10'] for run in results[config_name]['runs']]\n",
    "\n",
    "                if len(baseline_values) > 1 and len(feature_values) > 1:\n",
    "                    t_stat, p_val = scipy_stats.ttest_ind(feature_values, baseline_values)\n",
    "                    significance = \"***\" if p_val < 0.001 else \"**\" if p_val < 0.01 else \"*\" if p_val < 0.05 else \"n.s.\"\n",
    "                    feature_impact['p_value'] = p_val\n",
    "                    feature_impact['significance'] = significance\n",
    "\n",
    "                analysis['individual_feature_impacts'][config_name] = feature_impact\n",
    "\n",
    "        # Combined feature effect\n",
    "        if 'all_features' in results:\n",
    "            combined_perf = results['all_features']['statistics']['ndcg@10']['mean']\n",
    "            combined_std = results['all_features']['statistics']['ndcg@10']['std']\n",
    "            combined_improvement = (combined_perf - baseline_performance) / baseline_performance * 100\n",
    "\n",
    "            analysis['combined_feature_effect'] = {\n",
    "                'ndcg_mean': combined_perf,\n",
    "                'ndcg_std': combined_std,\n",
    "                'improvement_percent': combined_improvement\n",
    "            }\n",
    "\n",
    "            # Synergy analysis\n",
    "            if len(feature_improvements) >= 3:\n",
    "                expected_improvement = sum(feature_improvements.values())\n",
    "                synergy_effect = combined_improvement - expected_improvement\n",
    "\n",
    "                synergy_interpretation = \"neutral\"\n",
    "                if synergy_effect > 2.0:\n",
    "                    synergy_interpretation = \"strong_positive\"\n",
    "                elif synergy_effect > 0.5:\n",
    "                    synergy_interpretation = \"moderate_positive\"\n",
    "                elif synergy_effect < -2.0:\n",
    "                    synergy_interpretation = \"strong_negative\"\n",
    "                elif synergy_effect < -0.5:\n",
    "                    synergy_interpretation = \"moderate_negative\"\n",
    "\n",
    "                analysis['synergy_analysis'] = {\n",
    "                    'expected_additive_improvement': expected_improvement,\n",
    "                    'actual_combined_improvement': combined_improvement,\n",
    "                    'synergy_effect': synergy_effect,\n",
    "                    'interpretation': synergy_interpretation\n",
    "                }\n",
    "\n",
    "        # Feature ranking\n",
    "        feature_ranking = sorted(feature_improvements.items(), key=lambda x: x[1], reverse=True)\n",
    "        analysis['feature_ranking'] = [\n",
    "            {\n",
    "                'rank': i + 1,\n",
    "                'feature_type': config_name.replace('_features', '').replace('_', ' ').title(),\n",
    "                'config_name': config_name,\n",
    "                'improvement_percent': improvement\n",
    "            }\n",
    "            for i, (config_name, improvement) in enumerate(feature_ranking)\n",
    "        ]\n",
    "\n",
    "        return analysis\n",
    "\n",
    "    def _analyze_graph_structure(self, results):\n",
    "        \"\"\"Analyze graph structure importance\"\"\"\n",
    "        analysis = {\n",
    "            'configurations': {},\n",
    "            'best_structure': None,\n",
    "            'structure_ranking': []\n",
    "        }\n",
    "\n",
    "        phase1_configs = ['baseline', 'with_artists', 'with_users', 'full_graph']\n",
    "        structure_performances = {}\n",
    "\n",
    "        for config_name in phase1_configs:\n",
    "            if config_name in results:\n",
    "                perf = results[config_name]['statistics']['ndcg@10']['mean']\n",
    "                std = results[config_name]['statistics']['ndcg@10']['std']\n",
    "                description = results[config_name]['config']['description']\n",
    "\n",
    "                structure_performances[config_name] = perf\n",
    "                analysis['configurations'][config_name] = {\n",
    "                    'ndcg_mean': perf,\n",
    "                    'ndcg_std': std,\n",
    "                    'description': description\n",
    "                }\n",
    "\n",
    "        # Best structure\n",
    "        if structure_performances:\n",
    "            best_structure = max(structure_performances.items(), key=lambda x: x[1])\n",
    "            baseline_perf = structure_performances.get('baseline', 0)\n",
    "\n",
    "            analysis['best_structure'] = {\n",
    "                'config_name': best_structure[0],\n",
    "                'ndcg_mean': best_structure[1],\n",
    "                'improvement_over_baseline': (best_structure[1] - baseline_perf) / baseline_perf * 100 if baseline_perf > 0 else 0\n",
    "            }\n",
    "\n",
    "            # Structure ranking\n",
    "            structure_ranking = sorted(structure_performances.items(), key=lambda x: x[1], reverse=True)\n",
    "            analysis['structure_ranking'] = [\n",
    "                {\n",
    "                    'rank': i + 1,\n",
    "                    'config_name': config_name,\n",
    "                    'ndcg_mean': perf,\n",
    "                    'improvement_over_baseline': (perf - baseline_perf) / baseline_perf * 100 if baseline_perf > 0 else 0\n",
    "                }\n",
    "                for i, (config_name, perf) in enumerate(structure_ranking)\n",
    "            ]\n",
    "\n",
    "        return analysis\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 11. MAIN EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "def run_lightgcn_experiments(data_path=\"../data/processed/spotify_scaled_hybrid_7500.json\"):\n",
    "    \"\"\"\n",
    "    Main function to run LightGCN experiments with comprehensive result saving\n",
    "    \"\"\"\n",
    "    print(\"üéØ Starting Enhanced LightGCN Experiments with Result Saving...\")\n",
    "\n",
    "    # 1. Setup\n",
    "    config = ExperimentConfig()\n",
    "    print(f\"üìÅ All results will be saved to: {config.results_dir}\")\n",
    "\n",
    "    # 2. Load and process data\n",
    "    data_processor = SpotifyDataProcessor(config)\n",
    "    data = data_processor.load_and_process_data(data_path, seed=42)\n",
    "\n",
    "    # 3. Run experiments\n",
    "    experiment_runner = ExperimentRunner(config, data)\n",
    "    results = experiment_runner.run_all_experiments()\n",
    "\n",
    "    # 4. Final summary\n",
    "    if results:\n",
    "        print(\"\\nüéâ All experiments completed successfully!\")\n",
    "\n",
    "        print(f\"\\nüìã FINAL SUMMARY:\")\n",
    "        print(f\"   üî¨ Configurations tested: {len(results)}\")\n",
    "        print(f\"   üìÅ Results directory: {config.results_dir}\")\n",
    "        print(f\"   üïê Experiment timestamp: {experiment_runner.experiment_timestamp}\")\n",
    "\n",
    "        # List saved files\n",
    "        saved_files = []\n",
    "        for root, dirs, files in os.walk(config.results_dir):\n",
    "            for file in files:\n",
    "                if experiment_runner.experiment_timestamp in file:\n",
    "                    saved_files.append(os.path.join(root, file))\n",
    "\n",
    "        print(f\"\\nüìÑ Generated {len(saved_files)} files:\")\n",
    "        for file_path in sorted(saved_files)[:10]:\n",
    "            rel_path = os.path.relpath(file_path, config.results_dir)\n",
    "            print(f\"   üìÑ {rel_path}\")\n",
    "\n",
    "        if len(saved_files) > 10:\n",
    "            print(f\"   ... and {len(saved_files) - 10} more files\")\n",
    "\n",
    "        return results\n",
    "    else:\n",
    "        print(\"\\n‚ùå Experiments failed!\")\n",
    "        return None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üéØ Enhanced LightGCN Experiments with Comprehensive Result Saving\")\n",
    "    print(\"\\nüìã EXPERIMENTAL DESIGN:\")\n",
    "    print(\"   Phase 1: Graph Structure Ablation (4 configurations)\")\n",
    "    print(\"      ‚Ä¢ baseline: playlist_track only\")\n",
    "    print(\"      ‚Ä¢ with_artists: + track_artist edges\")\n",
    "    print(\"      ‚Ä¢ with_users: + user_playlist edges\")\n",
    "    print(\"      ‚Ä¢ full_graph: all edge types\")\n",
    "    print(\"\\n   Phase 2: Feature Importance Analysis (4 configurations)\")\n",
    "    print(\"      ‚Ä¢ playlist_features: baseline graph + playlist features (6D)\")\n",
    "    print(\"      ‚Ä¢ track_features: baseline graph + track features (4D)\")\n",
    "    print(\"      ‚Ä¢ user_features: baseline graph + user features (4D)\")\n",
    "    print(\"      ‚Ä¢ all_features: baseline graph + all feature types\")\n",
    "\n",
    "    results = run_lightgcn_experiments(\n",
    "        data_path=\"../data/processed/spotify_scaled_hybrid_tiny.json\"\n",
    "    )\n",
    "\n",
    "    if results:\n",
    "        print(\"\\nüéâ Enhanced LightGCN experiments completed successfully!\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå Experiments failed! Check error messages above.\")"
   ],
   "id": "a9585695f66ec3c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Enhanced LightGCN Experiments with Comprehensive Result Saving\n",
      "\n",
      "üìã EXPERIMENTAL DESIGN:\n",
      "   Phase 1: Graph Structure Ablation (4 configurations)\n",
      "      ‚Ä¢ baseline: playlist_track only\n",
      "      ‚Ä¢ with_artists: + track_artist edges\n",
      "      ‚Ä¢ with_users: + user_playlist edges\n",
      "      ‚Ä¢ full_graph: all edge types\n",
      "\n",
      "   Phase 2: Feature Importance Analysis (4 configurations)\n",
      "      ‚Ä¢ playlist_features: baseline graph + playlist features (6D)\n",
      "      ‚Ä¢ track_features: baseline graph + track features (4D)\n",
      "      ‚Ä¢ user_features: baseline graph + user features (4D)\n",
      "      ‚Ä¢ all_features: baseline graph + all feature types\n",
      "üéØ Starting Enhanced LightGCN Experiments with Result Saving...\n",
      "üìÅ Result directories created in: ../results/lightgcn_experiments_enhanced\n",
      "üéØ Experiment Configuration:\n",
      "   üì± Device: cpu\n",
      "   üé≤ Seeds: 5 seeds\n",
      "   üìä Target playlists: 1,500\n",
      "   üß† Embedding dim: 128\n",
      "   ‚ö° Learning rate: 0.0005\n",
      "   üõ°Ô∏è Regularization: 0.001\n",
      "   üíæ Results dir: ../results/lightgcn_experiments_enhanced\n",
      "üìÅ All results will be saved to: ../results/lightgcn_experiments_enhanced\n",
      "üéµ Loading Spotify data from: ../data/processed/spotify_scaled_hybrid_tiny.json\n",
      "‚úÖ Loaded 299 playlists\n",
      "üìä Dataset statistics:\n",
      "   ‚Ä¢ Playlists: 299\n",
      "   ‚Ä¢ Tracks: 10,631\n",
      "   ‚Ä¢ Artists: 4,164\n",
      "   ‚Ä¢ Albums: 6,966\n",
      "   ‚Ä¢ Users: 252\n",
      "üìà Extracted edges:\n",
      "   ‚Ä¢ playlist_track: 13,107 edges\n",
      "   ‚Ä¢ track_artist: 10,631 edges\n",
      "   ‚Ä¢ user_playlist: 299 edges\n",
      "   ‚Ä¢ track_album: 10,631 edges\n",
      "üìã Data splits:\n",
      "   ‚Ä¢ Train: 9,174 edges (70.0%)\n",
      "   ‚Ä¢ Validation: 1,966 edges (15.0%)\n",
      "   ‚Ä¢ Test: 1,967 edges (15.0%)\n",
      "üé® Generated features:\n",
      "   ‚Ä¢ playlist: (299, 6)\n",
      "   ‚Ä¢ track: (10631, 4)\n",
      "   ‚Ä¢ user: (252, 4)\n",
      "   ‚Ä¢ artist: (4164, 4)\n",
      "   ‚Ä¢ album: (6966, 4)\n",
      "üéØ Model Trainer initialized:\n",
      "   üë• Playlists: 299\n",
      "   üéµ Tracks: 10,631\n",
      "   üë§ Users: 252\n",
      "üéØ EXPERIMENT RUNNER INITIALIZED\n",
      "   üìä Dataset: 299 playlists\n",
      "   üé≤ Seeds per config: 5\n",
      "   üìÅ Results dir: ../results/lightgcn_experiments_enhanced\n",
      "   üïê Timestamp: 20250816_211920\n",
      "\n",
      "================================================================================\n",
      "üî¨ STARTING LIGHTGCN EXPERIMENTS WITH RESULT SAVING\n",
      "================================================================================\n",
      "\n",
      "üî¨ Running 8 configurations:\n",
      "   ‚Ä¢ baseline: Playlist-track edges only\n",
      "   ‚Ä¢ with_artists: Add track-artist relationships\n",
      "   ‚Ä¢ with_users: Add user-playlist relationships\n",
      "   ‚Ä¢ full_graph: All edge types\n",
      "   ‚Ä¢ playlist_features: Only playlist features (6D) on baseline graph\n",
      "   ‚Ä¢ track_features: Only track features (4D) on baseline graph\n",
      "   ‚Ä¢ user_features: Only user features (4D) on baseline graph\n",
      "   ‚Ä¢ all_features: All feature types combined on baseline graph\n",
      "üíæ Experiment configuration saved: experiment_config_20250816_211920.json\n",
      "\n",
      "============================================================\n",
      "üß™ Configuration: Baseline\n",
      "üìù Playlist-track edges only\n",
      "\n",
      "üé≤ Seed 1/5 (seed=42):\n",
      "\n",
      "üöÄ Training: Baseline (seed=42)\n",
      "   üìù Playlist-track edges only\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3601, Val=0.4914\n",
      "      Epoch 100: Train=0.3604, Val=0.5454\n",
      "      Epoch 150: Train=0.3561, Val=0.5895\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: Baseline_seed42_20250816_211920.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.5109, AUC: 0.7687\n",
      "      üìä NDCG@10: 0.5109\n",
      "      üìä AUC: 0.7687\n",
      "      ‚è±Ô∏è Time: 715.7s\n",
      "\n",
      "üé≤ Seed 2/5 (seed=123):\n",
      "\n",
      "üöÄ Training: Baseline (seed=123)\n",
      "   üìù Playlist-track edges only\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3590, Val=0.4925\n",
      "      Epoch 100: Train=0.3595, Val=0.5422\n",
      "      Epoch 150: Train=0.3564, Val=0.5877\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: Baseline_seed123_20250816_213116.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.5151, AUC: 0.7727\n",
      "      üìä NDCG@10: 0.5151\n",
      "      üìä AUC: 0.7727\n",
      "      ‚è±Ô∏è Time: 665.2s\n",
      "\n",
      "üé≤ Seed 3/5 (seed=456):\n",
      "\n",
      "üöÄ Training: Baseline (seed=456)\n",
      "   üìù Playlist-track edges only\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3599, Val=0.4950\n",
      "      Epoch 100: Train=0.3596, Val=0.5433\n",
      "      Epoch 150: Train=0.3559, Val=0.5973\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: Baseline_seed456_20250816_214222.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.5214, AUC: 0.7704\n",
      "      üìä NDCG@10: 0.5214\n",
      "      üìä AUC: 0.7704\n",
      "      ‚è±Ô∏è Time: 1830.6s\n",
      "\n",
      "üé≤ Seed 4/5 (seed=789):\n",
      "\n",
      "üöÄ Training: Baseline (seed=789)\n",
      "   üìù Playlist-track edges only\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3603, Val=0.4925\n",
      "      Epoch 100: Train=0.3601, Val=0.5425\n",
      "      Epoch 150: Train=0.3560, Val=0.5868\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: Baseline_seed789_20250816_221254.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.5306, AUC: 0.7764\n",
      "      üìä NDCG@10: 0.5306\n",
      "      üìä AUC: 0.7764\n",
      "      ‚è±Ô∏è Time: 1730.9s\n",
      "\n",
      "üé≤ Seed 5/5 (seed=999):\n",
      "\n",
      "üöÄ Training: Baseline (seed=999)\n",
      "   üìù Playlist-track edges only\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3602, Val=0.4941\n",
      "      Epoch 100: Train=0.3604, Val=0.5493\n",
      "      Epoch 150: Train=0.3565, Val=0.5918\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: Baseline_seed999_20250816_224145.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.5364, AUC: 0.7730\n",
      "      üìä NDCG@10: 0.5364\n",
      "      üìä AUC: 0.7730\n",
      "      ‚è±Ô∏è Time: 854.2s\n",
      "\n",
      "   üìä CONFIGURATION SUMMARY: Baseline\n",
      "      NDCG@10: 0.5229 ¬± 0.0106\n",
      "      ‚úÖ Results saved for baseline\n",
      "   üíæ Saved baseline results\n",
      "\n",
      "============================================================\n",
      "üß™ Configuration: With Artists\n",
      "üìù Add track-artist relationships\n",
      "\n",
      "üé≤ Seed 1/5 (seed=42):\n",
      "\n",
      "üöÄ Training: With Artists (seed=42)\n",
      "   üìù Add track-artist relationships\n",
      "   üîó Building adjacency matrix: ['playlist_track', 'track_artist']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      üìä Adding track_artist: 10,631 edges\n",
      "      ‚úÖ Total edges: 47,476\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 69788\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3590, Val=0.5204\n",
      "      Epoch 100: Train=0.3576, Val=0.6034\n",
      "      Epoch 150: Train=0.3520, Val=0.6551\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: With Artists_seed42_20250816_225600.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.3979, AUC: 0.6648\n",
      "      üìä NDCG@10: 0.3979\n",
      "      üìä AUC: 0.6648\n",
      "      ‚è±Ô∏è Time: 1036.1s\n",
      "\n",
      "üé≤ Seed 2/5 (seed=123):\n",
      "\n",
      "üöÄ Training: With Artists (seed=123)\n",
      "   üìù Add track-artist relationships\n",
      "   üîó Building adjacency matrix: ['playlist_track', 'track_artist']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      üìä Adding track_artist: 10,631 edges\n",
      "      ‚úÖ Total edges: 47,476\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 69788\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3581, Val=0.5216\n",
      "      Epoch 100: Train=0.3565, Val=0.5984\n",
      "      Epoch 150: Train=0.3525, Val=0.6527\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: With Artists_seed123_20250816_231317.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.4006, AUC: 0.6690\n",
      "      üìä NDCG@10: 0.4006\n",
      "      üìä AUC: 0.6690\n",
      "      ‚è±Ô∏è Time: 1005.5s\n",
      "\n",
      "üé≤ Seed 3/5 (seed=456):\n",
      "\n",
      "üöÄ Training: With Artists (seed=456)\n",
      "   üìù Add track-artist relationships\n",
      "   üîó Building adjacency matrix: ['playlist_track', 'track_artist']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      üìä Adding track_artist: 10,631 edges\n",
      "      ‚úÖ Total edges: 47,476\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 69788\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3587, Val=0.5246\n",
      "      Epoch 100: Train=0.3569, Val=0.6012\n",
      "      Epoch 150: Train=0.3520, Val=0.6621\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: With Artists_seed456_20250816_233004.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.4043, AUC: 0.6691\n",
      "      üìä NDCG@10: 0.4043\n",
      "      üìä AUC: 0.6691\n",
      "      ‚è±Ô∏è Time: 1178.8s\n",
      "\n",
      "üé≤ Seed 4/5 (seed=789):\n",
      "\n",
      "üöÄ Training: With Artists (seed=789)\n",
      "   üìù Add track-artist relationships\n",
      "   üîó Building adjacency matrix: ['playlist_track', 'track_artist']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      üìä Adding track_artist: 10,631 edges\n",
      "      ‚úÖ Total edges: 47,476\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 69788\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3590, Val=0.5225\n",
      "      Epoch 100: Train=0.3572, Val=0.5995\n",
      "      Epoch 150: Train=0.3522, Val=0.6523\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: With Artists_seed789_20250816_234943.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.3994, AUC: 0.6745\n",
      "      üìä NDCG@10: 0.3994\n",
      "      üìä AUC: 0.6745\n",
      "      ‚è±Ô∏è Time: 968.4s\n",
      "\n",
      "üé≤ Seed 5/5 (seed=999):\n",
      "\n",
      "üöÄ Training: With Artists (seed=999)\n",
      "   üìù Add track-artist relationships\n",
      "   üîó Building adjacency matrix: ['playlist_track', 'track_artist']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      üìä Adding track_artist: 10,631 edges\n",
      "      ‚úÖ Total edges: 47,476\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 69788\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3593, Val=0.5234\n",
      "      Epoch 100: Train=0.3574, Val=0.6062\n",
      "      Epoch 150: Train=0.3525, Val=0.6560\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: With Artists_seed999_20250817_000552.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.4075, AUC: 0.6667\n",
      "      üìä NDCG@10: 0.4075\n",
      "      üìä AUC: 0.6667\n",
      "      ‚è±Ô∏è Time: 1448.1s\n",
      "\n",
      "   üìä CONFIGURATION SUMMARY: With Artists\n",
      "      NDCG@10: 0.4019 ¬± 0.0039\n",
      "      ‚úÖ Results saved for with_artists\n",
      "   üíæ Saved with_artists results\n",
      "\n",
      "============================================================\n",
      "üß™ Configuration: With Users\n",
      "üìù Add user-playlist relationships\n",
      "\n",
      "üé≤ Seed 1/5 (seed=42):\n",
      "\n",
      "üöÄ Training: With Users (seed=42)\n",
      "   üìù Add user-playlist relationships\n",
      "   üîó Building adjacency matrix: ['playlist_track', 'user_playlist']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      üìä Adding user_playlist: 299 edges\n",
      "      ‚úÖ Total edges: 26,812\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 49124\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3600, Val=0.4937\n",
      "      Epoch 100: Train=0.3602, Val=0.5505\n",
      "      Epoch 150: Train=0.3558, Val=0.5969\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: With Users_seed42_20250817_003002.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.4978, AUC: 0.7584\n",
      "      üìä NDCG@10: 0.4978\n",
      "      üìä AUC: 0.7584\n",
      "      ‚è±Ô∏è Time: 1214.9s\n",
      "\n",
      "üé≤ Seed 2/5 (seed=123):\n",
      "\n",
      "üöÄ Training: With Users (seed=123)\n",
      "   üìù Add user-playlist relationships\n",
      "   üîó Building adjacency matrix: ['playlist_track', 'user_playlist']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      üìä Adding user_playlist: 299 edges\n",
      "      ‚úÖ Total edges: 26,812\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 49124\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3590, Val=0.4942\n",
      "      Epoch 100: Train=0.3594, Val=0.5470\n",
      "      Epoch 150: Train=0.3561, Val=0.5949\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: With Users_seed123_20250817_005017.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.5039, AUC: 0.7629\n",
      "      üìä NDCG@10: 0.5039\n",
      "      üìä AUC: 0.7629\n",
      "      ‚è±Ô∏è Time: 1279.0s\n",
      "\n",
      "üé≤ Seed 3/5 (seed=456):\n",
      "\n",
      "üöÄ Training: With Users (seed=456)\n",
      "   üìù Add user-playlist relationships\n",
      "   üîó Building adjacency matrix: ['playlist_track', 'user_playlist']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      üìä Adding user_playlist: 299 edges\n",
      "      ‚úÖ Total edges: 26,812\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 49124\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3599, Val=0.4974\n",
      "      Epoch 100: Train=0.3594, Val=0.5487\n",
      "      Epoch 150: Train=0.3556, Val=0.6048\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: With Users_seed456_20250817_011137.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.5053, AUC: 0.7604\n",
      "      üìä NDCG@10: 0.5053\n",
      "      üìä AUC: 0.7604\n",
      "      ‚è±Ô∏è Time: 1712.6s\n",
      "\n",
      "üé≤ Seed 4/5 (seed=789):\n",
      "\n",
      "üöÄ Training: With Users (seed=789)\n",
      "   üìù Add user-playlist relationships\n",
      "   üîó Building adjacency matrix: ['playlist_track', 'user_playlist']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      üìä Adding user_playlist: 299 edges\n",
      "      ‚úÖ Total edges: 26,812\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 49124\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3603, Val=0.4946\n",
      "      Epoch 100: Train=0.3600, Val=0.5477\n",
      "      Epoch 150: Train=0.3557, Val=0.5943\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: With Users_seed789_20250817_014010.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.5173, AUC: 0.7671\n",
      "      üìä NDCG@10: 0.5173\n",
      "      üìä AUC: 0.7671\n",
      "      ‚è±Ô∏è Time: 971.1s\n",
      "\n",
      "üé≤ Seed 5/5 (seed=999):\n",
      "\n",
      "üöÄ Training: With Users (seed=999)\n",
      "   üìù Add user-playlist relationships\n",
      "   üîó Building adjacency matrix: ['playlist_track', 'user_playlist']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      üìä Adding user_playlist: 299 edges\n",
      "      ‚úÖ Total edges: 26,812\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 49124\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3602, Val=0.4962\n",
      "      Epoch 100: Train=0.3603, Val=0.5542\n",
      "      Epoch 150: Train=0.3562, Val=0.5988\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: With Users_seed999_20250817_015622.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.5224, AUC: 0.7635\n",
      "      üìä NDCG@10: 0.5224\n",
      "      üìä AUC: 0.7635\n",
      "      ‚è±Ô∏è Time: 641.3s\n",
      "\n",
      "   üìä CONFIGURATION SUMMARY: With Users\n",
      "      NDCG@10: 0.5093 ¬± 0.0102\n",
      "      ‚úÖ Results saved for with_users\n",
      "   üíæ Saved with_users results\n",
      "\n",
      "============================================================\n",
      "üß™ Configuration: Full Graph\n",
      "üìù All edge types\n",
      "\n",
      "üé≤ Seed 1/5 (seed=42):\n",
      "\n",
      "üöÄ Training: Full Graph (seed=42)\n",
      "   üìù All edge types\n",
      "   üîó Building adjacency matrix: ['playlist_track', 'track_artist', 'user_playlist', 'track_album']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      üìä Adding track_artist: 10,631 edges\n",
      "      üìä Adding user_playlist: 299 edges\n",
      "      üìä Adding track_album: 10,631 edges\n",
      "      ‚úÖ Total edges: 69,336\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 91648\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3605, Val=0.5469\n",
      "      Epoch 100: Train=0.3584, Val=0.6341\n",
      "      Epoch 150: Train=0.3527, Val=0.6733\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: Full Graph_seed42_20250817_020704.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.3330, AUC: 0.6178\n",
      "      üìä NDCG@10: 0.3330\n",
      "      üìä AUC: 0.6178\n",
      "      ‚è±Ô∏è Time: 1506.4s\n",
      "\n",
      "üé≤ Seed 2/5 (seed=123):\n",
      "\n",
      "üöÄ Training: Full Graph (seed=123)\n",
      "   üìù All edge types\n",
      "   üîó Building adjacency matrix: ['playlist_track', 'track_artist', 'user_playlist', 'track_album']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      üìä Adding track_artist: 10,631 edges\n",
      "      üìä Adding user_playlist: 299 edges\n",
      "      üìä Adding track_album: 10,631 edges\n",
      "      ‚úÖ Total edges: 69,336\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 91648\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3597, Val=0.5482\n",
      "      Epoch 100: Train=0.3576, Val=0.6299\n",
      "      Epoch 150: Train=0.3533, Val=0.6726\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: Full Graph_seed123_20250817_023211.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.3344, AUC: 0.6181\n",
      "      üìä NDCG@10: 0.3344\n",
      "      üìä AUC: 0.6181\n",
      "      ‚è±Ô∏è Time: 1001.5s\n",
      "\n",
      "üé≤ Seed 3/5 (seed=456):\n",
      "\n",
      "üöÄ Training: Full Graph (seed=456)\n",
      "   üìù All edge types\n",
      "   üîó Building adjacency matrix: ['playlist_track', 'track_artist', 'user_playlist', 'track_album']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      üìä Adding track_artist: 10,631 edges\n",
      "      üìä Adding user_playlist: 299 edges\n",
      "      üìä Adding track_album: 10,631 edges\n",
      "      ‚úÖ Total edges: 69,336\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 91648\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3603, Val=0.5496\n",
      "      Epoch 100: Train=0.3580, Val=0.6305\n",
      "      Epoch 150: Train=0.3528, Val=0.6805\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: Full Graph_seed456_20250817_024854.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.3407, AUC: 0.6242\n",
      "      üìä NDCG@10: 0.3407\n",
      "      üìä AUC: 0.6242\n",
      "      ‚è±Ô∏è Time: 1394.8s\n",
      "\n",
      "üé≤ Seed 4/5 (seed=789):\n",
      "\n",
      "üöÄ Training: Full Graph (seed=789)\n",
      "   üìù All edge types\n",
      "   üîó Building adjacency matrix: ['playlist_track', 'track_artist', 'user_playlist', 'track_album']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      üìä Adding track_artist: 10,631 edges\n",
      "      üìä Adding user_playlist: 299 edges\n",
      "      üìä Adding track_album: 10,631 edges\n",
      "      ‚úÖ Total edges: 69,336\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 91648\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3608, Val=0.5463\n",
      "      Epoch 100: Train=0.3579, Val=0.6292\n",
      "      Epoch 150: Train=0.3531, Val=0.6704\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: Full Graph_seed789_20250817_031209.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.3409, AUC: 0.6264\n",
      "      üìä NDCG@10: 0.3409\n",
      "      üìä AUC: 0.6264\n",
      "      ‚è±Ô∏è Time: 2008.6s\n",
      "\n",
      "üé≤ Seed 5/5 (seed=999):\n",
      "\n",
      "üöÄ Training: Full Graph (seed=999)\n",
      "   üìù All edge types\n",
      "   üîó Building adjacency matrix: ['playlist_track', 'track_artist', 'user_playlist', 'track_album']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      üìä Adding track_artist: 10,631 edges\n",
      "      üìä Adding user_playlist: 299 edges\n",
      "      üìä Adding track_album: 10,631 edges\n",
      "      ‚úÖ Total edges: 69,336\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 91648\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3608, Val=0.5490\n",
      "      Epoch 100: Train=0.3584, Val=0.6366\n",
      "      Epoch 150: Train=0.3532, Val=0.6746\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: Full Graph_seed999_20250817_034538.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.3461, AUC: 0.6165\n",
      "      üìä NDCG@10: 0.3461\n",
      "      üìä AUC: 0.6165\n",
      "      ‚è±Ô∏è Time: 1552.5s\n",
      "\n",
      "   üìä CONFIGURATION SUMMARY: Full Graph\n",
      "      NDCG@10: 0.3390 ¬± 0.0054\n",
      "      ‚úÖ Results saved for full_graph\n",
      "   üíæ Saved full_graph results\n",
      "\n",
      "============================================================\n",
      "üß™ Configuration: Playlist Features\n",
      "üìù Only playlist features (6D) on baseline graph\n",
      "\n",
      "üé≤ Seed 1/5 (seed=42):\n",
      "\n",
      "üöÄ Training: Playlist Features (seed=42)\n",
      "   üìù Only playlist features (6D) on baseline graph\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üîß Building features: ['playlist']\n",
      "      üé® Building playlist features...\n",
      "      ‚úÖ Playlist features: torch.Size([299, 6])\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:True, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3876, Val=0.4543\n",
      "      Epoch 100: Train=0.3691, Val=0.5148\n",
      "      Epoch 150: Train=0.3588, Val=0.5670\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: Playlist Features_seed42_20250817_041132.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.5265, AUC: 0.7961\n",
      "      üìä NDCG@10: 0.5265\n",
      "      üìä AUC: 0.7961\n",
      "      ‚è±Ô∏è Time: 1727.9s\n",
      "\n",
      "üé≤ Seed 2/5 (seed=123):\n",
      "\n",
      "üöÄ Training: Playlist Features (seed=123)\n",
      "   üìù Only playlist features (6D) on baseline graph\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üîß Building features: ['playlist']\n",
      "      üé® Building playlist features...\n",
      "      ‚úÖ Playlist features: torch.Size([299, 6])\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:True, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3854, Val=0.4541\n",
      "      Epoch 100: Train=0.3697, Val=0.5141\n",
      "      Epoch 150: Train=0.3588, Val=0.5679\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: Playlist Features_seed123_20250817_044020.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.5314, AUC: 0.8015\n",
      "      üìä NDCG@10: 0.5314\n",
      "      üìä AUC: 0.8015\n",
      "      ‚è±Ô∏è Time: 885.1s\n",
      "\n",
      "üé≤ Seed 3/5 (seed=456):\n",
      "\n",
      "üöÄ Training: Playlist Features (seed=456)\n",
      "   üìù Only playlist features (6D) on baseline graph\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üîß Building features: ['playlist']\n",
      "      üé® Building playlist features...\n",
      "      ‚úÖ Playlist features: torch.Size([299, 6])\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:True, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3867, Val=0.4591\n",
      "      Epoch 100: Train=0.3699, Val=0.5134\n",
      "      Epoch 150: Train=0.3591, Val=0.5730\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: Playlist Features_seed456_20250817_045506.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.5456, AUC: 0.8051\n",
      "      üìä NDCG@10: 0.5456\n",
      "      üìä AUC: 0.8051\n",
      "      ‚è±Ô∏è Time: 1958.0s\n",
      "\n",
      "üé≤ Seed 4/5 (seed=789):\n",
      "\n",
      "üöÄ Training: Playlist Features (seed=789)\n",
      "   üìù Only playlist features (6D) on baseline graph\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üîß Building features: ['playlist']\n",
      "      üé® Building playlist features...\n",
      "      ‚úÖ Playlist features: torch.Size([299, 6])\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:True, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3869, Val=0.4564\n",
      "      Epoch 100: Train=0.3693, Val=0.5134\n",
      "      Epoch 150: Train=0.3587, Val=0.5669\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: Playlist Features_seed789_20250817_052745.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.5336, AUC: 0.7991\n",
      "      üìä NDCG@10: 0.5336\n",
      "      üìä AUC: 0.7991\n",
      "      ‚è±Ô∏è Time: 1329.3s\n",
      "\n",
      "üé≤ Seed 5/5 (seed=999):\n",
      "\n",
      "üöÄ Training: Playlist Features (seed=999)\n",
      "   üìù Only playlist features (6D) on baseline graph\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üîß Building features: ['playlist']\n",
      "      üé® Building playlist features...\n",
      "      ‚úÖ Playlist features: torch.Size([299, 6])\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:True, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3871, Val=0.4551\n",
      "      Epoch 100: Train=0.3706, Val=0.5199\n",
      "      Epoch 150: Train=0.3590, Val=0.5722\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: Playlist Features_seed999_20250817_054955.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.5502, AUC: 0.8008\n",
      "      üìä NDCG@10: 0.5502\n",
      "      üìä AUC: 0.8008\n",
      "      ‚è±Ô∏è Time: 1731.3s\n",
      "\n",
      "   üìä CONFIGURATION SUMMARY: Playlist Features\n",
      "      NDCG@10: 0.5375 ¬± 0.0100\n",
      "      ‚úÖ Results saved for playlist_features\n",
      "   üíæ Saved playlist_features results\n",
      "\n",
      "============================================================\n",
      "üß™ Configuration: Track Features\n",
      "üìù Only track features (4D) on baseline graph\n",
      "\n",
      "üé≤ Seed 1/5 (seed=42):\n",
      "\n",
      "üöÄ Training: Track Features (seed=42)\n",
      "   üìù Only track features (4D) on baseline graph\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üîß Building features: ['track']\n",
      "      üé® Building track features...\n",
      "      ‚úÖ Track features: torch.Size([10631, 4])\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:True, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3951, Val=0.5598\n",
      "      Epoch 100: Train=0.3702, Val=0.5967\n",
      "      Epoch 150: Train=0.3580, Val=0.6357\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: Track Features_seed42_20250817_061847.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.4272, AUC: 0.7062\n",
      "      üìä NDCG@10: 0.4272\n",
      "      üìä AUC: 0.7062\n",
      "      ‚è±Ô∏è Time: 1663.6s\n",
      "\n",
      "üé≤ Seed 2/5 (seed=123):\n",
      "\n",
      "üöÄ Training: Track Features (seed=123)\n",
      "   üìù Only track features (4D) on baseline graph\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üîß Building features: ['track']\n",
      "      üé® Building track features...\n",
      "      ‚úÖ Track features: torch.Size([10631, 4])\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:True, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3962, Val=0.5637\n",
      "      Epoch 100: Train=0.3697, Val=0.5936\n",
      "      Epoch 150: Train=0.3592, Val=0.6339\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: Track Features_seed123_20250817_064631.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.4402, AUC: 0.7062\n",
      "      üìä NDCG@10: 0.4402\n",
      "      üìä AUC: 0.7062\n",
      "      ‚è±Ô∏è Time: 2045.8s\n",
      "\n",
      "üé≤ Seed 3/5 (seed=456):\n",
      "\n",
      "üöÄ Training: Track Features (seed=456)\n",
      "   üìù Only track features (4D) on baseline graph\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üîß Building features: ['track']\n",
      "      üé® Building track features...\n",
      "      ‚úÖ Track features: torch.Size([10631, 4])\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:True, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3946, Val=0.5690\n",
      "      Epoch 100: Train=0.3694, Val=0.5979\n",
      "      Epoch 150: Train=0.3588, Val=0.6420\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: Track Features_seed456_20250817_072038.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.4455, AUC: 0.7054\n",
      "      üìä NDCG@10: 0.4455\n",
      "      üìä AUC: 0.7054\n",
      "      ‚è±Ô∏è Time: 3001.9s\n",
      "\n",
      "üé≤ Seed 4/5 (seed=789):\n",
      "\n",
      "üöÄ Training: Track Features (seed=789)\n",
      "   üìù Only track features (4D) on baseline graph\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üîß Building features: ['track']\n",
      "      üé® Building track features...\n",
      "      ‚úÖ Track features: torch.Size([10631, 4])\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:True, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3965, Val=0.5665\n",
      "      Epoch 100: Train=0.3699, Val=0.5982\n",
      "      Epoch 150: Train=0.3586, Val=0.6329\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: Track Features_seed789_20250817_081040.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.4512, AUC: 0.7071\n",
      "      üìä NDCG@10: 0.4512\n",
      "      üìä AUC: 0.7071\n",
      "      ‚è±Ô∏è Time: 1398.1s\n",
      "\n",
      "üé≤ Seed 5/5 (seed=999):\n",
      "\n",
      "üöÄ Training: Track Features (seed=999)\n",
      "   üìù Only track features (4D) on baseline graph\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üîß Building features: ['track']\n",
      "      üé® Building track features...\n",
      "      ‚úÖ Track features: torch.Size([10631, 4])\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:True, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3943, Val=0.5617\n",
      "      Epoch 100: Train=0.3704, Val=0.6046\n",
      "      Epoch 150: Train=0.3590, Val=0.6416\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: Track Features_seed999_20250817_083359.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.4447, AUC: 0.6995\n",
      "      üìä NDCG@10: 0.4447\n",
      "      üìä AUC: 0.6995\n",
      "      ‚è±Ô∏è Time: 2075.9s\n",
      "\n",
      "   üìä CONFIGURATION SUMMARY: Track Features\n",
      "      NDCG@10: 0.4418 ¬± 0.0090\n",
      "      ‚úÖ Results saved for track_features\n",
      "   üíæ Saved track_features results\n",
      "\n",
      "============================================================\n",
      "üß™ Configuration: User Features\n",
      "üìù Only user features (4D) on baseline graph\n",
      "\n",
      "üé≤ Seed 1/5 (seed=42):\n",
      "\n",
      "üöÄ Training: User Features (seed=42)\n",
      "   üìù Only user features (4D) on baseline graph\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üîß Building features: ['user']\n",
      "      üé® Building user features...\n",
      "      ‚úÖ User features: torch.Size([252, 4])\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:True\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3616, Val=0.4916\n",
      "      Epoch 100: Train=0.3600, Val=0.5470\n",
      "      Epoch 150: Train=0.3555, Val=0.5896\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: User Features_seed42_20250817_090836.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.5083, AUC: 0.7692\n",
      "      üìä NDCG@10: 0.5083\n",
      "      üìä AUC: 0.7692\n",
      "      ‚è±Ô∏è Time: 1951.1s\n",
      "\n",
      "üé≤ Seed 2/5 (seed=123):\n",
      "\n",
      "üöÄ Training: User Features (seed=123)\n",
      "   üìù Only user features (4D) on baseline graph\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üîß Building features: ['user']\n",
      "      üé® Building user features...\n",
      "      ‚úÖ User features: torch.Size([252, 4])\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:True\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3606, Val=0.4928\n",
      "      Epoch 100: Train=0.3595, Val=0.5440\n",
      "      Epoch 150: Train=0.3562, Val=0.5901\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: User Features_seed123_20250817_094108.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.5124, AUC: 0.7683\n",
      "      üìä NDCG@10: 0.5124\n",
      "      üìä AUC: 0.7683\n",
      "      ‚è±Ô∏è Time: 2418.5s\n",
      "\n",
      "üé≤ Seed 3/5 (seed=456):\n",
      "\n",
      "üöÄ Training: User Features (seed=456)\n",
      "   üìù Only user features (4D) on baseline graph\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üîß Building features: ['user']\n",
      "      üé® Building user features...\n",
      "      ‚úÖ User features: torch.Size([252, 4])\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:True\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3621, Val=0.4946\n",
      "      Epoch 100: Train=0.3599, Val=0.5437\n",
      "      Epoch 150: Train=0.3560, Val=0.5971\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: User Features_seed456_20250817_102127.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.5217, AUC: 0.7701\n",
      "      üìä NDCG@10: 0.5217\n",
      "      üìä AUC: 0.7701\n",
      "      ‚è±Ô∏è Time: 1754.3s\n",
      "\n",
      "üé≤ Seed 4/5 (seed=789):\n",
      "\n",
      "üöÄ Training: User Features (seed=789)\n",
      "   üìù Only user features (4D) on baseline graph\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üîß Building features: ['user']\n",
      "      üé® Building user features...\n",
      "      ‚úÖ User features: torch.Size([252, 4])\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:True\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3626, Val=0.4924\n",
      "      Epoch 100: Train=0.3597, Val=0.5416\n",
      "      Epoch 150: Train=0.3562, Val=0.5869\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: User Features_seed789_20250817_105042.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.5241, AUC: 0.7759\n",
      "      üìä NDCG@10: 0.5241\n",
      "      üìä AUC: 0.7759\n",
      "      ‚è±Ô∏è Time: 1912.3s\n",
      "\n",
      "üé≤ Seed 5/5 (seed=999):\n",
      "\n",
      "üöÄ Training: User Features (seed=999)\n",
      "   üìù Only user features (4D) on baseline graph\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üîß Building features: ['user']\n",
      "      üé® Building user features...\n",
      "      ‚úÖ User features: torch.Size([252, 4])\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:True\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3619, Val=0.4919\n",
      "      Epoch 100: Train=0.3602, Val=0.5493\n",
      "      Epoch 150: Train=0.3563, Val=0.5917\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: User Features_seed999_20250817_112235.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.5388, AUC: 0.7748\n",
      "      üìä NDCG@10: 0.5388\n",
      "      üìä AUC: 0.7748\n",
      "      ‚è±Ô∏è Time: 1671.6s\n",
      "\n",
      "   üìä CONFIGURATION SUMMARY: User Features\n",
      "      NDCG@10: 0.5210 ¬± 0.0119\n",
      "      ‚úÖ Results saved for user_features\n",
      "   üíæ Saved user_features results\n",
      "\n",
      "============================================================\n",
      "üß™ Configuration: All Features\n",
      "üìù All feature types combined on baseline graph\n",
      "\n",
      "üé≤ Seed 1/5 (seed=42):\n",
      "\n",
      "üöÄ Training: All Features (seed=42)\n",
      "   üìù All feature types combined on baseline graph\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üîß Building features: ['playlist', 'track', 'user']\n",
      "      üé® Building playlist features...\n",
      "      ‚úÖ Playlist features: torch.Size([299, 6])\n",
      "      üé® Building track features...\n",
      "      ‚úÖ Track features: torch.Size([10631, 4])\n",
      "      üé® Building user features...\n",
      "      ‚úÖ User features: torch.Size([252, 4])\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:True, T:True, U:True\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.4104, Val=0.5793\n",
      "      Epoch 100: Train=0.3753, Val=0.6081\n",
      "      Epoch 150: Train=0.3595, Val=0.6370\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: All Features_seed42_20250817_115027.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.4144, AUC: 0.6949\n",
      "      üìä NDCG@10: 0.4144\n",
      "      üìä AUC: 0.6949\n",
      "      ‚è±Ô∏è Time: 2911.4s\n",
      "\n",
      "üé≤ Seed 2/5 (seed=123):\n",
      "\n",
      "üöÄ Training: All Features (seed=123)\n",
      "   üìù All feature types combined on baseline graph\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üîß Building features: ['playlist', 'track', 'user']\n",
      "      üé® Building playlist features...\n",
      "      ‚úÖ Playlist features: torch.Size([299, 6])\n",
      "      üé® Building track features...\n",
      "      ‚úÖ Track features: torch.Size([10631, 4])\n",
      "      üé® Building user features...\n",
      "      ‚úÖ User features: torch.Size([252, 4])\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:True, T:True, U:True\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.4097, Val=0.5679\n",
      "      Epoch 100: Train=0.3759, Val=0.6101\n",
      "      Epoch 150: Train=0.3596, Val=0.6370\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: All Features_seed123_20250817_123859.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.4253, AUC: 0.7025\n",
      "      üìä NDCG@10: 0.4253\n",
      "      üìä AUC: 0.7025\n",
      "      ‚è±Ô∏è Time: 3741.2s\n",
      "\n",
      "üé≤ Seed 3/5 (seed=456):\n",
      "\n",
      "üöÄ Training: All Features (seed=456)\n",
      "   üìù All feature types combined on baseline graph\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üîß Building features: ['playlist', 'track', 'user']\n",
      "      üé® Building playlist features...\n",
      "      ‚úÖ Playlist features: torch.Size([299, 6])\n",
      "      üé® Building track features...\n",
      "      ‚úÖ Track features: torch.Size([10631, 4])\n",
      "      üé® Building user features...\n",
      "      ‚úÖ User features: torch.Size([252, 4])\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:True, T:True, U:True\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.4102, Val=0.5802\n",
      "      Epoch 100: Train=0.3746, Val=0.6129\n",
      "      Epoch 150: Train=0.3595, Val=0.6465\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: All Features_seed456_20250817_134121.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.4346, AUC: 0.7038\n",
      "      üìä NDCG@10: 0.4346\n",
      "      üìä AUC: 0.7038\n",
      "      ‚è±Ô∏è Time: 3045.3s\n",
      "\n",
      "üé≤ Seed 4/5 (seed=789):\n",
      "\n",
      "üöÄ Training: All Features (seed=789)\n",
      "   üìù All feature types combined on baseline graph\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üîß Building features: ['playlist', 'track', 'user']\n",
      "      üé® Building playlist features...\n",
      "      ‚úÖ Playlist features: torch.Size([299, 6])\n",
      "      üé® Building track features...\n",
      "      ‚úÖ Track features: torch.Size([10631, 4])\n",
      "      üé® Building user features...\n",
      "      ‚úÖ User features: torch.Size([252, 4])\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:True, T:True, U:True\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.4125, Val=0.5772\n",
      "      Epoch 100: Train=0.3749, Val=0.6081\n",
      "      Epoch 150: Train=0.3595, Val=0.6345\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: All Features_seed789_20250817_143207.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.4197, AUC: 0.7016\n",
      "      üìä NDCG@10: 0.4197\n",
      "      üìä AUC: 0.7016\n",
      "      ‚è±Ô∏è Time: 2084.2s\n",
      "\n",
      "üé≤ Seed 5/5 (seed=999):\n",
      "\n",
      "üöÄ Training: All Features (seed=999)\n",
      "   üìù All feature types combined on baseline graph\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üîß Building features: ['playlist', 'track', 'user']\n",
      "      üé® Building playlist features...\n",
      "      ‚úÖ Playlist features: torch.Size([299, 6])\n",
      "      üé® Building track features...\n",
      "      ‚úÖ Track features: torch.Size([10631, 4])\n",
      "      üé® Building user features...\n",
      "      ‚úÖ User features: torch.Size([252, 4])\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:True, T:True, U:True\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.4089, Val=0.5737\n",
      "      Epoch 100: Train=0.3758, Val=0.6141\n",
      "      Epoch 150: Train=0.3594, Val=0.6416\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: All Features_seed999_20250817_150652.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.4275, AUC: 0.6952\n",
      "      üìä NDCG@10: 0.4275\n",
      "      üìä AUC: 0.6952\n",
      "      ‚è±Ô∏è Time: 1296.6s\n",
      "\n",
      "   üìä CONFIGURATION SUMMARY: All Features\n",
      "      NDCG@10: 0.4243 ¬± 0.0077\n",
      "      ‚úÖ Results saved for all_features\n",
      "   üíæ Saved all_features results\n",
      "üì¶ Complete results saved: complete_results_20250816_211920.json\n",
      "\n",
      "================================================================================\n",
      "üìä EXPERIMENTAL RESULTS\n",
      "================================================================================\n",
      "\n",
      "Configuration                    NDCG@10 (Mean¬±Std)      AUC (Mean¬±Std)       Time (s)\n",
      "-------------------------------------------------------------------------------------\n",
      "playlist_features              0.5375¬±0.0100        0.8005¬±0.0033       1526.3\n",
      "baseline                       0.5229¬±0.0106        0.7722¬±0.0029       1159.3\n",
      "user_features                  0.5210¬±0.0119        0.7716¬±0.0034       1941.5\n",
      "with_users                     0.5093¬±0.0102        0.7625¬±0.0033       1163.8\n",
      "track_features                 0.4418¬±0.0090        0.7049¬±0.0031       2037.1\n",
      "all_features                   0.4243¬±0.0077        0.6996¬±0.0042       2615.7\n",
      "with_artists                   0.4019¬±0.0039        0.6688¬±0.0037       1127.4\n",
      "full_graph                     0.3390¬±0.0054        0.6206¬±0.0044       1492.8\n",
      "\n",
      "üèÜ BEST CONFIGURATION: playlist_features\n",
      "   üìä NDCG@10: 0.5375 ¬± 0.0100\n",
      "   üîç 95% CI: [0.5251, 0.5499]\n",
      "\n",
      "üí° PERFORMANCE INSIGHTS:\n",
      "   üéØ Feature Impact: +2.8% improvement\n",
      "      Best w/ features: playlist_features (0.5375)\n",
      "      Best w/o features: baseline (0.5229)\n",
      "\n",
      "================================================================================\n",
      "üî¨ STATISTICAL SIGNIFICANCE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Pairwise analysis (NDCG@10):\n",
      "Configuration 1          vs Configuration 2          p-value    Effect Size  Significant\n",
      "-----------------------------------------------------------------------------------------------\n",
      "baseline                  vs with_artists              0.0000      15.180(very large) ***\n",
      "baseline                  vs with_users                0.0723      1.309(very large) n.s.\n",
      "baseline                  vs full_graph                0.0000      21.940(very large) ***\n",
      "baseline                  vs playlist_features         0.0555      1.416(very large) n.s.\n",
      "baseline                  vs track_features            0.0000      8.261(very large) ***\n",
      "baseline                  vs user_features             0.8010      0.165(small) n.s.\n",
      "baseline                  vs all_features              0.0000      10.661(very large) ***\n",
      "with_artists              vs with_users                0.0000      13.962(very large) ***\n",
      "with_artists              vs full_graph                0.0000      13.458(very large) ***\n",
      "with_artists              vs playlist_features         0.0000      17.889(very large) ***\n",
      "with_artists              vs track_features            0.0000      5.740(very large) ***\n",
      "with_artists              vs user_features             0.0000      13.498(very large) ***\n",
      "with_artists              vs all_features              0.0004      3.668(very large) ***\n",
      "with_users                vs full_graph                0.0000      20.978(very large) ***\n",
      "with_users                vs playlist_features         0.0022      2.793(very large) **\n",
      "with_users                vs track_features            0.0000      7.039(very large) ***\n",
      "with_users                vs user_features             0.1319      1.061(very large) n.s.\n",
      "with_users                vs all_features              0.0000      9.436(very large) ***\n",
      "full_graph                vs playlist_features         0.0000      24.778(very large) ***\n",
      "full_graph                vs track_features            0.0000      13.872(very large) ***\n",
      "full_graph                vs user_features             0.0000      19.789(very large) ***\n",
      "full_graph                vs all_features              0.0000      12.871(very large) ***\n",
      "playlist_features         vs track_features            0.0000      10.067(very large) ***\n",
      "playlist_features         vs user_features             0.0454      1.498(very large) *\n",
      "playlist_features         vs all_features              0.0000      12.697(very large) ***\n",
      "track_features            vs user_features             0.0000      7.531(very large) ***\n",
      "track_features            vs all_features              0.0109      2.084(very large) *\n",
      "user_features             vs all_features              0.0000      9.679(very large) ***\n",
      "\n",
      "üìä SIGNIFICANT DIFFERENCES FOUND:\n",
      "   üî∏ baseline > with_artists\n",
      "      Improvement: 30.1%, p=0.0000, effect size=15.180\n",
      "   üî∏ baseline > full_graph\n",
      "      Improvement: 54.2%, p=0.0000, effect size=21.940\n",
      "   üî∏ baseline > track_features\n",
      "      Improvement: 18.4%, p=0.0000, effect size=8.261\n",
      "   üî∏ baseline > all_features\n",
      "      Improvement: 23.2%, p=0.0000, effect size=10.661\n",
      "   üî∏ with_users > with_artists\n",
      "      Improvement: 26.7%, p=0.0000, effect size=13.962\n",
      "   üî∏ with_artists > full_graph\n",
      "      Improvement: 18.6%, p=0.0000, effect size=13.458\n",
      "   üî∏ playlist_features > with_artists\n",
      "      Improvement: 33.7%, p=0.0000, effect size=17.889\n",
      "   üî∏ track_features > with_artists\n",
      "      Improvement: 9.9%, p=0.0000, effect size=5.740\n",
      "   üî∏ user_features > with_artists\n",
      "      Improvement: 29.6%, p=0.0000, effect size=13.498\n",
      "   üî∏ all_features > with_artists\n",
      "      Improvement: 5.6%, p=0.0004, effect size=3.668\n",
      "   üî∏ with_users > full_graph\n",
      "      Improvement: 50.2%, p=0.0000, effect size=20.978\n",
      "   üî∏ playlist_features > with_users\n",
      "      Improvement: 5.5%, p=0.0022, effect size=2.793\n",
      "   üî∏ with_users > track_features\n",
      "      Improvement: 15.3%, p=0.0000, effect size=7.039\n",
      "   üî∏ with_users > all_features\n",
      "      Improvement: 20.0%, p=0.0000, effect size=9.436\n",
      "   üî∏ playlist_features > full_graph\n",
      "      Improvement: 58.5%, p=0.0000, effect size=24.778\n",
      "   üî∏ track_features > full_graph\n",
      "      Improvement: 30.3%, p=0.0000, effect size=13.872\n",
      "   üî∏ user_features > full_graph\n",
      "      Improvement: 53.7%, p=0.0000, effect size=19.789\n",
      "   üî∏ all_features > full_graph\n",
      "      Improvement: 25.2%, p=0.0000, effect size=12.871\n",
      "   üî∏ playlist_features > track_features\n",
      "      Improvement: 21.7%, p=0.0000, effect size=10.067\n",
      "   üî∏ playlist_features > user_features\n",
      "      Improvement: 3.2%, p=0.0454, effect size=1.498\n",
      "   üî∏ playlist_features > all_features\n",
      "      Improvement: 26.7%, p=0.0000, effect size=12.697\n",
      "   üî∏ user_features > track_features\n",
      "      Improvement: 17.9%, p=0.0000, effect size=7.531\n",
      "   üî∏ track_features > all_features\n",
      "      Improvement: 4.1%, p=0.0109, effect size=2.084\n",
      "   üî∏ user_features > all_features\n",
      "      Improvement: 22.8%, p=0.0000, effect size=9.679\n",
      "üìä Analysis results saved: analysis_results_20250816_211920.json\n",
      "üìã Experiment summary saved: experiment_summary_20250816_211920.txt\n",
      "\n",
      "üéâ ALL RESULTS SAVED TO: ../results/lightgcn_experiments_enhanced\n",
      "üìÅ Experiment timestamp: 20250816_211920\n",
      "\n",
      "üéâ All experiments completed successfully!\n",
      "\n",
      "üìã FINAL SUMMARY:\n",
      "   üî¨ Configurations tested: 8\n",
      "   üìÅ Results directory: ../results/lightgcn_experiments_enhanced\n",
      "   üïê Experiment timestamp: 20250816_211920\n",
      "\n",
      "üìÑ Generated 23 files:\n",
      "   üìÑ complete_results_20250816_211920.json\n",
      "   üìÑ complete_results_20250816_211920.pkl\n",
      "   üìÑ experiment_config_20250816_211920.json\n",
      "   üìÑ experiment_summary_20250816_211920.txt\n",
      "   üìÑ logs/baseline_seed42_20250816_211920.json\n",
      "   üìÑ metrics/all_features_results_20250816_211920.json\n",
      "   üìÑ metrics/all_features_results_20250816_211920.pkl\n",
      "   üìÑ metrics/analysis_results_20250816_211920.json\n",
      "   üìÑ metrics/baseline_results_20250816_211920.json\n",
      "   üìÑ metrics/baseline_results_20250816_211920.pkl\n",
      "   ... and 13 more files\n",
      "\n",
      "üéâ Enhanced LightGCN experiments completed successfully!\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T16:24:21.234182Z",
     "start_time": "2025-08-17T15:31:32.311498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from scipy import stats as scipy_stats\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from datetime import datetime\n",
    "\n",
    "# =============================================================================\n",
    "# PHASE 3: COMBINED RESULTS CONFIGURATION SELECTOR\n",
    "# =============================================================================\n",
    "\n",
    "class Phase3CombinedResultsSelector:\n",
    "    \"\"\"\n",
    "    Enhanced configuration selector that handles combined Phase 1 & 2 results\n",
    "    in a single file and automatically separates them for analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, combined_results_path: str):\n",
    "        \"\"\"\n",
    "        Initialize selector with combined results file.\n",
    "\n",
    "        Args:\n",
    "            combined_results_path: Path to combined Phase 1&2 results file (.pkl or .json)\n",
    "        \"\"\"\n",
    "        self.combined_results = self._load_results(combined_results_path)\n",
    "\n",
    "        # Automatically separate Phase 1 and Phase 2 configurations\n",
    "        self.phase1_results, self.phase2_results = self._separate_phases()\n",
    "\n",
    "        # Statistical criteria (same as before)\n",
    "        self.significance_threshold = 0.05  # p < 0.05\n",
    "        self.effect_size_threshold = 0.2    # Cohen's d > 0.2\n",
    "        self.improvement_threshold = 5.0    # >5% improvement for features\n",
    "\n",
    "        print(\"üî¨ Phase 3 Combined Results Selector Initialized\")\n",
    "        print(f\"   üìä Total configurations loaded: {len(self.combined_results)}\")\n",
    "        print(f\"   üìä Phase 1 configs (graph structure): {len(self.phase1_results)}\")\n",
    "        print(f\"   üìä Phase 2 configs (feature importance): {len(self.phase2_results)}\")\n",
    "        print(f\"   üìã Statistical criteria:\")\n",
    "        print(f\"      ‚Ä¢ Significance: p < {self.significance_threshold}\")\n",
    "        print(f\"      ‚Ä¢ Effect size: Cohen's d > {self.effect_size_threshold}\")\n",
    "        print(f\"      ‚Ä¢ Feature improvement: >{self.improvement_threshold}%\")\n",
    "\n",
    "    def _load_results(self, results_path: str) -> Dict:\n",
    "        \"\"\"Load results from file (supports both .pkl and .json)\"\"\"\n",
    "        if results_path.endswith('.pkl'):\n",
    "            with open(results_path, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "        elif results_path.endswith('.json'):\n",
    "            with open(results_path, 'r') as f:\n",
    "                return json.load(f)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file format: {results_path}\")\n",
    "\n",
    "    def _separate_phases(self) -> Tuple[Dict, Dict]:\n",
    "        \"\"\"\n",
    "        Automatically separate Phase 1 and Phase 2 configurations based on their characteristics.\n",
    "\n",
    "        Phase 1: Graph structure ablation (no features, different edge types)\n",
    "        Phase 2: Feature importance (same baseline graph, different features)\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Dict, Dict]: (phase1_results, phase2_results)\n",
    "        \"\"\"\n",
    "        phase1_configs = {}\n",
    "        phase2_configs = {}\n",
    "\n",
    "        print(\"\\nüîç Analyzing configurations to separate phases...\")\n",
    "\n",
    "        for config_name, config_data in self.combined_results.items():\n",
    "            config = config_data['config']\n",
    "\n",
    "            # Phase 1 identification: No features used\n",
    "            if not config.get('use_features', False):\n",
    "                phase1_configs[config_name] = config_data\n",
    "                print(f\"   üìä Phase 1: {config_name} - {config['description']}\")\n",
    "\n",
    "            # Phase 2 identification: Features used with baseline graph\n",
    "            elif (config.get('use_features', False) and\n",
    "                  config.get('edge_types') == ['playlist_track']):\n",
    "                phase2_configs[config_name] = config_data\n",
    "                print(f\"   üé® Phase 2: {config_name} - {config['description']}\")\n",
    "\n",
    "            else:\n",
    "                # Handle edge cases - classify based on primary characteristic\n",
    "                if len(config.get('edge_types', [])) > 1:\n",
    "                    phase1_configs[config_name] = config_data\n",
    "                    print(f\"   üìä Phase 1 (edge case): {config_name} - {config['description']}\")\n",
    "                else:\n",
    "                    phase2_configs[config_name] = config_data\n",
    "                    print(f\"   üé® Phase 2 (edge case): {config_name} - {config['description']}\")\n",
    "\n",
    "        print(f\"\\n‚úÖ Phase separation complete:\")\n",
    "        print(f\"   Phase 1 (Graph Structure): {list(phase1_configs.keys())}\")\n",
    "        print(f\"   Phase 2 (Feature Importance): {list(phase2_configs.keys())}\")\n",
    "\n",
    "        return phase1_configs, phase2_configs\n",
    "\n",
    "    def determine_best_edge_types(self) -> Tuple[List[str], Dict]:\n",
    "        \"\"\"\n",
    "        Determine best edge types from Phase 1 results using statistical criteria.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[List[str], Dict]: (best_edge_types, analysis_details)\n",
    "        \"\"\"\n",
    "        print(\"\\nüîó PHASE 1 ANALYSIS: Edge Type Selection\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        if not self.phase1_results:\n",
    "            print(\"‚ùå No Phase 1 configurations found!\")\n",
    "            return [\"playlist_track\"], {\"error\": \"No Phase 1 configurations available\"}\n",
    "\n",
    "        # Extract NDCG@10 performance for all Phase 1 configs\n",
    "        config_performances = {}\n",
    "        for config_name, config_data in self.phase1_results.items():\n",
    "            if 'runs_summary' in config_data:\n",
    "                # Handle runs_summary format\n",
    "                ndcg_values = [run['metrics']['ndcg@10'] for run in config_data['runs_summary']]\n",
    "            elif 'runs' in config_data:\n",
    "                # Handle full runs format\n",
    "                ndcg_values = [run['metrics']['ndcg@10'] for run in config_data['runs']]\n",
    "            else:\n",
    "                # Fallback to statistics if available\n",
    "                if 'statistics' in config_data and 'ndcg@10' in config_data['statistics']:\n",
    "                    mean_val = config_data['statistics']['ndcg@10']['mean']\n",
    "                    std_val = config_data['statistics']['ndcg@10'].get('std', 0)\n",
    "                    n = config_data['statistics']['ndcg@10'].get('n', 1)\n",
    "                    # Approximate individual values (for analysis purposes)\n",
    "                    ndcg_values = [mean_val] * n\n",
    "                else:\n",
    "                    print(f\"   ‚ö†Ô∏è Skipping {config_name} - no usable performance data\")\n",
    "                    continue\n",
    "\n",
    "            config_performances[config_name] = {\n",
    "                'ndcg_values': ndcg_values,\n",
    "                'mean_ndcg': np.mean(ndcg_values),\n",
    "                'std_ndcg': np.std(ndcg_values, ddof=1) if len(ndcg_values) > 1 else 0,\n",
    "                'config': config_data['config']\n",
    "            }\n",
    "\n",
    "        if not config_performances:\n",
    "            print(\"‚ùå No usable Phase 1 performance data found!\")\n",
    "            return [\"playlist_track\"], {\"error\": \"No usable Phase 1 performance data\"}\n",
    "\n",
    "        # Rank configurations by mean NDCG@10\n",
    "        ranked_configs = sorted(\n",
    "            config_performances.items(),\n",
    "            key=lambda x: x[1]['mean_ndcg'],\n",
    "            reverse=True\n",
    "        )\n",
    "\n",
    "        print(\"üìä Phase 1 Configuration Rankings (by NDCG@10):\")\n",
    "        for i, (config_name, perf) in enumerate(ranked_configs, 1):\n",
    "            print(f\"   {i}. {config_name}: {perf['mean_ndcg']:.4f} ¬± {perf['std_ndcg']:.4f}\")\n",
    "\n",
    "        # Get best performing configuration\n",
    "        best_config_name, best_config_perf = ranked_configs[0]\n",
    "        best_edge_types = best_config_perf['config']['edge_types']\n",
    "\n",
    "        # Analysis details\n",
    "        analysis_details = {\n",
    "            'ranked_configs': [(name, perf['mean_ndcg']) for name, perf in ranked_configs],\n",
    "            'selected_config': best_config_name,\n",
    "            'performance': best_config_perf['mean_ndcg'],\n",
    "            'edge_types': best_edge_types\n",
    "        }\n",
    "\n",
    "        # Test statistical significance against baseline (if not baseline itself)\n",
    "        if best_config_name != 'baseline' and 'baseline' in config_performances:\n",
    "            baseline_values = config_performances['baseline']['ndcg_values']\n",
    "            best_values = config_performances[best_config_name]['ndcg_values']\n",
    "\n",
    "            if len(baseline_values) > 1 and len(best_values) > 1:\n",
    "                # t-test for significance\n",
    "                t_stat, p_value = scipy_stats.ttest_ind(best_values, baseline_values)\n",
    "\n",
    "                # Effect size (Cohen's d)\n",
    "                pooled_std = np.sqrt(\n",
    "                    ((len(best_values) - 1) * np.var(best_values, ddof=1) +\n",
    "                     (len(baseline_values) - 1) * np.var(baseline_values, ddof=1)) /\n",
    "                    (len(best_values) + len(baseline_values) - 2)\n",
    "                )\n",
    "                cohens_d = abs(np.mean(best_values) - np.mean(baseline_values)) / pooled_std\n",
    "\n",
    "                analysis_details.update({\n",
    "                    'vs_baseline': {\n",
    "                        'p_value': p_value,\n",
    "                        'cohens_d': cohens_d,\n",
    "                        'significant': p_value < self.significance_threshold,\n",
    "                        'meaningful_effect': cohens_d > self.effect_size_threshold\n",
    "                    }\n",
    "                })\n",
    "\n",
    "                print(f\"\\nüß™ Statistical Analysis vs Baseline:\")\n",
    "                print(f\"   ‚Ä¢ Best config: {best_config_name} (NDCG@10: {best_config_perf['mean_ndcg']:.4f})\")\n",
    "                print(f\"   ‚Ä¢ Baseline: {config_performances['baseline']['mean_ndcg']:.4f}\")\n",
    "                print(f\"   ‚Ä¢ p-value: {p_value:.4f} ({'significant' if p_value < self.significance_threshold else 'not significant'})\")\n",
    "                print(f\"   ‚Ä¢ Cohen's d: {cohens_d:.4f} ({'meaningful' if cohens_d > self.effect_size_threshold else 'small effect'})\")\n",
    "\n",
    "                # Conservative decision\n",
    "                if p_value < self.significance_threshold and cohens_d > self.effect_size_threshold:\n",
    "                    print(f\"   ‚úÖ Selected: {best_config_name} (meets all criteria)\")\n",
    "                    selected_edge_types = best_edge_types\n",
    "                    analysis_details['decision'] = f\"Selected {best_config_name} - statistically significant improvement\"\n",
    "                else:\n",
    "                    print(f\"   ‚ö†Ô∏è Conservative choice: baseline (insufficient evidence for improvement)\")\n",
    "                    selected_edge_types = config_performances['baseline']['config']['edge_types']\n",
    "                    analysis_details['decision'] = \"Conservative fallback to baseline - insufficient statistical evidence\"\n",
    "                    analysis_details['selected_config'] = 'baseline'\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è Insufficient data for statistical testing\")\n",
    "                selected_edge_types = best_edge_types\n",
    "                analysis_details['decision'] = \"Insufficient data for statistical testing - selected best performer\"\n",
    "        else:\n",
    "            if best_config_name == 'baseline':\n",
    "                print(f\"   ‚úÖ Selected: baseline (best performing)\")\n",
    "                selected_edge_types = best_edge_types\n",
    "                analysis_details['decision'] = \"Baseline was best performing\"\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è No baseline for comparison, selecting: {best_config_name}\")\n",
    "                selected_edge_types = best_edge_types\n",
    "                analysis_details['decision'] = \"No baseline comparison available\"\n",
    "\n",
    "        print(f\"\\nüéØ Final Edge Type Selection: {selected_edge_types}\")\n",
    "\n",
    "        return selected_edge_types, analysis_details\n",
    "\n",
    "    def determine_best_features(self) -> Tuple[bool, List[str], Dict]:\n",
    "        \"\"\"\n",
    "        Determine best features from Phase 2 results using improvement thresholds.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[bool, List[str], Dict]: (use_features, feature_types, analysis_details)\n",
    "        \"\"\"\n",
    "        print(\"\\nüé® PHASE 2 ANALYSIS: Feature Type Selection\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        if not self.phase2_results:\n",
    "            print(\"‚ùå No Phase 2 configurations found!\")\n",
    "            return False, [], {\"error\": \"No Phase 2 configurations available\"}\n",
    "\n",
    "        # Get baseline performance from Phase 1 results\n",
    "        baseline_performance = None\n",
    "        if 'baseline' in self.phase1_results:\n",
    "            baseline_config = self.phase1_results['baseline']\n",
    "            if 'runs_summary' in baseline_config:\n",
    "                baseline_ndcg_values = [run['metrics']['ndcg@10'] for run in baseline_config['runs_summary']]\n",
    "            elif 'statistics' in baseline_config:\n",
    "                baseline_ndcg_values = [baseline_config['statistics']['ndcg@10']['mean']]\n",
    "            baseline_performance = np.mean(baseline_ndcg_values)\n",
    "            print(f\"üìä Baseline Performance (Structure-only): {baseline_performance:.4f}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No baseline found in Phase 1 results - using first Phase 2 config as reference\")\n",
    "\n",
    "        # Analyze feature configurations\n",
    "        feature_analysis = {}\n",
    "        for config_name, config_data in self.phase2_results.items():\n",
    "            if 'runs_summary' in config_data:\n",
    "                ndcg_values = [run['metrics']['ndcg@10'] for run in config_data['runs_summary']]\n",
    "            elif 'statistics' in config_data:\n",
    "                ndcg_values = [config_data['statistics']['ndcg@10']['mean']]\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            mean_ndcg = np.mean(ndcg_values)\n",
    "\n",
    "            # Calculate improvement over baseline\n",
    "            if baseline_performance is not None:\n",
    "                improvement_pct = ((mean_ndcg - baseline_performance) / baseline_performance) * 100\n",
    "            else:\n",
    "                improvement_pct = 0.0\n",
    "\n",
    "            feature_analysis[config_name] = {\n",
    "                'mean_ndcg': mean_ndcg,\n",
    "                'improvement_pct': improvement_pct,\n",
    "                'ndcg_values': ndcg_values,\n",
    "                'feature_types': config_data['config']['feature_types']\n",
    "            }\n",
    "\n",
    "            print(f\"   ‚Ä¢ {config_name}: {mean_ndcg:.4f} ({improvement_pct:+.1f}% vs baseline)\")\n",
    "\n",
    "        # Find best feature configuration\n",
    "        if feature_analysis:\n",
    "            best_feature_config = max(feature_analysis.items(), key=lambda x: x[1]['mean_ndcg'])\n",
    "            best_config_name, best_config_perf = best_feature_config\n",
    "            best_improvement = best_config_perf['improvement_pct']\n",
    "\n",
    "            print(f\"\\nüèÜ Best Feature Configuration: {best_config_name}\")\n",
    "            print(f\"   ‚Ä¢ Performance: {best_config_perf['mean_ndcg']:.4f}\")\n",
    "            print(f\"   ‚Ä¢ Improvement: {best_improvement:+.1f}% vs baseline\")\n",
    "            print(f\"   ‚Ä¢ Threshold: {self.improvement_threshold}%\")\n",
    "\n",
    "            # Apply improvement threshold\n",
    "            if best_improvement >= self.improvement_threshold:\n",
    "                print(f\"   ‚úÖ Features justified: {best_improvement:.1f}% ‚â• {self.improvement_threshold}%\")\n",
    "                use_features = True\n",
    "                feature_types = best_config_perf['feature_types']\n",
    "                decision = f\"Selected {best_config_name} - {best_improvement:.1f}% improvement exceeds threshold\"\n",
    "            else:\n",
    "                print(f\"   ‚ùå Features not justified: {best_improvement:.1f}% < {self.improvement_threshold}%\")\n",
    "                use_features = False\n",
    "                feature_types = []\n",
    "                decision = f\"Improvement {best_improvement:.1f}% < {self.improvement_threshold}% threshold\"\n",
    "        else:\n",
    "            print(\"   ‚ùå No feature configurations found\")\n",
    "            use_features = False\n",
    "            feature_types = []\n",
    "            decision = \"No feature configurations available\"\n",
    "            best_config_name = None\n",
    "            best_improvement = 0.0\n",
    "\n",
    "        analysis_details = {\n",
    "            'baseline_performance': baseline_performance,\n",
    "            'feature_analysis': feature_analysis,\n",
    "            'best_config': best_config_name,\n",
    "            'best_improvement': best_improvement,\n",
    "            'threshold': self.improvement_threshold,\n",
    "            'decision': decision,\n",
    "            'use_features': use_features,\n",
    "            'selected_feature_types': feature_types\n",
    "        }\n",
    "\n",
    "        print(f\"\\nüéØ Final Feature Selection:\")\n",
    "        print(f\"   ‚Ä¢ Use features: {use_features}\")\n",
    "        print(f\"   ‚Ä¢ Feature types: {feature_types}\")\n",
    "\n",
    "        return use_features, feature_types, analysis_details\n",
    "\n",
    "    def create_optimal_configuration(self) -> Tuple[Dict, Dict]:\n",
    "        \"\"\"\n",
    "        Create optimal configuration based on empirical analysis of combined results.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Dict, Dict]: (optimal_config, selection_analysis)\n",
    "        \"\"\"\n",
    "        print(\"\\nüéØ PHASE 3: EMPIRICAL CONFIGURATION SELECTION\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        # Determine best edge types from Phase 1\n",
    "        best_edge_types, edge_analysis = self.determine_best_edge_types()\n",
    "\n",
    "        # Determine best features from Phase 2\n",
    "        use_features, feature_types, feature_analysis = self.determine_best_features()\n",
    "\n",
    "        # Create optimal configuration\n",
    "        optimal_config = {\n",
    "            \"name\": \"Dynamic Best Combined\",\n",
    "            \"description\": \"Empirically determined best configuration based on statistical criteria from combined results\",\n",
    "            \"edge_types\": best_edge_types,\n",
    "            \"use_features\": use_features,\n",
    "            \"feature_types\": feature_types,\n",
    "            \"use_playlist_features\": \"playlist\" in feature_types,\n",
    "            \"use_track_features\": \"track\" in feature_types,\n",
    "            \"use_user_features\": \"user\" in feature_types\n",
    "        }\n",
    "\n",
    "        # Comprehensive analysis summary\n",
    "        selection_analysis = {\n",
    "            'methodology': {\n",
    "                'significance_threshold': self.significance_threshold,\n",
    "                'effect_size_threshold': self.effect_size_threshold,\n",
    "                'improvement_threshold': self.improvement_threshold,\n",
    "                'approach': 'Conservative, evidence-based selection from combined results'\n",
    "            },\n",
    "            'data_source': {\n",
    "                'combined_results': True,\n",
    "                'phase1_configs': list(self.phase1_results.keys()),\n",
    "                'phase2_configs': list(self.phase2_results.keys()),\n",
    "                'separation_method': 'Automatic based on configuration characteristics'\n",
    "            },\n",
    "            'edge_selection': edge_analysis,\n",
    "            'feature_selection': feature_analysis,\n",
    "            'final_configuration': optimal_config,\n",
    "            'timestamp': datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        }\n",
    "\n",
    "        print(f\"\\nüèÜ OPTIMAL CONFIGURATION DETERMINED:\")\n",
    "        print(f\"=\"*50)\n",
    "        print(f\"Name: {optimal_config['name']}\")\n",
    "        print(f\"Description: {optimal_config['description']}\")\n",
    "        print(f\"Edge Types: {optimal_config['edge_types']}\")\n",
    "        print(f\"Use Features: {optimal_config['use_features']}\")\n",
    "        print(f\"Feature Types: {optimal_config['feature_types']}\")\n",
    "\n",
    "        return optimal_config, selection_analysis\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# PHASE 3: EXPERIMENT RUNNER (EMBEDDED)\n",
    "# =============================================================================\n",
    "\n",
    "class Phase3ExperimentRunner:\n",
    "    \"\"\"\n",
    "    Runs Phase 3 experiments using the empirically determined optimal configuration.\n",
    "    Uses the same methodology as Phase 1 & 2 for consistency.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: ExperimentConfig, data: Dict):\n",
    "        self.config = config\n",
    "        self.data = data\n",
    "        self.trainer = ModelTrainer(config, data)\n",
    "        self.experiment_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "        print(\"üéØ PHASE 3 EXPERIMENT RUNNER INITIALIZED\")\n",
    "        print(f\"   üìä Dataset: {data['entity_counts']['playlists']:,} playlists\")\n",
    "        print(f\"   üé≤ Seeds: {len(config.random_seeds)}\")\n",
    "        print(f\"   üìÅ Results dir: {config.results_dir}\")\n",
    "        print(f\"   üïê Timestamp: {self.experiment_timestamp}\")\n",
    "\n",
    "    def run_phase3_experiment(self, optimal_config: Dict, selection_analysis: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        Run Phase 3 experiment with the empirically determined optimal configuration.\n",
    "\n",
    "        Args:\n",
    "            optimal_config: The empirically determined optimal configuration\n",
    "            selection_analysis: Analysis details from configuration selection\n",
    "\n",
    "        Returns:\n",
    "            Dict: Complete Phase 3 results\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üî¨ PHASE 3: OPTIMAL CONFIGURATION EXPERIMENT\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        config_name = \"phase3_optimal\"\n",
    "        config_spec = optimal_config\n",
    "\n",
    "        print(f\"\\nüß™ Configuration: {config_spec['name']}\")\n",
    "        print(f\"üìù {config_spec['description']}\")\n",
    "        print(f\"üîó Edge types: {config_spec['edge_types']}\")\n",
    "        print(f\"üé® Features: {config_spec['feature_types'] if config_spec['use_features'] else 'None'}\")\n",
    "\n",
    "        # Save Phase 3 configuration and analysis\n",
    "        self._save_phase3_setup(optimal_config, selection_analysis)\n",
    "\n",
    "        # Run experiments with multiple seeds (same as Phase 1 & 2)\n",
    "        phase3_results = []\n",
    "\n",
    "        for seed_idx, seed in enumerate(self.config.random_seeds):\n",
    "            print(f\"\\nüé≤ Seed {seed_idx+1}/{len(self.config.random_seeds)} (seed={seed}):\")\n",
    "\n",
    "            # Train model (same method as Phase 1 & 2)\n",
    "            training_result = self.trainer.train_model(config_spec, seed=seed, save_model=True)\n",
    "\n",
    "            if training_result is None:\n",
    "                print(f\"   ‚ùå Training failed for seed {seed}\")\n",
    "                continue\n",
    "\n",
    "            # Evaluate model (same method as Phase 1 & 2)\n",
    "            test_metrics = self.trainer.evaluate_model(\n",
    "                training_result['model'],\n",
    "                training_result['adj_matrix'],\n",
    "                'test',\n",
    "                seed=seed\n",
    "            )\n",
    "\n",
    "            # Store results\n",
    "            run_result = {\n",
    "                'seed': seed,\n",
    "                'metrics': test_metrics,\n",
    "                'training_time': training_result['training_time'],\n",
    "                'final_loss': training_result['final_loss'],\n",
    "                'best_val_loss': training_result['best_val_loss'],\n",
    "                'model_file': training_result.get('model_file'),\n",
    "                'timestamp': training_result.get('timestamp')\n",
    "            }\n",
    "            phase3_results.append(run_result)\n",
    "\n",
    "            # Save individual run results\n",
    "            self.config.result_saver.save_training_run(\n",
    "                config_name, seed, training_result, test_metrics,\n",
    "                training_result.get('timestamp')\n",
    "            )\n",
    "\n",
    "            # Print immediate results\n",
    "            print(f\"      üìä NDCG@10: {test_metrics.get('ndcg@10', 0):.4f}\")\n",
    "            print(f\"      üìä AUC: {test_metrics.get('auc', 0):.4f}\")\n",
    "            print(f\"      ‚è±Ô∏è Time: {training_result['training_time']:.1f}s\")\n",
    "\n",
    "            # Memory cleanup\n",
    "            del training_result\n",
    "            torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "\n",
    "        # Calculate statistics\n",
    "        if phase3_results:\n",
    "            stats = self._calculate_statistics(phase3_results)\n",
    "\n",
    "            complete_results = {\n",
    "                'config': config_spec,\n",
    "                'runs': phase3_results,\n",
    "                'statistics': stats,\n",
    "                'selection_analysis': selection_analysis,\n",
    "                'methodology': 'Empirical configuration selection based on combined Phase 1 & 2 analysis'\n",
    "            }\n",
    "\n",
    "            # Save Phase 3 results\n",
    "            self.config.result_saver.save_config_results(\n",
    "                config_name, complete_results, self.experiment_timestamp\n",
    "            )\n",
    "\n",
    "            # Print summary\n",
    "            self._print_phase3_summary(complete_results)\n",
    "\n",
    "            return complete_results\n",
    "\n",
    "        return None\n",
    "\n",
    "    def _save_phase3_setup(self, optimal_config: Dict, selection_analysis: Dict):\n",
    "        \"\"\"Save Phase 3 experimental setup and configuration selection analysis\"\"\"\n",
    "        setup_info = {\n",
    "            'phase3_timestamp': self.experiment_timestamp,\n",
    "            'optimal_configuration': optimal_config,\n",
    "            'selection_analysis': selection_analysis,\n",
    "            'methodology': {\n",
    "                'approach': 'Empirical, performance-driven configuration selection from combined results',\n",
    "                'statistical_criteria': {\n",
    "                    'significance_testing': 'p < 0.05',\n",
    "                    'effect_size_analysis': 'Cohen\\'s d > 0.2',\n",
    "                    'improvement_threshold': '>5% for feature justification'\n",
    "                },\n",
    "                'ranking_method': 'Mean NDCG@10 performance across multiple random seeds',\n",
    "                'conservative_approach': 'Evidence-based selection with fallback to baseline'\n",
    "            },\n",
    "            'experiment_settings': {\n",
    "                'random_seeds': self.config.random_seeds,\n",
    "                'evaluation_metrics': self.config.k_values,\n",
    "                'training_parameters': {\n",
    "                    'epochs': self.config.epochs,\n",
    "                    'learning_rate': self.config.learning_rate,\n",
    "                    'embedding_dim': self.config.embedding_dim,\n",
    "                    'n_layers': self.config.n_layers\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        setup_file = os.path.join(\n",
    "            self.config.results_dir,\n",
    "            f\"phase3_setup_{self.experiment_timestamp}.json\"\n",
    "        )\n",
    "        with open(setup_file, 'w') as f:\n",
    "            json.dump(setup_info, f, indent=2)\n",
    "\n",
    "        print(f\"üíæ Phase 3 setup saved: {os.path.basename(setup_file)}\")\n",
    "\n",
    "    def _calculate_statistics(self, phase3_results: List[Dict]) -> Dict:\n",
    "        \"\"\"Calculate statistics for Phase 3 results (same method as Phase 1 & 2)\"\"\"\n",
    "        if not phase3_results:\n",
    "            return {}\n",
    "\n",
    "        statistics = {}\n",
    "\n",
    "        # Get all metric names\n",
    "        all_metrics = set()\n",
    "        for run in phase3_results:\n",
    "            all_metrics.update(run['metrics'].keys())\n",
    "\n",
    "        # Calculate statistics for each metric\n",
    "        for metric in all_metrics:\n",
    "            values = [run['metrics'].get(metric, 0) for run in phase3_results]\n",
    "\n",
    "            if values and len(values) > 1:\n",
    "                mean_val = np.mean(values)\n",
    "                std_val = np.std(values, ddof=1)\n",
    "                n = len(values)\n",
    "\n",
    "                # 95% Confidence intervals\n",
    "                if n > 2:\n",
    "                    t_value = scipy_stats.t.ppf(0.975, n-1)\n",
    "                    margin_error = t_value * std_val / np.sqrt(n)\n",
    "                    ci_lower = mean_val - margin_error\n",
    "                    ci_upper = mean_val + margin_error\n",
    "                else:\n",
    "                    ci_lower = mean_val\n",
    "                    ci_upper = mean_val\n",
    "\n",
    "                statistics[metric] = {\n",
    "                    'mean': mean_val,\n",
    "                    'std': std_val,\n",
    "                    'min': np.min(values),\n",
    "                    'max': np.max(values),\n",
    "                    'ci_lower': ci_lower,\n",
    "                    'ci_upper': ci_upper,\n",
    "                    'n': n\n",
    "                }\n",
    "            elif values:\n",
    "                statistics[metric] = {\n",
    "                    'mean': values[0],\n",
    "                    'std': 0.0,\n",
    "                    'min': values[0],\n",
    "                    'max': values[0],\n",
    "                    'ci_lower': values[0],\n",
    "                    'ci_upper': values[0],\n",
    "                    'n': 1\n",
    "                }\n",
    "\n",
    "        return statistics\n",
    "\n",
    "    def _print_phase3_summary(self, results: Dict):\n",
    "        \"\"\"Print Phase 3 results summary\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üìä PHASE 3: OPTIMAL CONFIGURATION RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        stats = results['statistics']\n",
    "\n",
    "        print(f\"\\nüèÜ EMPIRICALLY DETERMINED OPTIMAL CONFIGURATION:\")\n",
    "        print(f\"   Name: {results['config']['name']}\")\n",
    "        print(f\"   Description: {results['config']['description']}\")\n",
    "        print(f\"   Edge Types: {results['config']['edge_types']}\")\n",
    "        print(f\"   Features: {results['config']['feature_types'] if results['config']['use_features'] else 'None'}\")\n",
    "\n",
    "        print(f\"\\nüìä PERFORMANCE METRICS:\")\n",
    "\n",
    "        # Key metrics with confidence intervals\n",
    "        key_metrics = ['ndcg@10', 'ndcg@20', 'precision@10', 'recall@10', 'auc']\n",
    "        for metric in key_metrics:\n",
    "            if metric in stats:\n",
    "                s = stats[metric]\n",
    "                print(f\"   ‚Ä¢ {metric.upper()}: {s['mean']:.4f} ¬± {s['std']:.4f} \"\n",
    "                      f\"(95% CI: [{s['ci_lower']:.4f}, {s['ci_upper']:.4f}])\")\n",
    "\n",
    "        # Training efficiency\n",
    "        avg_time = np.mean([run['training_time'] for run in results['runs']])\n",
    "        print(f\"\\n‚è±Ô∏è TRAINING EFFICIENCY:\")\n",
    "        print(f\"   ‚Ä¢ Average training time: {avg_time:.1f}s ({avg_time/60:.1f} minutes)\")\n",
    "        print(f\"   ‚Ä¢ Seeds completed: {len(results['runs'])}/{len(self.config.random_seeds)}\")\n",
    "\n",
    "        print(f\"\\nüî¨ EMPIRICAL SELECTION SUMMARY:\")\n",
    "        edge_decision = results['selection_analysis']['edge_selection']['decision']\n",
    "        feature_decision = results['selection_analysis']['feature_selection']['decision']\n",
    "        print(f\"   ‚Ä¢ Edge selection: {edge_decision}\")\n",
    "        print(f\"   ‚Ä¢ Feature selection: {feature_decision}\")\n",
    "\n",
    "        print(f\"\\n‚úÖ Phase 3 experiment completed successfully!\")\n",
    "        print(f\"üìÅ Results saved with timestamp: {self.experiment_timestamp}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN PHASE 3 EXECUTION FOR COMBINED RESULTS\n",
    "# =============================================================================\n",
    "\n",
    "def run_phase3_experiments_combined(combined_results_path: str,\n",
    "                                   data_path: str = \"../data/processed/spotify_scaled_hybrid_tiny.json\") -> Dict:\n",
    "    \"\"\"\n",
    "    Main function to run Phase 3 experiments using combined Phase 1&2 results file.\n",
    "\n",
    "    Args:\n",
    "        combined_results_path: Path to combined Phase 1&2 results (.pkl or .json)\n",
    "        data_path: Path to the dataset\n",
    "\n",
    "    Returns:\n",
    "        Dict: Complete Phase 3 results\n",
    "    \"\"\"\n",
    "    print(\"üéØ PHASE 3: EMPIRICAL CONFIGURATION SELECTION FROM COMBINED RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # 1. Initialize configuration selector for combined results\n",
    "    selector = Phase3CombinedResultsSelector(combined_results_path)\n",
    "\n",
    "    # 2. Determine optimal configuration empirically\n",
    "    optimal_config, selection_analysis = selector.create_optimal_configuration()\n",
    "\n",
    "    # 3. Setup experiment infrastructure (same as before)\n",
    "    config = ExperimentConfig()\n",
    "    # Update results directory for Phase 3\n",
    "    config.results_dir = \"../results/lightgcn_phase3_optimal_combined\"\n",
    "    config.result_saver = ResultSaver(config.results_dir)\n",
    "\n",
    "    print(f\"\\nüìÅ Phase 3 results will be saved to: {config.results_dir}\")\n",
    "\n",
    "    # 4. Load and process data (same methodology)\n",
    "    data_processor = SpotifyDataProcessor(config)\n",
    "    data = data_processor.load_and_process_data(data_path, seed=42)\n",
    "\n",
    "    # 5. Run Phase 3 experiment using embedded Phase3ExperimentRunner\n",
    "    phase3_runner = Phase3ExperimentRunner(config, data)\n",
    "    results = phase3_runner.run_phase3_experiment(optimal_config, selection_analysis)\n",
    "\n",
    "    # 6. Save complete Phase 3 results with combined source notation\n",
    "    if results:\n",
    "        # Add source information\n",
    "        results['data_source'] = {\n",
    "            'combined_results_file': combined_results_path,\n",
    "            'automatic_phase_separation': True,\n",
    "            'methodology': 'Empirical selection from combined Phase 1&2 results'\n",
    "        }\n",
    "\n",
    "        config.result_saver.save_complete_results(\n",
    "            {'phase3_optimal_combined': results},\n",
    "            phase3_runner.experiment_timestamp\n",
    "        )\n",
    "\n",
    "        # Create summary report\n",
    "        config.result_saver.create_experiment_summary(\n",
    "            {'phase3_optimal_combined': results},\n",
    "            phase3_runner.experiment_timestamp\n",
    "        )\n",
    "\n",
    "        print(f\"\\nüéâ Phase 3 experiments completed successfully!\")\n",
    "        print(f\"üìä Empirical selection from combined results successful\")\n",
    "        print(f\"üìÅ All results saved to: {config.results_dir}\")\n",
    "\n",
    "        return results\n",
    "    else:\n",
    "        print(f\"\\n‚ùå Phase 3 experiments failed!\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ANALYSIS UTILITIES FOR COMBINED RESULTS\n",
    "# =============================================================================\n",
    "\n",
    "def analyze_combined_results_selection(combined_results_path: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyze the empirical selection process for combined results without running experiments.\n",
    "    Useful for understanding what configuration would be selected and why.\n",
    "\n",
    "    Args:\n",
    "        combined_results_path: Path to combined Phase 1&2 results\n",
    "\n",
    "    Returns:\n",
    "        Dict: Selection analysis details\n",
    "    \"\"\"\n",
    "    print(\"üîç ANALYZING EMPIRICAL CONFIGURATION SELECTION\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Initialize selector\n",
    "    selector = Phase3CombinedResultsSelector(combined_results_path)\n",
    "\n",
    "    # Perform selection analysis\n",
    "    optimal_config, selection_analysis = selector.create_optimal_configuration()\n",
    "\n",
    "    # Create detailed analysis report\n",
    "    report = {\n",
    "        'optimal_configuration': optimal_config,\n",
    "        'selection_analysis': selection_analysis,\n",
    "        'summary': {\n",
    "            'edge_decision': selection_analysis['edge_selection']['decision'],\n",
    "            'feature_decision': selection_analysis['feature_selection']['decision'],\n",
    "            'final_edge_types': optimal_config['edge_types'],\n",
    "            'final_features': optimal_config['feature_types'],\n",
    "            'complexity_level': 'Simple' if not optimal_config['use_features'] else 'Feature-Enhanced'\n",
    "        }\n",
    "    }\n",
    "\n",
    "    print(f\"\\nüìä SELECTION ANALYSIS COMPLETE\")\n",
    "    print(f\"   üîó Edge Selection: {report['summary']['edge_decision']}\")\n",
    "    print(f\"   üé® Feature Selection: {report['summary']['feature_decision']}\")\n",
    "    print(f\"   üéØ Final Configuration: {report['summary']['complexity_level']}\")\n",
    "\n",
    "    return report\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# USAGE EXAMPLE FOR YOUR DATA\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üî¨ Phase 3: Empirical Configuration Selection from Combined Results\")\n",
    "    print(\"\\nüìã METHODOLOGY:\")\n",
    "    print(\"   ‚Ä¢ Automatic Phase 1/2 separation from combined results\")\n",
    "    print(\"   ‚Ä¢ Statistical criteria: p < 0.05, Cohen's d > 0.2, >5% improvement\")\n",
    "    print(\"   ‚Ä¢ Conservative evidence-based selection\")\n",
    "    print(\"   ‚Ä¢ Same training/evaluation methodology as Phase 1 & 2\")\n",
    "\n",
    "    # Use your actual combined results file\n",
    "    combined_results_path = \"../results/lightgcn_experiments_enhanced/complete_results_20250816_211920.json\"  # Your file with the JSON data\n",
    "    data_path = \"../data/processed/spotify_scaled_hybrid_tiny.json\"\n",
    "\n",
    "    try:\n",
    "        # First, let's analyze what configuration would be selected\n",
    "        print(\"\\nüîç STEP 1: Analyzing empirical selection...\")\n",
    "        analysis = analyze_combined_results_selection(combined_results_path)\n",
    "\n",
    "        print(f\"\\nüìã PREDICTED OPTIMAL CONFIGURATION:\")\n",
    "        print(f\"   ‚Ä¢ Edge Types: {analysis['optimal_configuration']['edge_types']}\")\n",
    "        print(f\"   ‚Ä¢ Features: {analysis['optimal_configuration']['feature_types']}\")\n",
    "        print(f\"   ‚Ä¢ Rationale: {analysis['summary']['edge_decision']}\")\n",
    "\n",
    "        # Then run the full Phase 3 experiment\n",
    "        print(f\"\\nüöÄ STEP 2: Running Phase 3 experiment with optimal configuration...\")\n",
    "\n",
    "        results = run_phase3_experiments_combined(\n",
    "            combined_results_path=combined_results_path,\n",
    "            data_path=data_path\n",
    "        )\n",
    "\n",
    "        if results:\n",
    "            print(\"\\nüéâ Phase 3 completed successfully!\")\n",
    "            print(\"üìä Key results:\")\n",
    "            stats = results['statistics']\n",
    "            print(f\"   ‚Ä¢ NDCG@10: {stats['ndcg@10']['mean']:.4f} ¬± {stats['ndcg@10']['std']:.4f}\")\n",
    "            print(f\"   ‚Ä¢ AUC: {stats['auc']['mean']:.4f} ¬± {stats['auc']['std']:.4f}\")\n",
    "            print(f\"   ‚Ä¢ Configuration: {results['config']['edge_types']} + {results['config']['feature_types']}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"\\n‚ùå Error: Could not find results file\")\n",
    "        print(f\"Please ensure the combined results file exists at: {combined_results_path}\")\n",
    "        print(f\"Error details: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error running Phase 3 experiments: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ],
   "id": "667abecce501b399",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ Phase 3: Empirical Configuration Selection from Combined Results\n",
      "\n",
      "üìã METHODOLOGY:\n",
      "   ‚Ä¢ Automatic Phase 1/2 separation from combined results\n",
      "   ‚Ä¢ Statistical criteria: p < 0.05, Cohen's d > 0.2, >5% improvement\n",
      "   ‚Ä¢ Conservative evidence-based selection\n",
      "   ‚Ä¢ Same training/evaluation methodology as Phase 1 & 2\n",
      "\n",
      "üîç STEP 1: Analyzing empirical selection...\n",
      "üîç ANALYZING EMPIRICAL CONFIGURATION SELECTION\n",
      "============================================================\n",
      "\n",
      "üîç Analyzing configurations to separate phases...\n",
      "   üìä Phase 1: baseline - Playlist-track edges only\n",
      "   üìä Phase 1: with_artists - Add track-artist relationships\n",
      "   üìä Phase 1: with_users - Add user-playlist relationships\n",
      "   üìä Phase 1: full_graph - All edge types\n",
      "   üé® Phase 2: playlist_features - Only playlist features (6D) on baseline graph\n",
      "   üé® Phase 2: track_features - Only track features (4D) on baseline graph\n",
      "   üé® Phase 2: user_features - Only user features (4D) on baseline graph\n",
      "   üé® Phase 2: all_features - All feature types combined on baseline graph\n",
      "\n",
      "‚úÖ Phase separation complete:\n",
      "   Phase 1 (Graph Structure): ['baseline', 'with_artists', 'with_users', 'full_graph']\n",
      "   Phase 2 (Feature Importance): ['playlist_features', 'track_features', 'user_features', 'all_features']\n",
      "üî¨ Phase 3 Combined Results Selector Initialized\n",
      "   üìä Total configurations loaded: 8\n",
      "   üìä Phase 1 configs (graph structure): 4\n",
      "   üìä Phase 2 configs (feature importance): 4\n",
      "   üìã Statistical criteria:\n",
      "      ‚Ä¢ Significance: p < 0.05\n",
      "      ‚Ä¢ Effect size: Cohen's d > 0.2\n",
      "      ‚Ä¢ Feature improvement: >5.0%\n",
      "\n",
      "üéØ PHASE 3: EMPIRICAL CONFIGURATION SELECTION\n",
      "================================================================================\n",
      "\n",
      "üîó PHASE 1 ANALYSIS: Edge Type Selection\n",
      "============================================================\n",
      "üìä Phase 1 Configuration Rankings (by NDCG@10):\n",
      "   1. baseline: 0.5229 ¬± 0.0106\n",
      "   2. with_users: 0.5093 ¬± 0.0102\n",
      "   3. with_artists: 0.4019 ¬± 0.0039\n",
      "   4. full_graph: 0.3390 ¬± 0.0054\n",
      "   ‚úÖ Selected: baseline (best performing)\n",
      "\n",
      "üéØ Final Edge Type Selection: ['playlist_track']\n",
      "\n",
      "üé® PHASE 2 ANALYSIS: Feature Type Selection\n",
      "============================================================\n",
      "üìä Baseline Performance (Structure-only): 0.5229\n",
      "   ‚Ä¢ playlist_features: 0.5375 (+2.8% vs baseline)\n",
      "   ‚Ä¢ track_features: 0.4418 (-15.5% vs baseline)\n",
      "   ‚Ä¢ user_features: 0.5210 (-0.4% vs baseline)\n",
      "   ‚Ä¢ all_features: 0.4243 (-18.9% vs baseline)\n",
      "\n",
      "üèÜ Best Feature Configuration: playlist_features\n",
      "   ‚Ä¢ Performance: 0.5375\n",
      "   ‚Ä¢ Improvement: +2.8% vs baseline\n",
      "   ‚Ä¢ Threshold: 5.0%\n",
      "   ‚ùå Features not justified: 2.8% < 5.0%\n",
      "\n",
      "üéØ Final Feature Selection:\n",
      "   ‚Ä¢ Use features: False\n",
      "   ‚Ä¢ Feature types: []\n",
      "\n",
      "üèÜ OPTIMAL CONFIGURATION DETERMINED:\n",
      "==================================================\n",
      "Name: Dynamic Best Combined\n",
      "Description: Empirically determined best configuration based on statistical criteria from combined results\n",
      "Edge Types: ['playlist_track']\n",
      "Use Features: False\n",
      "Feature Types: []\n",
      "\n",
      "üìä SELECTION ANALYSIS COMPLETE\n",
      "   üîó Edge Selection: Baseline was best performing\n",
      "   üé® Feature Selection: Improvement 2.8% < 5.0% threshold\n",
      "   üéØ Final Configuration: Simple\n",
      "\n",
      "üìã PREDICTED OPTIMAL CONFIGURATION:\n",
      "   ‚Ä¢ Edge Types: ['playlist_track']\n",
      "   ‚Ä¢ Features: []\n",
      "   ‚Ä¢ Rationale: Baseline was best performing\n",
      "\n",
      "üöÄ STEP 2: Running Phase 3 experiment with optimal configuration...\n",
      "üéØ PHASE 3: EMPIRICAL CONFIGURATION SELECTION FROM COMBINED RESULTS\n",
      "================================================================================\n",
      "\n",
      "üîç Analyzing configurations to separate phases...\n",
      "   üìä Phase 1: baseline - Playlist-track edges only\n",
      "   üìä Phase 1: with_artists - Add track-artist relationships\n",
      "   üìä Phase 1: with_users - Add user-playlist relationships\n",
      "   üìä Phase 1: full_graph - All edge types\n",
      "   üé® Phase 2: playlist_features - Only playlist features (6D) on baseline graph\n",
      "   üé® Phase 2: track_features - Only track features (4D) on baseline graph\n",
      "   üé® Phase 2: user_features - Only user features (4D) on baseline graph\n",
      "   üé® Phase 2: all_features - All feature types combined on baseline graph\n",
      "\n",
      "‚úÖ Phase separation complete:\n",
      "   Phase 1 (Graph Structure): ['baseline', 'with_artists', 'with_users', 'full_graph']\n",
      "   Phase 2 (Feature Importance): ['playlist_features', 'track_features', 'user_features', 'all_features']\n",
      "üî¨ Phase 3 Combined Results Selector Initialized\n",
      "   üìä Total configurations loaded: 8\n",
      "   üìä Phase 1 configs (graph structure): 4\n",
      "   üìä Phase 2 configs (feature importance): 4\n",
      "   üìã Statistical criteria:\n",
      "      ‚Ä¢ Significance: p < 0.05\n",
      "      ‚Ä¢ Effect size: Cohen's d > 0.2\n",
      "      ‚Ä¢ Feature improvement: >5.0%\n",
      "\n",
      "üéØ PHASE 3: EMPIRICAL CONFIGURATION SELECTION\n",
      "================================================================================\n",
      "\n",
      "üîó PHASE 1 ANALYSIS: Edge Type Selection\n",
      "============================================================\n",
      "üìä Phase 1 Configuration Rankings (by NDCG@10):\n",
      "   1. baseline: 0.5229 ¬± 0.0106\n",
      "   2. with_users: 0.5093 ¬± 0.0102\n",
      "   3. with_artists: 0.4019 ¬± 0.0039\n",
      "   4. full_graph: 0.3390 ¬± 0.0054\n",
      "   ‚úÖ Selected: baseline (best performing)\n",
      "\n",
      "üéØ Final Edge Type Selection: ['playlist_track']\n",
      "\n",
      "üé® PHASE 2 ANALYSIS: Feature Type Selection\n",
      "============================================================\n",
      "üìä Baseline Performance (Structure-only): 0.5229\n",
      "   ‚Ä¢ playlist_features: 0.5375 (+2.8% vs baseline)\n",
      "   ‚Ä¢ track_features: 0.4418 (-15.5% vs baseline)\n",
      "   ‚Ä¢ user_features: 0.5210 (-0.4% vs baseline)\n",
      "   ‚Ä¢ all_features: 0.4243 (-18.9% vs baseline)\n",
      "\n",
      "üèÜ Best Feature Configuration: playlist_features\n",
      "   ‚Ä¢ Performance: 0.5375\n",
      "   ‚Ä¢ Improvement: +2.8% vs baseline\n",
      "   ‚Ä¢ Threshold: 5.0%\n",
      "   ‚ùå Features not justified: 2.8% < 5.0%\n",
      "\n",
      "üéØ Final Feature Selection:\n",
      "   ‚Ä¢ Use features: False\n",
      "   ‚Ä¢ Feature types: []\n",
      "\n",
      "üèÜ OPTIMAL CONFIGURATION DETERMINED:\n",
      "==================================================\n",
      "Name: Dynamic Best Combined\n",
      "Description: Empirically determined best configuration based on statistical criteria from combined results\n",
      "Edge Types: ['playlist_track']\n",
      "Use Features: False\n",
      "Feature Types: []\n",
      "üìÅ Result directories created in: ../results/lightgcn_experiments_enhanced\n",
      "üéØ Experiment Configuration:\n",
      "   üì± Device: cpu\n",
      "   üé≤ Seeds: 5 seeds\n",
      "   üìä Target playlists: 1,500\n",
      "   üß† Embedding dim: 128\n",
      "   ‚ö° Learning rate: 0.0005\n",
      "   üõ°Ô∏è Regularization: 0.001\n",
      "   üíæ Results dir: ../results/lightgcn_experiments_enhanced\n",
      "üìÅ Result directories created in: ../results/lightgcn_phase3_optimal_combined\n",
      "\n",
      "üìÅ Phase 3 results will be saved to: ../results/lightgcn_phase3_optimal_combined\n",
      "üéµ Loading Spotify data from: ../data/processed/spotify_scaled_hybrid_tiny.json\n",
      "‚úÖ Loaded 299 playlists\n",
      "üìä Dataset statistics:\n",
      "   ‚Ä¢ Playlists: 299\n",
      "   ‚Ä¢ Tracks: 10,631\n",
      "   ‚Ä¢ Artists: 4,164\n",
      "   ‚Ä¢ Albums: 6,966\n",
      "   ‚Ä¢ Users: 252\n",
      "üìà Extracted edges:\n",
      "   ‚Ä¢ playlist_track: 13,107 edges\n",
      "   ‚Ä¢ track_artist: 10,631 edges\n",
      "   ‚Ä¢ user_playlist: 299 edges\n",
      "   ‚Ä¢ track_album: 10,631 edges\n",
      "üìã Data splits:\n",
      "   ‚Ä¢ Train: 9,174 edges (70.0%)\n",
      "   ‚Ä¢ Validation: 1,966 edges (15.0%)\n",
      "   ‚Ä¢ Test: 1,967 edges (15.0%)\n",
      "üé® Generated features:\n",
      "   ‚Ä¢ playlist: (299, 6)\n",
      "   ‚Ä¢ track: (10631, 4)\n",
      "   ‚Ä¢ user: (252, 4)\n",
      "   ‚Ä¢ artist: (4164, 4)\n",
      "   ‚Ä¢ album: (6966, 4)\n",
      "üéØ Model Trainer initialized:\n",
      "   üë• Playlists: 299\n",
      "   üéµ Tracks: 10,631\n",
      "   üë§ Users: 252\n",
      "üéØ PHASE 3 EXPERIMENT RUNNER INITIALIZED\n",
      "   üìä Dataset: 299 playlists\n",
      "   üé≤ Seeds: 5\n",
      "   üìÅ Results dir: ../results/lightgcn_phase3_optimal_combined\n",
      "   üïê Timestamp: 20250817_163132\n",
      "\n",
      "================================================================================\n",
      "üî¨ PHASE 3: OPTIMAL CONFIGURATION EXPERIMENT\n",
      "================================================================================\n",
      "\n",
      "üß™ Configuration: Dynamic Best Combined\n",
      "üìù Empirically determined best configuration based on statistical criteria from combined results\n",
      "üîó Edge types: ['playlist_track']\n",
      "üé® Features: None\n",
      "üíæ Phase 3 setup saved: phase3_setup_20250817_163132.json\n",
      "\n",
      "üé≤ Seed 1/5 (seed=42):\n",
      "\n",
      "üöÄ Training: Dynamic Best Combined (seed=42)\n",
      "   üìù Empirically determined best configuration based on statistical criteria from combined results\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3601, Val=0.4914\n",
      "      Epoch 100: Train=0.3604, Val=0.5454\n",
      "      Epoch 150: Train=0.3561, Val=0.5895\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: Dynamic Best Combined_seed42_20250817_163132.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.5109, AUC: 0.7687\n",
      "      üìä NDCG@10: 0.5109\n",
      "      üìä AUC: 0.7687\n",
      "      ‚è±Ô∏è Time: 632.5s\n",
      "\n",
      "üé≤ Seed 2/5 (seed=123):\n",
      "\n",
      "üöÄ Training: Dynamic Best Combined (seed=123)\n",
      "   üìù Empirically determined best configuration based on statistical criteria from combined results\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3590, Val=0.4925\n",
      "      Epoch 100: Train=0.3595, Val=0.5422\n",
      "      Epoch 150: Train=0.3564, Val=0.5877\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: Dynamic Best Combined_seed123_20250817_164206.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.5151, AUC: 0.7727\n",
      "      üìä NDCG@10: 0.5151\n",
      "      üìä AUC: 0.7727\n",
      "      ‚è±Ô∏è Time: 634.7s\n",
      "\n",
      "üé≤ Seed 3/5 (seed=456):\n",
      "\n",
      "üöÄ Training: Dynamic Best Combined (seed=456)\n",
      "   üìù Empirically determined best configuration based on statistical criteria from combined results\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3599, Val=0.4950\n",
      "      Epoch 100: Train=0.3596, Val=0.5433\n",
      "      Epoch 150: Train=0.3559, Val=0.5973\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: Dynamic Best Combined_seed456_20250817_165241.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.5214, AUC: 0.7704\n",
      "      üìä NDCG@10: 0.5214\n",
      "      üìä AUC: 0.7704\n",
      "      ‚è±Ô∏è Time: 631.0s\n",
      "\n",
      "üé≤ Seed 4/5 (seed=789):\n",
      "\n",
      "üöÄ Training: Dynamic Best Combined (seed=789)\n",
      "   üìù Empirically determined best configuration based on statistical criteria from combined results\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3603, Val=0.4925\n",
      "      Epoch 100: Train=0.3601, Val=0.5425\n",
      "      Epoch 150: Train=0.3560, Val=0.5868\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: Dynamic Best Combined_seed789_20250817_170313.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.5306, AUC: 0.7764\n",
      "      üìä NDCG@10: 0.5306\n",
      "      üìä AUC: 0.7764\n",
      "      ‚è±Ô∏è Time: 631.9s\n",
      "\n",
      "üé≤ Seed 5/5 (seed=999):\n",
      "\n",
      "üöÄ Training: Dynamic Best Combined (seed=999)\n",
      "   üìù Empirically determined best configuration based on statistical criteria from combined results\n",
      "   üîó Building adjacency matrix: ['playlist_track']\n",
      "      üìä Adding playlist_track: 13,107 edges\n",
      "      ‚úÖ Total edges: 26,214\n",
      "      ‚úÖ Adjacency matrix: torch.Size([22312, 22312]), nnz: 48526\n",
      "   üß† LightGCN initialized:\n",
      "      üìè Nodes: 22,312, Embedding: 128, Layers: 2\n",
      "      üé® Features: P:False, T:False, U:False\n",
      "      üìä Dataset: 9,174 positive pairs\n",
      "      üìä Dataset: 1,966 positive pairs\n",
      "   üèÉ Training: 9,174 samples, validating: 1,966\n",
      "      Epoch 50: Train=0.3602, Val=0.4941\n",
      "      Epoch 100: Train=0.3604, Val=0.5493\n",
      "      Epoch 150: Train=0.3565, Val=0.5918\n",
      "      ‚è∞ Early stopping at epoch 160\n",
      "   ü§ñ Saved model checkpoint: Dynamic Best Combined_seed999_20250817_171345.pth\n",
      "   üìä Evaluating on test set...\n",
      "      ‚úÖ Evaluated 280 playlists\n",
      "      üìä NDCG@10: 0.5364, AUC: 0.7730\n",
      "      üìä NDCG@10: 0.5364\n",
      "      üìä AUC: 0.7730\n",
      "      ‚è±Ô∏è Time: 635.0s\n",
      "   üíæ Saved phase3_optimal results\n",
      "\n",
      "================================================================================\n",
      "üìä PHASE 3: OPTIMAL CONFIGURATION RESULTS\n",
      "================================================================================\n",
      "\n",
      "üèÜ EMPIRICALLY DETERMINED OPTIMAL CONFIGURATION:\n",
      "   Name: Dynamic Best Combined\n",
      "   Description: Empirically determined best configuration based on statistical criteria from combined results\n",
      "   Edge Types: ['playlist_track']\n",
      "   Features: None\n",
      "\n",
      "üìä PERFORMANCE METRICS:\n",
      "   ‚Ä¢ NDCG@10: 0.5229 ¬± 0.0106 (95% CI: [0.5098, 0.5360])\n",
      "   ‚Ä¢ NDCG@20: 0.5621 ¬± 0.0103 (95% CI: [0.5493, 0.5749])\n",
      "   ‚Ä¢ PRECISION@10: 0.3496 ¬± 0.0033 (95% CI: [0.3455, 0.3537])\n",
      "   ‚Ä¢ RECALL@10: 0.5454 ¬± 0.0064 (95% CI: [0.5375, 0.5534])\n",
      "   ‚Ä¢ AUC: 0.7722 ¬± 0.0029 (95% CI: [0.7686, 0.7759])\n",
      "\n",
      "‚è±Ô∏è TRAINING EFFICIENCY:\n",
      "   ‚Ä¢ Average training time: 633.0s (10.6 minutes)\n",
      "   ‚Ä¢ Seeds completed: 5/5\n",
      "\n",
      "üî¨ EMPIRICAL SELECTION SUMMARY:\n",
      "   ‚Ä¢ Edge selection: Baseline was best performing\n",
      "   ‚Ä¢ Feature selection: Improvement 2.8% < 5.0% threshold\n",
      "\n",
      "‚úÖ Phase 3 experiment completed successfully!\n",
      "üìÅ Results saved with timestamp: 20250817_163132\n",
      "üì¶ Complete results saved: complete_results_20250817_163132.json\n",
      "üìã Experiment summary saved: experiment_summary_20250817_163132.txt\n",
      "\n",
      "üéâ Phase 3 experiments completed successfully!\n",
      "üìä Empirical selection from combined results successful\n",
      "üìÅ All results saved to: ../results/lightgcn_phase3_optimal_combined\n",
      "\n",
      "üéâ Phase 3 completed successfully!\n",
      "üìä Key results:\n",
      "   ‚Ä¢ NDCG@10: 0.5229 ¬± 0.0106\n",
      "   ‚Ä¢ AUC: 0.7722 ¬± 0.0029\n",
      "   ‚Ä¢ Configuration: ['playlist_track'] + []\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
