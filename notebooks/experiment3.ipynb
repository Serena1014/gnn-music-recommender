{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T22:45:58.762399Z",
     "start_time": "2025-08-13T21:46:28.506698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# REVISED CODE: DYNAMIC PHASE 3 BASED ON EXISTING EXPERIMENT 1 & 2 RESULTS\n",
    "# =============================================================================\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy import stats as scipy_stats\n",
    "\n",
    "class DynamicPhase3ConfigGenerator:\n",
    "    \"\"\"Generate Phase 3 configuration based on existing Phase 1 & 2 results\"\"\"\n",
    "\n",
    "    def __init__(self, results_file_path=None, phase1_results=None, phase2_results=None):\n",
    "        \"\"\"\n",
    "        Initialize with either:\n",
    "        1. Path to JSON results file from previous experiments, OR\n",
    "        2. Direct results dictionaries from Phase 1 & 2\n",
    "        \"\"\"\n",
    "        if results_file_path:\n",
    "            with open(results_file_path, 'r') as f:\n",
    "                all_results = json.load(f)\n",
    "            self.phase1_results, self.phase2_results = self._extract_phases(all_results)\n",
    "        else:\n",
    "            self.phase1_results = phase1_results\n",
    "            self.phase2_results = phase2_results\n",
    "\n",
    "    def _extract_phases(self, all_results):\n",
    "        \"\"\"Extract Phase 1 and Phase 2 results from combined results\"\"\"\n",
    "        phase1_configs = ['baseline', 'with_artists', 'with_users', 'full_graph']\n",
    "        phase2_configs = ['features_basic', 'features_audio']\n",
    "\n",
    "        phase1_results = {k: v for k, v in all_results.items() if k in phase1_configs}\n",
    "        phase2_results = {k: v for k, v in all_results.items() if k in phase2_configs}\n",
    "\n",
    "        return phase1_results, phase2_results\n",
    "\n",
    "    def determine_best_edge_types(self, metric='ndcg@10', significance_threshold=0.05, min_effect_size=0.2):\n",
    "        \"\"\"\n",
    "        Determine best edge types from Phase 1 results\n",
    "\n",
    "        Args:\n",
    "            metric: Performance metric to optimize ('ndcg@10', 'precision@10', etc.)\n",
    "            significance_threshold: p-value threshold for statistical significance\n",
    "            min_effect_size: Minimum Cohen's d for practical significance\n",
    "        \"\"\"\n",
    "        print(f\"🔍 Analyzing Phase 1 results to determine best edge types...\")\n",
    "        print(f\"   📊 Metric: {metric}\")\n",
    "        print(f\"   📈 Significance threshold: {significance_threshold}\")\n",
    "        print(f\"   📏 Minimum effect size: {min_effect_size}\")\n",
    "\n",
    "        # Extract performance scores for each configuration\n",
    "        config_scores = {}\n",
    "        config_details = {}\n",
    "\n",
    "        for config_name, results in self.phase1_results.items():\n",
    "            if 'statistics' in results and metric in results['statistics']:\n",
    "                mean_score = results['statistics'][metric]['mean']\n",
    "                config_scores[config_name] = mean_score\n",
    "                config_details[config_name] = {\n",
    "                    'edge_types': results['config']['edge_types'],\n",
    "                    'mean': mean_score,\n",
    "                    'std': results['statistics'][metric].get('std', 0),\n",
    "                    'n': results['statistics'][metric].get('n', 5)\n",
    "                }\n",
    "                print(f\"      {config_name}: {mean_score:.4f} ± {results['statistics'][metric].get('std', 0):.4f}\")\n",
    "\n",
    "        # Find the configuration with highest performance\n",
    "        best_config_name = max(config_scores, key=config_scores.get)\n",
    "        best_edge_types = config_details[best_config_name]['edge_types']\n",
    "\n",
    "        print(f\"\\n   🏆 Highest performing: {best_config_name} ({config_scores[best_config_name]:.4f})\")\n",
    "        print(f\"   🔗 Edge types: {best_edge_types}\")\n",
    "\n",
    "        # Validate statistical significance vs baseline\n",
    "        if 'baseline' in config_details and best_config_name != 'baseline':\n",
    "            # Simulate t-test (since we only have summary statistics)\n",
    "            baseline_mean = config_details['baseline']['mean']\n",
    "            baseline_std = config_details['baseline']['std']\n",
    "            best_mean = config_details[best_config_name]['mean']\n",
    "            best_std = config_details[best_config_name]['std']\n",
    "            n = config_details[best_config_name]['n']\n",
    "\n",
    "            # Calculate effect size (Cohen's d)\n",
    "            pooled_std = np.sqrt((baseline_std**2 + best_std**2) / 2)\n",
    "            cohens_d = (best_mean - baseline_mean) / pooled_std if pooled_std > 0 else 0\n",
    "\n",
    "            # Estimate p-value using effect size and sample size\n",
    "            se_diff = pooled_std * np.sqrt(2/n)\n",
    "            t_stat = (best_mean - baseline_mean) / se_diff if se_diff > 0 else 0\n",
    "            p_value = 2 * (1 - scipy_stats.t.cdf(abs(t_stat), df=2*n-2))\n",
    "\n",
    "            improvement_pct = ((best_mean - baseline_mean) / baseline_mean * 100) if baseline_mean > 0 else 0\n",
    "\n",
    "            print(f\"\\n   📊 Statistical Analysis vs Baseline:\")\n",
    "            print(f\"      Improvement: {improvement_pct:+.1f}%\")\n",
    "            print(f\"      Cohen's d: {cohens_d:.3f}\")\n",
    "            print(f\"      Estimated p-value: {p_value:.4f}\")\n",
    "\n",
    "            # Check if improvement is significant and meaningful\n",
    "            if p_value < significance_threshold and cohens_d >= min_effect_size:\n",
    "                print(f\"   ✅ {best_config_name} is statistically and practically significant!\")\n",
    "                return best_edge_types, {\n",
    "                    'selected_config': best_config_name,\n",
    "                    'performance': best_mean,\n",
    "                    'improvement_vs_baseline': improvement_pct,\n",
    "                    'statistical_significance': True,\n",
    "                    'p_value': p_value,\n",
    "                    'effect_size': cohens_d\n",
    "                }\n",
    "            else:\n",
    "                print(f\"   ⚠️  Improvement not significant enough, falling back to baseline\")\n",
    "                return config_details['baseline']['edge_types'], {\n",
    "                    'selected_config': 'baseline',\n",
    "                    'performance': baseline_mean,\n",
    "                    'fallback_reason': f\"p={p_value:.4f} > {significance_threshold} or d={cohens_d:.3f} < {min_effect_size}\"\n",
    "                }\n",
    "        else:\n",
    "            return best_edge_types, {\n",
    "                'selected_config': best_config_name,\n",
    "                'performance': config_scores[best_config_name],\n",
    "                'note': 'No baseline comparison available'\n",
    "            }\n",
    "\n",
    "    def determine_best_features(self, metric='ndcg@10', min_improvement_threshold=0.05):\n",
    "        \"\"\"\n",
    "        Determine best feature types from Phase 2 results\n",
    "\n",
    "        Args:\n",
    "            metric: Performance metric to optimize\n",
    "            min_improvement_threshold: Minimum improvement to justify using features (5% default)\n",
    "        \"\"\"\n",
    "        print(f\"\\n🔍 Analyzing Phase 2 results to determine best features...\")\n",
    "        print(f\"   📊 Metric: {metric}\")\n",
    "        print(f\"   📈 Minimum improvement threshold: {min_improvement_threshold*100}%\")\n",
    "\n",
    "        # Extract feature performance\n",
    "        feature_scores = {}\n",
    "        feature_details = {}\n",
    "\n",
    "        for config_name, results in self.phase2_results.items():\n",
    "            if 'statistics' in results and metric in results['statistics']:\n",
    "                mean_score = results['statistics'][metric]['mean']\n",
    "                feature_scores[config_name] = mean_score\n",
    "                feature_details[config_name] = {\n",
    "                    'feature_types': results['config']['feature_types'],\n",
    "                    'mean': mean_score,\n",
    "                    'std': results['statistics'][metric].get('std', 0)\n",
    "                }\n",
    "                print(f\"      {config_name}: {mean_score:.4f} ± {results['statistics'][metric].get('std', 0):.4f}\")\n",
    "\n",
    "        if not feature_scores:\n",
    "            print(\"   ❌ No Phase 2 results found!\")\n",
    "            return [], {'selected_config': 'no_features', 'reason': 'No Phase 2 results available'}\n",
    "\n",
    "        # Find best feature configuration\n",
    "        best_feature_config = max(feature_scores, key=feature_scores.get)\n",
    "        best_feature_types = feature_details[best_feature_config]['feature_types']\n",
    "        best_score = feature_scores[best_feature_config]\n",
    "\n",
    "        print(f\"\\n   🏆 Highest performing: {best_feature_config} ({best_score:.4f})\")\n",
    "        print(f\"   🎯 Feature types: {best_feature_types}\")\n",
    "\n",
    "        # Check if features provide meaningful improvement\n",
    "        # (Compare against baseline performance from Phase 1 if available)\n",
    "        baseline_performance = None\n",
    "        if self.phase1_results and 'baseline' in self.phase1_results:\n",
    "            baseline_stats = self.phase1_results['baseline'].get('statistics', {})\n",
    "            baseline_performance = baseline_stats.get(metric, {}).get('mean', 0)\n",
    "\n",
    "        if baseline_performance:\n",
    "            improvement = (best_score - baseline_performance) / baseline_performance\n",
    "            print(f\"   📈 Improvement vs structure-only baseline: {improvement*100:+.1f}%\")\n",
    "\n",
    "            if improvement >= min_improvement_threshold:\n",
    "                print(f\"   ✅ Features provide meaningful improvement!\")\n",
    "                return best_feature_types, {\n",
    "                    'selected_config': best_feature_config,\n",
    "                    'performance': best_score,\n",
    "                    'improvement_vs_baseline': improvement*100,\n",
    "                    'use_features': True\n",
    "                }\n",
    "            else:\n",
    "                print(f\"   ⚠️  Feature improvement below threshold, not using features\")\n",
    "                return [], {\n",
    "                    'selected_config': 'no_features',\n",
    "                    'reason': f'Improvement {improvement*100:.1f}% < {min_improvement_threshold*100}% threshold'\n",
    "                }\n",
    "        else:\n",
    "            # If no baseline comparison, use features if they exist\n",
    "            return best_feature_types, {\n",
    "                'selected_config': best_feature_config,\n",
    "                'performance': best_score,\n",
    "                'note': 'No baseline comparison available, using best feature config'\n",
    "            }\n",
    "\n",
    "    def generate_dynamic_phase3_config(self, metric='ndcg@10'):\n",
    "        \"\"\"Generate the optimal Phase 3 configuration based on empirical results\"\"\"\n",
    "        print(\"=\"*80)\n",
    "        print(\"🔬 GENERATING DYNAMIC PHASE 3 CONFIGURATION\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        # Determine best edge types from Phase 1\n",
    "        best_edge_types, edge_analysis = self.determine_best_edge_types(metric=metric)\n",
    "\n",
    "        # Determine best feature types from Phase 2\n",
    "        best_feature_types, feature_analysis = self.determine_best_features(metric=metric)\n",
    "\n",
    "        # Create the dynamic configuration\n",
    "        dynamic_config = {\n",
    "            \"name\": \"Dynamic Best Combined\",\n",
    "            \"description\": f\"Empirically determined best configuration based on {metric}\",\n",
    "            \"edge_types\": best_edge_types,\n",
    "            \"use_features\": len(best_feature_types) > 0,\n",
    "            \"feature_types\": best_feature_types\n",
    "        }\n",
    "\n",
    "        # Create analysis summary\n",
    "        analysis_summary = {\n",
    "            'optimization_metric': metric,\n",
    "            'edge_selection': edge_analysis,\n",
    "            'feature_selection': feature_analysis,\n",
    "            'final_config': dynamic_config\n",
    "        }\n",
    "\n",
    "        print(f\"\\n🎯 FINAL DYNAMIC CONFIGURATION:\")\n",
    "        print(f\"   📊 Optimization metric: {metric}\")\n",
    "        print(f\"   🔗 Selected edge types: {best_edge_types}\")\n",
    "        print(f\"   🎯 Selected feature types: {best_feature_types}\")\n",
    "        print(f\"   🔄 Use features: {len(best_feature_types) > 0}\")\n",
    "\n",
    "        return dynamic_config, analysis_summary\n",
    "\n",
    "# =============================================================================\n",
    "# REVISED EXPERIMENT RUNNER FOR PHASE 3 ONLY\n",
    "# =============================================================================\n",
    "\n",
    "class Phase3OnlyExperimentRunner:\n",
    "    \"\"\"Run only Phase 3 with dynamically determined configuration\"\"\"\n",
    "\n",
    "    def __init__(self, config, data, existing_results_path=None):\n",
    "        self.config = config\n",
    "        self.data = data\n",
    "        self.trainer = ImprovedExperimentTrainer(config, data)\n",
    "        self.existing_results_path = existing_results_path\n",
    "\n",
    "    def run_dynamic_phase3_experiment(self, optimization_metric='ndcg@10'):\n",
    "        \"\"\"Run Phase 3 experiment with dynamically determined configuration\"\"\"\n",
    "\n",
    "        print(\"🚀 STARTING DYNAMIC PHASE 3 EXPERIMENT\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        # 1. Generate dynamic configuration based on existing results\n",
    "        if self.existing_results_path:\n",
    "            config_generator = DynamicPhase3ConfigGenerator(\n",
    "                results_file_path=self.existing_results_path\n",
    "            )\n",
    "        else:\n",
    "            print(\"❌ Error: No existing results file provided!\")\n",
    "            return None\n",
    "\n",
    "        # 2. Determine optimal configuration\n",
    "        dynamic_config, analysis_summary = config_generator.generate_dynamic_phase3_config(\n",
    "            metric=optimization_metric\n",
    "        )\n",
    "\n",
    "        # 3. Run the experiment with the dynamic configuration\n",
    "        print(f\"\\n🧪 Running experiment with dynamic configuration...\")\n",
    "\n",
    "        phase3_results = []\n",
    "\n",
    "        # Run with multiple seeds for statistical robustness\n",
    "        for seed_idx, seed in enumerate(self.config.random_seeds):\n",
    "            print(f\"\\n🎲 Seed {seed_idx+1}/{len(self.config.random_seeds)} (seed={seed}):\")\n",
    "\n",
    "            # Train model\n",
    "            training_result = self.trainer.train_model(dynamic_config, seed=seed)\n",
    "\n",
    "            if training_result is None:\n",
    "                print(f\"   ❌ Training failed for seed {seed}\")\n",
    "                continue\n",
    "\n",
    "            # Evaluate on test set\n",
    "            test_metrics = self.trainer.evaluate_model(\n",
    "                training_result['model'],\n",
    "                training_result['adj_matrix'],\n",
    "                'test',\n",
    "                seed=seed\n",
    "            )\n",
    "\n",
    "            # Store results\n",
    "            run_result = {\n",
    "                'seed': seed,\n",
    "                'metrics': test_metrics,\n",
    "                'training_time': training_result['training_time'],\n",
    "                'final_loss': training_result['final_loss'],\n",
    "                'best_val_loss': training_result['best_val_loss']\n",
    "            }\n",
    "            phase3_results.append(run_result)\n",
    "\n",
    "            # Print immediate results\n",
    "            print(f\"      📊 NDCG@10: {test_metrics.get('ndcg@10', 0):.4f}\")\n",
    "            print(f\"      📊 AUC: {test_metrics.get('auc', 0):.4f}\")\n",
    "            print(f\"      ⏱️ Time: {training_result['training_time']:.1f}s\")\n",
    "\n",
    "            # Memory cleanup\n",
    "            del training_result\n",
    "            gc.collect()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        # 4. Calculate statistics for Phase 3 results\n",
    "        if phase3_results:\n",
    "            phase3_stats = self._calculate_statistics(phase3_results)\n",
    "\n",
    "            final_results = {\n",
    "                'dynamic_best_combined': {\n",
    "                    'config': dynamic_config,\n",
    "                    'runs': phase3_results,\n",
    "                    'statistics': phase3_stats\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # 5. Print summary\n",
    "            self._print_phase3_summary(final_results, analysis_summary)\n",
    "\n",
    "            return {\n",
    "                'results': final_results,\n",
    "                'analysis_summary': analysis_summary,\n",
    "                'optimization_metric': optimization_metric\n",
    "            }\n",
    "        else:\n",
    "            print(\"❌ No successful runs in Phase 3!\")\n",
    "            return None\n",
    "\n",
    "    def _calculate_statistics(self, phase3_results):\n",
    "        \"\"\"Calculate statistics for Phase 3 results\"\"\"\n",
    "        statistics = {}\n",
    "\n",
    "        # Get all metric names\n",
    "        all_metrics = set()\n",
    "        for run in phase3_results:\n",
    "            all_metrics.update(run['metrics'].keys())\n",
    "\n",
    "        # Calculate statistics for each metric\n",
    "        for metric in all_metrics:\n",
    "            values = [run['metrics'].get(metric, 0) for run in phase3_results]\n",
    "\n",
    "            if values and len(values) > 1:\n",
    "                mean_val = np.mean(values)\n",
    "                std_val = np.std(values, ddof=1)\n",
    "                n = len(values)\n",
    "\n",
    "                # Calculate confidence intervals\n",
    "                if n > 2:\n",
    "                    t_value = scipy_stats.t.ppf(0.975, n-1)\n",
    "                    margin_error = t_value * std_val / np.sqrt(n)\n",
    "                    ci_lower = mean_val - margin_error\n",
    "                    ci_upper = mean_val + margin_error\n",
    "                else:\n",
    "                    ci_lower = mean_val\n",
    "                    ci_upper = mean_val\n",
    "\n",
    "                statistics[metric] = {\n",
    "                    'mean': mean_val,\n",
    "                    'std': std_val,\n",
    "                    'min': np.min(values),\n",
    "                    'max': np.max(values),\n",
    "                    'ci_lower': ci_lower,\n",
    "                    'ci_upper': ci_upper,\n",
    "                    'n': n\n",
    "                }\n",
    "\n",
    "        return statistics\n",
    "\n",
    "    def _print_phase3_summary(self, results, analysis_summary):\n",
    "        \"\"\"Print comprehensive Phase 3 summary\"\"\"\n",
    "        print(f\"\\n\" + \"=\"*80)\n",
    "        print(f\"📊 DYNAMIC PHASE 3 RESULTS SUMMARY\")\n",
    "        print(f\"=\"*80)\n",
    "\n",
    "        config_result = results['dynamic_best_combined']\n",
    "        stats = config_result['statistics']\n",
    "\n",
    "        # Print configuration details\n",
    "        print(f\"\\n🎯 CONFIGURATION USED:\")\n",
    "        print(f\"   📊 Optimization metric: {analysis_summary['optimization_metric']}\")\n",
    "        print(f\"   🔗 Edge types: {config_result['config']['edge_types']}\")\n",
    "        print(f\"   🎯 Feature types: {config_result['config']['feature_types']}\")\n",
    "        print(f\"   🔄 Uses features: {config_result['config']['use_features']}\")\n",
    "\n",
    "        # Print performance results\n",
    "        ndcg_mean = stats.get('ndcg@10', {}).get('mean', 0)\n",
    "        ndcg_std = stats.get('ndcg@10', {}).get('std', 0)\n",
    "        ndcg_ci_lower = stats.get('ndcg@10', {}).get('ci_lower', 0)\n",
    "        ndcg_ci_upper = stats.get('ndcg@10', {}).get('ci_upper', 0)\n",
    "\n",
    "        print(f\"\\n📈 PERFORMANCE RESULTS:\")\n",
    "        print(f\"   NDCG@10: {ndcg_mean:.4f} ± {ndcg_std:.4f}\")\n",
    "        print(f\"   95% CI: [{ndcg_ci_lower:.4f}, {ndcg_ci_upper:.4f}]\")\n",
    "\n",
    "        if 'auc' in stats:\n",
    "            auc_mean = stats['auc']['mean']\n",
    "            auc_std = stats['auc']['std']\n",
    "            print(f\"   AUC: {auc_mean:.4f} ± {auc_std:.4f}\")\n",
    "\n",
    "        # Print selection rationale\n",
    "        print(f\"\\n🔍 SELECTION RATIONALE:\")\n",
    "        edge_rationale = analysis_summary['edge_selection']\n",
    "        feature_rationale = analysis_summary['feature_selection']\n",
    "\n",
    "        print(f\"   🔗 Edge Selection: {edge_rationale.get('selected_config', 'unknown')}\")\n",
    "        if 'improvement_vs_baseline' in edge_rationale:\n",
    "            print(f\"      Improvement vs baseline: {edge_rationale['improvement_vs_baseline']:+.1f}%\")\n",
    "\n",
    "        print(f\"   🎯 Feature Selection: {feature_rationale.get('selected_config', 'unknown')}\")\n",
    "        if 'improvement_vs_baseline' in feature_rationale:\n",
    "            print(f\"      Improvement vs baseline: {feature_rationale['improvement_vs_baseline']:+.1f}%\")\n",
    "\n",
    "# =============================================================================\n",
    "# USAGE EXAMPLE\n",
    "# =============================================================================\n",
    "\n",
    "def run_dynamic_phase3_only(existing_results_file, target_playlists=1500, optimization_metric='ndcg@10'):\n",
    "    \"\"\"\n",
    "    Run only Phase 3 with configuration determined from existing Phase 1 & 2 results\n",
    "\n",
    "    Args:\n",
    "        existing_results_file: Path to JSON file containing Phase 1 & 2 results\n",
    "        target_playlists: Number of playlists for the experiment\n",
    "        optimization_metric: Metric to optimize for ('ndcg@10', 'precision@10', etc.)\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Initialize configuration\n",
    "        config = FixedExperimentConfig()\n",
    "        config.target_playlists = target_playlists\n",
    "\n",
    "        # Generate data (same as before)\n",
    "        print(f\"🎵 Generating data for {target_playlists} playlists...\")\n",
    "        data_generator = ImprovedSyntheticMusicDataGenerator(config)\n",
    "        data = data_generator.generate_heterogeneous_data(seed=42)\n",
    "\n",
    "        # Initialize Phase 3 runner\n",
    "        runner = Phase3OnlyExperimentRunner(\n",
    "            config=config,\n",
    "            data=data,\n",
    "            existing_results_path=existing_results_file\n",
    "        )\n",
    "\n",
    "        # Run dynamic Phase 3 experiment\n",
    "        results = runner.run_dynamic_phase3_experiment(\n",
    "            optimization_metric=optimization_metric\n",
    "        )\n",
    "\n",
    "        if results:\n",
    "            # Save results\n",
    "            output_file = f\"dynamic_phase3_results_{optimization_metric}.json\"\n",
    "\n",
    "            # Convert results to serializable format\n",
    "            serializable_results = {\n",
    "                'dynamic_phase3': results['results'],\n",
    "                'analysis_summary': results['analysis_summary'],\n",
    "                'optimization_metric': optimization_metric\n",
    "            }\n",
    "\n",
    "            with open(output_file, 'w') as f:\n",
    "                json.dump(serializable_results, f, indent=2, default=str)\n",
    "\n",
    "            print(f\"\\n💾 Results saved to: {output_file}\")\n",
    "            print(f\"🎉 DYNAMIC PHASE 3 EXPERIMENT COMPLETED SUCCESSFULLY!\")\n",
    "\n",
    "            return results\n",
    "        else:\n",
    "            print(f\"❌ Dynamic Phase 3 experiment failed!\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in dynamic Phase 3 experiment: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# =============================================================================\n",
    "# EXAMPLE USAGE\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example: Run Phase 3 only using existing results\n",
    "\n",
    "    # Option 1: Use existing results file\n",
    "    results = run_dynamic_phase3_only(\n",
    "        existing_results_file=\"../results/fixed_lightgcn_experiments/improved_experiment_results.json\",\n",
    "        target_playlists=1500,\n",
    "        optimization_metric='ndcg@10'\n",
    "    )\n",
    "\n",
    "    # Option 2: If you want to try different optimization metrics\n",
    "    # results_precision = run_dynamic_phase3_only(\n",
    "    #     existing_results_file=\"../results/fixed_lightgcn_experiments/improved_experiment_results.json\",\n",
    "    #     optimization_metric='precision@10'\n",
    "    # )\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🎯 DYNAMIC PHASE 3 FRAMEWORK READY\")\n",
    "print(\"=\"*80)\n",
    "print(\"🚀 USAGE:\")\n",
    "print(\"   # Run Phase 3 only with empirically determined 'best' configuration\")\n",
    "print(\"   results = run_dynamic_phase3_only(\")\n",
    "print(\"       existing_results_file='path/to/your/phase1_phase2_results.json',\")\n",
    "print(\"       optimization_metric='ndcg@10'\")\n",
    "print(\"   )\")\n",
    "print()\n",
    "print(\"🔧 FEATURES:\")\n",
    "print(\"   ✅ Empirically determines best edge types from Phase 1 results\")\n",
    "print(\"   ✅ Empirically determines best feature types from Phase 2 results\")\n",
    "print(\"   ✅ Statistical significance testing for configuration selection\")\n",
    "print(\"   ✅ Effect size analysis for practical significance\")\n",
    "print(\"   ✅ Configurable optimization metrics\")\n",
    "print(\"   ✅ Comprehensive analysis and rationale reporting\")\n",
    "print(\"   ✅ Only runs Phase 3 - no need to repeat Phase 1 & 2\")\n",
    "print(\"=\"*80)"
   ],
   "id": "5b24ba4d89ef095b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Fixed Configuration loaded:\n",
      "   📱 Device: cpu\n",
      "   🎲 Seeds: 5 seeds\n",
      "   📊 Target playlists: 1,500\n",
      "   🧠 Embedding dim: 128\n",
      "   ⚡ Learning rate: 0.0005\n",
      "   🛡️ Regularization: 0.001\n",
      "🎵 Generating data for 1500 playlists...\n",
      "🎵 Improved Synthetic Data Generator:\n",
      "   📊 Playlists: 1,500\n",
      "   🎵 Tracks: 4,500\n",
      "   🎤 Artists: 500\n",
      "   💿 Albums: 500\n",
      "   👥 Users: 187\n",
      "🔧 Generating improved heterogeneous music data (seed=42)...\n",
      "   🔢 Total nodes: 7,187\n",
      "   🔗 Generating improved edge distributions...\n",
      "      ✅ playlist_track: 27,478 edges\n",
      "      ✅ track_artist: 5,171 edges\n",
      "      ✅ track_album: 4,500 edges\n",
      "      ✅ user_playlist: 981 edges\n",
      "   📊 Generating balanced splits...\n",
      "      ✅ train: 18,579 edges\n",
      "      ✅ val: 4,024 edges\n",
      "      ✅ test: 4,875 edges\n",
      "   🎯 Generating correlated features...\n",
      "      ✅ Generated correlated features for all node types\n",
      "🎯 Improved Experiment Trainer initialized:\n",
      "   👥 Playlists: 1,500\n",
      "   🎵 Tracks: 4,500\n",
      "   🔢 Total nodes: 7,187\n",
      "🚀 STARTING DYNAMIC PHASE 3 EXPERIMENT\n",
      "============================================================\n",
      "================================================================================\n",
      "🔬 GENERATING DYNAMIC PHASE 3 CONFIGURATION\n",
      "================================================================================\n",
      "🔍 Analyzing Phase 1 results to determine best edge types...\n",
      "   📊 Metric: ndcg@10\n",
      "   📈 Significance threshold: 0.05\n",
      "   📏 Minimum effect size: 0.2\n",
      "      baseline: 0.4441 ± 0.0082\n",
      "      with_artists: 0.4423 ± 0.0110\n",
      "      with_users: 0.4432 ± 0.0092\n",
      "      full_graph: 0.4377 ± 0.0096\n",
      "\n",
      "   🏆 Highest performing: baseline (0.4441)\n",
      "   🔗 Edge types: ['playlist_track']\n",
      "\n",
      "🔍 Analyzing Phase 2 results to determine best features...\n",
      "   📊 Metric: ndcg@10\n",
      "   📈 Minimum improvement threshold: 5.0%\n",
      "      features_basic: 0.4432 ± 0.0037\n",
      "      features_audio: 0.4456 ± 0.0042\n",
      "\n",
      "   🏆 Highest performing: features_audio (0.4456)\n",
      "   🎯 Feature types: ['audio']\n",
      "   📈 Improvement vs structure-only baseline: +0.3%\n",
      "   ⚠️  Feature improvement below threshold, not using features\n",
      "\n",
      "🎯 FINAL DYNAMIC CONFIGURATION:\n",
      "   📊 Optimization metric: ndcg@10\n",
      "   🔗 Selected edge types: ['playlist_track']\n",
      "   🎯 Selected feature types: []\n",
      "   🔄 Use features: False\n",
      "\n",
      "🧪 Running experiment with dynamic configuration...\n",
      "\n",
      "🎲 Seed 1/5 (seed=42):\n",
      "\n",
      "🚀 Training: Dynamic Best Combined (seed=42)\n",
      "   📝 Empirically determined best configuration based on ndcg@10\n",
      "   🔗 Building adjacency matrix: ['playlist_track']\n",
      "      📊 Adding playlist_track: 27,478 edges\n",
      "      ✅ Total edges: 54,956\n",
      "      ✅ Adjacency matrix: torch.Size([7187, 7187]), nnz: 62143\n",
      "   🧠 ImprovedLightGCN initialized:\n",
      "      📏 Total nodes: 7,187\n",
      "      📏 Embedding dim: 128\n",
      "      🔗 Layers: 2\n",
      "      👥 Playlist features: False\n",
      "      🎵 Track features: False\n",
      "      📊 Improved training dataset: 18,579 positive pairs\n",
      "      📊 Improved training dataset: 4,024 positive pairs\n",
      "   🏃 Training with 18,579 samples, validating with 4,024...\n",
      "      Epoch 50: Train Loss = 0.3974, Val Loss = 0.4361\n",
      "      Epoch 100: Train Loss = 0.4000, Val Loss = 0.4376\n",
      "      Epoch 150: Train Loss = 0.3951, Val Loss = 0.4376\n",
      "      ⏰ Early stopping at epoch 160\n",
      "   📊 Evaluating on test set...\n",
      "      ✅ Evaluation completed: 500 valid playlists\n",
      "      📊 NDCG@10: 0.4531\n",
      "      📊 AUC: 0.8997\n",
      "      📊 NDCG@10: 0.4531\n",
      "      📊 AUC: 0.8997\n",
      "      ⏱️ Time: 677.4s\n",
      "\n",
      "🎲 Seed 2/5 (seed=123):\n",
      "\n",
      "🚀 Training: Dynamic Best Combined (seed=123)\n",
      "   📝 Empirically determined best configuration based on ndcg@10\n",
      "   🔗 Building adjacency matrix: ['playlist_track']\n",
      "      📊 Adding playlist_track: 27,478 edges\n",
      "      ✅ Total edges: 54,956\n",
      "      ✅ Adjacency matrix: torch.Size([7187, 7187]), nnz: 62143\n",
      "   🧠 ImprovedLightGCN initialized:\n",
      "      📏 Total nodes: 7,187\n",
      "      📏 Embedding dim: 128\n",
      "      🔗 Layers: 2\n",
      "      👥 Playlist features: False\n",
      "      🎵 Track features: False\n",
      "      📊 Improved training dataset: 18,579 positive pairs\n",
      "      📊 Improved training dataset: 4,024 positive pairs\n",
      "   🏃 Training with 18,579 samples, validating with 4,024...\n",
      "      Epoch 50: Train Loss = 0.3977, Val Loss = 0.4347\n",
      "      Epoch 100: Train Loss = 0.4000, Val Loss = 0.4334\n",
      "      Epoch 150: Train Loss = 0.3968, Val Loss = 0.4395\n",
      "      ⏰ Early stopping at epoch 170\n",
      "   📊 Evaluating on test set...\n",
      "      ✅ Evaluation completed: 500 valid playlists\n",
      "      📊 NDCG@10: 0.4352\n",
      "      📊 AUC: 0.8966\n",
      "      📊 NDCG@10: 0.4352\n",
      "      📊 AUC: 0.8966\n",
      "      ⏱️ Time: 703.0s\n",
      "\n",
      "🎲 Seed 3/5 (seed=456):\n",
      "\n",
      "🚀 Training: Dynamic Best Combined (seed=456)\n",
      "   📝 Empirically determined best configuration based on ndcg@10\n",
      "   🔗 Building adjacency matrix: ['playlist_track']\n",
      "      📊 Adding playlist_track: 27,478 edges\n",
      "      ✅ Total edges: 54,956\n",
      "      ✅ Adjacency matrix: torch.Size([7187, 7187]), nnz: 62143\n",
      "   🧠 ImprovedLightGCN initialized:\n",
      "      📏 Total nodes: 7,187\n",
      "      📏 Embedding dim: 128\n",
      "      🔗 Layers: 2\n",
      "      👥 Playlist features: False\n",
      "      🎵 Track features: False\n",
      "      📊 Improved training dataset: 18,579 positive pairs\n",
      "      📊 Improved training dataset: 4,024 positive pairs\n",
      "   🏃 Training with 18,579 samples, validating with 4,024...\n",
      "      Epoch 50: Train Loss = 0.3981, Val Loss = 0.4324\n",
      "      Epoch 100: Train Loss = 0.4011, Val Loss = 0.4348\n",
      "      Epoch 150: Train Loss = 0.3965, Val Loss = 0.4379\n",
      "      ⏰ Early stopping at epoch 170\n",
      "   📊 Evaluating on test set...\n",
      "      ✅ Evaluation completed: 500 valid playlists\n",
      "      📊 NDCG@10: 0.4357\n",
      "      📊 AUC: 0.9013\n",
      "      📊 NDCG@10: 0.4357\n",
      "      📊 AUC: 0.9013\n",
      "      ⏱️ Time: 692.6s\n",
      "\n",
      "🎲 Seed 4/5 (seed=789):\n",
      "\n",
      "🚀 Training: Dynamic Best Combined (seed=789)\n",
      "   📝 Empirically determined best configuration based on ndcg@10\n",
      "   🔗 Building adjacency matrix: ['playlist_track']\n",
      "      📊 Adding playlist_track: 27,478 edges\n",
      "      ✅ Total edges: 54,956\n",
      "      ✅ Adjacency matrix: torch.Size([7187, 7187]), nnz: 62143\n",
      "   🧠 ImprovedLightGCN initialized:\n",
      "      📏 Total nodes: 7,187\n",
      "      📏 Embedding dim: 128\n",
      "      🔗 Layers: 2\n",
      "      👥 Playlist features: False\n",
      "      🎵 Track features: False\n",
      "      📊 Improved training dataset: 18,579 positive pairs\n",
      "      📊 Improved training dataset: 4,024 positive pairs\n",
      "   🏃 Training with 18,579 samples, validating with 4,024...\n",
      "      Epoch 50: Train Loss = 0.3975, Val Loss = 0.4368\n",
      "      Epoch 100: Train Loss = 0.4004, Val Loss = 0.4328\n",
      "      Epoch 150: Train Loss = 0.4003, Val Loss = 0.4395\n",
      "      Epoch 200: Train Loss = 0.3995, Val Loss = 0.4389\n",
      "   📊 Evaluating on test set...\n",
      "      ✅ Evaluation completed: 500 valid playlists\n",
      "      📊 NDCG@10: 0.4502\n",
      "      📊 AUC: 0.9061\n",
      "      📊 NDCG@10: 0.4502\n",
      "      📊 AUC: 0.9061\n",
      "      ⏱️ Time: 813.2s\n",
      "\n",
      "🎲 Seed 5/5 (seed=999):\n",
      "\n",
      "🚀 Training: Dynamic Best Combined (seed=999)\n",
      "   📝 Empirically determined best configuration based on ndcg@10\n",
      "   🔗 Building adjacency matrix: ['playlist_track']\n",
      "      📊 Adding playlist_track: 27,478 edges\n",
      "      ✅ Total edges: 54,956\n",
      "      ✅ Adjacency matrix: torch.Size([7187, 7187]), nnz: 62143\n",
      "   🧠 ImprovedLightGCN initialized:\n",
      "      📏 Total nodes: 7,187\n",
      "      📏 Embedding dim: 128\n",
      "      🔗 Layers: 2\n",
      "      👥 Playlist features: False\n",
      "      🎵 Track features: False\n",
      "      📊 Improved training dataset: 18,579 positive pairs\n",
      "      📊 Improved training dataset: 4,024 positive pairs\n",
      "   🏃 Training with 18,579 samples, validating with 4,024...\n",
      "      Epoch 50: Train Loss = 0.3974, Val Loss = 0.4364\n",
      "      Epoch 100: Train Loss = 0.3997, Val Loss = 0.4326\n",
      "      Epoch 150: Train Loss = 0.3980, Val Loss = 0.4416\n",
      "      ⏰ Early stopping at epoch 170\n",
      "   📊 Evaluating on test set...\n",
      "      ✅ Evaluation completed: 500 valid playlists\n",
      "      📊 NDCG@10: 0.4461\n",
      "      📊 AUC: 0.9010\n",
      "      📊 NDCG@10: 0.4461\n",
      "      📊 AUC: 0.9010\n",
      "      ⏱️ Time: 679.0s\n",
      "\n",
      "================================================================================\n",
      "📊 DYNAMIC PHASE 3 RESULTS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "🎯 CONFIGURATION USED:\n",
      "   📊 Optimization metric: ndcg@10\n",
      "   🔗 Edge types: ['playlist_track']\n",
      "   🎯 Feature types: []\n",
      "   🔄 Uses features: False\n",
      "\n",
      "📈 PERFORMANCE RESULTS:\n",
      "   NDCG@10: 0.4441 ± 0.0082\n",
      "   95% CI: [0.4338, 0.4543]\n",
      "   AUC: 0.9009 ± 0.0034\n",
      "\n",
      "🔍 SELECTION RATIONALE:\n",
      "   🔗 Edge Selection: baseline\n",
      "   🎯 Feature Selection: no_features\n",
      "\n",
      "💾 Results saved to: dynamic_phase3_results_ndcg@10.json\n",
      "🎉 DYNAMIC PHASE 3 EXPERIMENT COMPLETED SUCCESSFULLY!\n",
      "\n",
      "================================================================================\n",
      "🎯 DYNAMIC PHASE 3 FRAMEWORK READY\n",
      "================================================================================\n",
      "🚀 USAGE:\n",
      "   # Run Phase 3 only with empirically determined 'best' configuration\n",
      "   results = run_dynamic_phase3_only(\n",
      "       existing_results_file='path/to/your/phase1_phase2_results.json',\n",
      "       optimization_metric='ndcg@10'\n",
      "   )\n",
      "\n",
      "🔧 FEATURES:\n",
      "   ✅ Empirically determines best edge types from Phase 1 results\n",
      "   ✅ Empirically determines best feature types from Phase 2 results\n",
      "   ✅ Statistical significance testing for configuration selection\n",
      "   ✅ Effect size analysis for practical significance\n",
      "   ✅ Configurable optimization metrics\n",
      "   ✅ Comprehensive analysis and rationale reporting\n",
      "   ✅ Only runs Phase 3 - no need to repeat Phase 1 & 2\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
