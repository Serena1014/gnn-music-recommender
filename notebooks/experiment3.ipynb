{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T22:45:58.762399Z",
     "start_time": "2025-08-13T21:46:28.506698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# REVISED CODE: DYNAMIC PHASE 3 BASED ON EXISTING EXPERIMENT 1 & 2 RESULTS\n",
    "# =============================================================================\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy import stats as scipy_stats\n",
    "\n",
    "class DynamicPhase3ConfigGenerator:\n",
    "    \"\"\"Generate Phase 3 configuration based on existing Phase 1 & 2 results\"\"\"\n",
    "\n",
    "    def __init__(self, results_file_path=None, phase1_results=None, phase2_results=None):\n",
    "        \"\"\"\n",
    "        Initialize with either:\n",
    "        1. Path to JSON results file from previous experiments, OR\n",
    "        2. Direct results dictionaries from Phase 1 & 2\n",
    "        \"\"\"\n",
    "        if results_file_path:\n",
    "            with open(results_file_path, 'r') as f:\n",
    "                all_results = json.load(f)\n",
    "            self.phase1_results, self.phase2_results = self._extract_phases(all_results)\n",
    "        else:\n",
    "            self.phase1_results = phase1_results\n",
    "            self.phase2_results = phase2_results\n",
    "\n",
    "    def _extract_phases(self, all_results):\n",
    "        \"\"\"Extract Phase 1 and Phase 2 results from combined results\"\"\"\n",
    "        phase1_configs = ['baseline', 'with_artists', 'with_users', 'full_graph']\n",
    "        phase2_configs = ['features_basic', 'features_audio']\n",
    "\n",
    "        phase1_results = {k: v for k, v in all_results.items() if k in phase1_configs}\n",
    "        phase2_results = {k: v for k, v in all_results.items() if k in phase2_configs}\n",
    "\n",
    "        return phase1_results, phase2_results\n",
    "\n",
    "    def determine_best_edge_types(self, metric='ndcg@10', significance_threshold=0.05, min_effect_size=0.2):\n",
    "        \"\"\"\n",
    "        Determine best edge types from Phase 1 results\n",
    "\n",
    "        Args:\n",
    "            metric: Performance metric to optimize ('ndcg@10', 'precision@10', etc.)\n",
    "            significance_threshold: p-value threshold for statistical significance\n",
    "            min_effect_size: Minimum Cohen's d for practical significance\n",
    "        \"\"\"\n",
    "        print(f\"ğŸ” Analyzing Phase 1 results to determine best edge types...\")\n",
    "        print(f\"   ğŸ“Š Metric: {metric}\")\n",
    "        print(f\"   ğŸ“ˆ Significance threshold: {significance_threshold}\")\n",
    "        print(f\"   ğŸ“ Minimum effect size: {min_effect_size}\")\n",
    "\n",
    "        # Extract performance scores for each configuration\n",
    "        config_scores = {}\n",
    "        config_details = {}\n",
    "\n",
    "        for config_name, results in self.phase1_results.items():\n",
    "            if 'statistics' in results and metric in results['statistics']:\n",
    "                mean_score = results['statistics'][metric]['mean']\n",
    "                config_scores[config_name] = mean_score\n",
    "                config_details[config_name] = {\n",
    "                    'edge_types': results['config']['edge_types'],\n",
    "                    'mean': mean_score,\n",
    "                    'std': results['statistics'][metric].get('std', 0),\n",
    "                    'n': results['statistics'][metric].get('n', 5)\n",
    "                }\n",
    "                print(f\"      {config_name}: {mean_score:.4f} Â± {results['statistics'][metric].get('std', 0):.4f}\")\n",
    "\n",
    "        # Find the configuration with highest performance\n",
    "        best_config_name = max(config_scores, key=config_scores.get)\n",
    "        best_edge_types = config_details[best_config_name]['edge_types']\n",
    "\n",
    "        print(f\"\\n   ğŸ† Highest performing: {best_config_name} ({config_scores[best_config_name]:.4f})\")\n",
    "        print(f\"   ğŸ”— Edge types: {best_edge_types}\")\n",
    "\n",
    "        # Validate statistical significance vs baseline\n",
    "        if 'baseline' in config_details and best_config_name != 'baseline':\n",
    "            # Simulate t-test (since we only have summary statistics)\n",
    "            baseline_mean = config_details['baseline']['mean']\n",
    "            baseline_std = config_details['baseline']['std']\n",
    "            best_mean = config_details[best_config_name]['mean']\n",
    "            best_std = config_details[best_config_name]['std']\n",
    "            n = config_details[best_config_name]['n']\n",
    "\n",
    "            # Calculate effect size (Cohen's d)\n",
    "            pooled_std = np.sqrt((baseline_std**2 + best_std**2) / 2)\n",
    "            cohens_d = (best_mean - baseline_mean) / pooled_std if pooled_std > 0 else 0\n",
    "\n",
    "            # Estimate p-value using effect size and sample size\n",
    "            se_diff = pooled_std * np.sqrt(2/n)\n",
    "            t_stat = (best_mean - baseline_mean) / se_diff if se_diff > 0 else 0\n",
    "            p_value = 2 * (1 - scipy_stats.t.cdf(abs(t_stat), df=2*n-2))\n",
    "\n",
    "            improvement_pct = ((best_mean - baseline_mean) / baseline_mean * 100) if baseline_mean > 0 else 0\n",
    "\n",
    "            print(f\"\\n   ğŸ“Š Statistical Analysis vs Baseline:\")\n",
    "            print(f\"      Improvement: {improvement_pct:+.1f}%\")\n",
    "            print(f\"      Cohen's d: {cohens_d:.3f}\")\n",
    "            print(f\"      Estimated p-value: {p_value:.4f}\")\n",
    "\n",
    "            # Check if improvement is significant and meaningful\n",
    "            if p_value < significance_threshold and cohens_d >= min_effect_size:\n",
    "                print(f\"   âœ… {best_config_name} is statistically and practically significant!\")\n",
    "                return best_edge_types, {\n",
    "                    'selected_config': best_config_name,\n",
    "                    'performance': best_mean,\n",
    "                    'improvement_vs_baseline': improvement_pct,\n",
    "                    'statistical_significance': True,\n",
    "                    'p_value': p_value,\n",
    "                    'effect_size': cohens_d\n",
    "                }\n",
    "            else:\n",
    "                print(f\"   âš ï¸  Improvement not significant enough, falling back to baseline\")\n",
    "                return config_details['baseline']['edge_types'], {\n",
    "                    'selected_config': 'baseline',\n",
    "                    'performance': baseline_mean,\n",
    "                    'fallback_reason': f\"p={p_value:.4f} > {significance_threshold} or d={cohens_d:.3f} < {min_effect_size}\"\n",
    "                }\n",
    "        else:\n",
    "            return best_edge_types, {\n",
    "                'selected_config': best_config_name,\n",
    "                'performance': config_scores[best_config_name],\n",
    "                'note': 'No baseline comparison available'\n",
    "            }\n",
    "\n",
    "    def determine_best_features(self, metric='ndcg@10', min_improvement_threshold=0.05):\n",
    "        \"\"\"\n",
    "        Determine best feature types from Phase 2 results\n",
    "\n",
    "        Args:\n",
    "            metric: Performance metric to optimize\n",
    "            min_improvement_threshold: Minimum improvement to justify using features (5% default)\n",
    "        \"\"\"\n",
    "        print(f\"\\nğŸ” Analyzing Phase 2 results to determine best features...\")\n",
    "        print(f\"   ğŸ“Š Metric: {metric}\")\n",
    "        print(f\"   ğŸ“ˆ Minimum improvement threshold: {min_improvement_threshold*100}%\")\n",
    "\n",
    "        # Extract feature performance\n",
    "        feature_scores = {}\n",
    "        feature_details = {}\n",
    "\n",
    "        for config_name, results in self.phase2_results.items():\n",
    "            if 'statistics' in results and metric in results['statistics']:\n",
    "                mean_score = results['statistics'][metric]['mean']\n",
    "                feature_scores[config_name] = mean_score\n",
    "                feature_details[config_name] = {\n",
    "                    'feature_types': results['config']['feature_types'],\n",
    "                    'mean': mean_score,\n",
    "                    'std': results['statistics'][metric].get('std', 0)\n",
    "                }\n",
    "                print(f\"      {config_name}: {mean_score:.4f} Â± {results['statistics'][metric].get('std', 0):.4f}\")\n",
    "\n",
    "        if not feature_scores:\n",
    "            print(\"   âŒ No Phase 2 results found!\")\n",
    "            return [], {'selected_config': 'no_features', 'reason': 'No Phase 2 results available'}\n",
    "\n",
    "        # Find best feature configuration\n",
    "        best_feature_config = max(feature_scores, key=feature_scores.get)\n",
    "        best_feature_types = feature_details[best_feature_config]['feature_types']\n",
    "        best_score = feature_scores[best_feature_config]\n",
    "\n",
    "        print(f\"\\n   ğŸ† Highest performing: {best_feature_config} ({best_score:.4f})\")\n",
    "        print(f\"   ğŸ¯ Feature types: {best_feature_types}\")\n",
    "\n",
    "        # Check if features provide meaningful improvement\n",
    "        # (Compare against baseline performance from Phase 1 if available)\n",
    "        baseline_performance = None\n",
    "        if self.phase1_results and 'baseline' in self.phase1_results:\n",
    "            baseline_stats = self.phase1_results['baseline'].get('statistics', {})\n",
    "            baseline_performance = baseline_stats.get(metric, {}).get('mean', 0)\n",
    "\n",
    "        if baseline_performance:\n",
    "            improvement = (best_score - baseline_performance) / baseline_performance\n",
    "            print(f\"   ğŸ“ˆ Improvement vs structure-only baseline: {improvement*100:+.1f}%\")\n",
    "\n",
    "            if improvement >= min_improvement_threshold:\n",
    "                print(f\"   âœ… Features provide meaningful improvement!\")\n",
    "                return best_feature_types, {\n",
    "                    'selected_config': best_feature_config,\n",
    "                    'performance': best_score,\n",
    "                    'improvement_vs_baseline': improvement*100,\n",
    "                    'use_features': True\n",
    "                }\n",
    "            else:\n",
    "                print(f\"   âš ï¸  Feature improvement below threshold, not using features\")\n",
    "                return [], {\n",
    "                    'selected_config': 'no_features',\n",
    "                    'reason': f'Improvement {improvement*100:.1f}% < {min_improvement_threshold*100}% threshold'\n",
    "                }\n",
    "        else:\n",
    "            # If no baseline comparison, use features if they exist\n",
    "            return best_feature_types, {\n",
    "                'selected_config': best_feature_config,\n",
    "                'performance': best_score,\n",
    "                'note': 'No baseline comparison available, using best feature config'\n",
    "            }\n",
    "\n",
    "    def generate_dynamic_phase3_config(self, metric='ndcg@10'):\n",
    "        \"\"\"Generate the optimal Phase 3 configuration based on empirical results\"\"\"\n",
    "        print(\"=\"*80)\n",
    "        print(\"ğŸ”¬ GENERATING DYNAMIC PHASE 3 CONFIGURATION\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        # Determine best edge types from Phase 1\n",
    "        best_edge_types, edge_analysis = self.determine_best_edge_types(metric=metric)\n",
    "\n",
    "        # Determine best feature types from Phase 2\n",
    "        best_feature_types, feature_analysis = self.determine_best_features(metric=metric)\n",
    "\n",
    "        # Create the dynamic configuration\n",
    "        dynamic_config = {\n",
    "            \"name\": \"Dynamic Best Combined\",\n",
    "            \"description\": f\"Empirically determined best configuration based on {metric}\",\n",
    "            \"edge_types\": best_edge_types,\n",
    "            \"use_features\": len(best_feature_types) > 0,\n",
    "            \"feature_types\": best_feature_types\n",
    "        }\n",
    "\n",
    "        # Create analysis summary\n",
    "        analysis_summary = {\n",
    "            'optimization_metric': metric,\n",
    "            'edge_selection': edge_analysis,\n",
    "            'feature_selection': feature_analysis,\n",
    "            'final_config': dynamic_config\n",
    "        }\n",
    "\n",
    "        print(f\"\\nğŸ¯ FINAL DYNAMIC CONFIGURATION:\")\n",
    "        print(f\"   ğŸ“Š Optimization metric: {metric}\")\n",
    "        print(f\"   ğŸ”— Selected edge types: {best_edge_types}\")\n",
    "        print(f\"   ğŸ¯ Selected feature types: {best_feature_types}\")\n",
    "        print(f\"   ğŸ”„ Use features: {len(best_feature_types) > 0}\")\n",
    "\n",
    "        return dynamic_config, analysis_summary\n",
    "\n",
    "# =============================================================================\n",
    "# REVISED EXPERIMENT RUNNER FOR PHASE 3 ONLY\n",
    "# =============================================================================\n",
    "\n",
    "class Phase3OnlyExperimentRunner:\n",
    "    \"\"\"Run only Phase 3 with dynamically determined configuration\"\"\"\n",
    "\n",
    "    def __init__(self, config, data, existing_results_path=None):\n",
    "        self.config = config\n",
    "        self.data = data\n",
    "        self.trainer = ImprovedExperimentTrainer(config, data)\n",
    "        self.existing_results_path = existing_results_path\n",
    "\n",
    "    def run_dynamic_phase3_experiment(self, optimization_metric='ndcg@10'):\n",
    "        \"\"\"Run Phase 3 experiment with dynamically determined configuration\"\"\"\n",
    "\n",
    "        print(\"ğŸš€ STARTING DYNAMIC PHASE 3 EXPERIMENT\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        # 1. Generate dynamic configuration based on existing results\n",
    "        if self.existing_results_path:\n",
    "            config_generator = DynamicPhase3ConfigGenerator(\n",
    "                results_file_path=self.existing_results_path\n",
    "            )\n",
    "        else:\n",
    "            print(\"âŒ Error: No existing results file provided!\")\n",
    "            return None\n",
    "\n",
    "        # 2. Determine optimal configuration\n",
    "        dynamic_config, analysis_summary = config_generator.generate_dynamic_phase3_config(\n",
    "            metric=optimization_metric\n",
    "        )\n",
    "\n",
    "        # 3. Run the experiment with the dynamic configuration\n",
    "        print(f\"\\nğŸ§ª Running experiment with dynamic configuration...\")\n",
    "\n",
    "        phase3_results = []\n",
    "\n",
    "        # Run with multiple seeds for statistical robustness\n",
    "        for seed_idx, seed in enumerate(self.config.random_seeds):\n",
    "            print(f\"\\nğŸ² Seed {seed_idx+1}/{len(self.config.random_seeds)} (seed={seed}):\")\n",
    "\n",
    "            # Train model\n",
    "            training_result = self.trainer.train_model(dynamic_config, seed=seed)\n",
    "\n",
    "            if training_result is None:\n",
    "                print(f\"   âŒ Training failed for seed {seed}\")\n",
    "                continue\n",
    "\n",
    "            # Evaluate on test set\n",
    "            test_metrics = self.trainer.evaluate_model(\n",
    "                training_result['model'],\n",
    "                training_result['adj_matrix'],\n",
    "                'test',\n",
    "                seed=seed\n",
    "            )\n",
    "\n",
    "            # Store results\n",
    "            run_result = {\n",
    "                'seed': seed,\n",
    "                'metrics': test_metrics,\n",
    "                'training_time': training_result['training_time'],\n",
    "                'final_loss': training_result['final_loss'],\n",
    "                'best_val_loss': training_result['best_val_loss']\n",
    "            }\n",
    "            phase3_results.append(run_result)\n",
    "\n",
    "            # Print immediate results\n",
    "            print(f\"      ğŸ“Š NDCG@10: {test_metrics.get('ndcg@10', 0):.4f}\")\n",
    "            print(f\"      ğŸ“Š AUC: {test_metrics.get('auc', 0):.4f}\")\n",
    "            print(f\"      â±ï¸ Time: {training_result['training_time']:.1f}s\")\n",
    "\n",
    "            # Memory cleanup\n",
    "            del training_result\n",
    "            gc.collect()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        # 4. Calculate statistics for Phase 3 results\n",
    "        if phase3_results:\n",
    "            phase3_stats = self._calculate_statistics(phase3_results)\n",
    "\n",
    "            final_results = {\n",
    "                'dynamic_best_combined': {\n",
    "                    'config': dynamic_config,\n",
    "                    'runs': phase3_results,\n",
    "                    'statistics': phase3_stats\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # 5. Print summary\n",
    "            self._print_phase3_summary(final_results, analysis_summary)\n",
    "\n",
    "            return {\n",
    "                'results': final_results,\n",
    "                'analysis_summary': analysis_summary,\n",
    "                'optimization_metric': optimization_metric\n",
    "            }\n",
    "        else:\n",
    "            print(\"âŒ No successful runs in Phase 3!\")\n",
    "            return None\n",
    "\n",
    "    def _calculate_statistics(self, phase3_results):\n",
    "        \"\"\"Calculate statistics for Phase 3 results\"\"\"\n",
    "        statistics = {}\n",
    "\n",
    "        # Get all metric names\n",
    "        all_metrics = set()\n",
    "        for run in phase3_results:\n",
    "            all_metrics.update(run['metrics'].keys())\n",
    "\n",
    "        # Calculate statistics for each metric\n",
    "        for metric in all_metrics:\n",
    "            values = [run['metrics'].get(metric, 0) for run in phase3_results]\n",
    "\n",
    "            if values and len(values) > 1:\n",
    "                mean_val = np.mean(values)\n",
    "                std_val = np.std(values, ddof=1)\n",
    "                n = len(values)\n",
    "\n",
    "                # Calculate confidence intervals\n",
    "                if n > 2:\n",
    "                    t_value = scipy_stats.t.ppf(0.975, n-1)\n",
    "                    margin_error = t_value * std_val / np.sqrt(n)\n",
    "                    ci_lower = mean_val - margin_error\n",
    "                    ci_upper = mean_val + margin_error\n",
    "                else:\n",
    "                    ci_lower = mean_val\n",
    "                    ci_upper = mean_val\n",
    "\n",
    "                statistics[metric] = {\n",
    "                    'mean': mean_val,\n",
    "                    'std': std_val,\n",
    "                    'min': np.min(values),\n",
    "                    'max': np.max(values),\n",
    "                    'ci_lower': ci_lower,\n",
    "                    'ci_upper': ci_upper,\n",
    "                    'n': n\n",
    "                }\n",
    "\n",
    "        return statistics\n",
    "\n",
    "    def _print_phase3_summary(self, results, analysis_summary):\n",
    "        \"\"\"Print comprehensive Phase 3 summary\"\"\"\n",
    "        print(f\"\\n\" + \"=\"*80)\n",
    "        print(f\"ğŸ“Š DYNAMIC PHASE 3 RESULTS SUMMARY\")\n",
    "        print(f\"=\"*80)\n",
    "\n",
    "        config_result = results['dynamic_best_combined']\n",
    "        stats = config_result['statistics']\n",
    "\n",
    "        # Print configuration details\n",
    "        print(f\"\\nğŸ¯ CONFIGURATION USED:\")\n",
    "        print(f\"   ğŸ“Š Optimization metric: {analysis_summary['optimization_metric']}\")\n",
    "        print(f\"   ğŸ”— Edge types: {config_result['config']['edge_types']}\")\n",
    "        print(f\"   ğŸ¯ Feature types: {config_result['config']['feature_types']}\")\n",
    "        print(f\"   ğŸ”„ Uses features: {config_result['config']['use_features']}\")\n",
    "\n",
    "        # Print performance results\n",
    "        ndcg_mean = stats.get('ndcg@10', {}).get('mean', 0)\n",
    "        ndcg_std = stats.get('ndcg@10', {}).get('std', 0)\n",
    "        ndcg_ci_lower = stats.get('ndcg@10', {}).get('ci_lower', 0)\n",
    "        ndcg_ci_upper = stats.get('ndcg@10', {}).get('ci_upper', 0)\n",
    "\n",
    "        print(f\"\\nğŸ“ˆ PERFORMANCE RESULTS:\")\n",
    "        print(f\"   NDCG@10: {ndcg_mean:.4f} Â± {ndcg_std:.4f}\")\n",
    "        print(f\"   95% CI: [{ndcg_ci_lower:.4f}, {ndcg_ci_upper:.4f}]\")\n",
    "\n",
    "        if 'auc' in stats:\n",
    "            auc_mean = stats['auc']['mean']\n",
    "            auc_std = stats['auc']['std']\n",
    "            print(f\"   AUC: {auc_mean:.4f} Â± {auc_std:.4f}\")\n",
    "\n",
    "        # Print selection rationale\n",
    "        print(f\"\\nğŸ” SELECTION RATIONALE:\")\n",
    "        edge_rationale = analysis_summary['edge_selection']\n",
    "        feature_rationale = analysis_summary['feature_selection']\n",
    "\n",
    "        print(f\"   ğŸ”— Edge Selection: {edge_rationale.get('selected_config', 'unknown')}\")\n",
    "        if 'improvement_vs_baseline' in edge_rationale:\n",
    "            print(f\"      Improvement vs baseline: {edge_rationale['improvement_vs_baseline']:+.1f}%\")\n",
    "\n",
    "        print(f\"   ğŸ¯ Feature Selection: {feature_rationale.get('selected_config', 'unknown')}\")\n",
    "        if 'improvement_vs_baseline' in feature_rationale:\n",
    "            print(f\"      Improvement vs baseline: {feature_rationale['improvement_vs_baseline']:+.1f}%\")\n",
    "\n",
    "# =============================================================================\n",
    "# USAGE EXAMPLE\n",
    "# =============================================================================\n",
    "\n",
    "def run_dynamic_phase3_only(existing_results_file, target_playlists=1500, optimization_metric='ndcg@10'):\n",
    "    \"\"\"\n",
    "    Run only Phase 3 with configuration determined from existing Phase 1 & 2 results\n",
    "\n",
    "    Args:\n",
    "        existing_results_file: Path to JSON file containing Phase 1 & 2 results\n",
    "        target_playlists: Number of playlists for the experiment\n",
    "        optimization_metric: Metric to optimize for ('ndcg@10', 'precision@10', etc.)\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Initialize configuration\n",
    "        config = FixedExperimentConfig()\n",
    "        config.target_playlists = target_playlists\n",
    "\n",
    "        # Generate data (same as before)\n",
    "        print(f\"ğŸµ Generating data for {target_playlists} playlists...\")\n",
    "        data_generator = ImprovedSyntheticMusicDataGenerator(config)\n",
    "        data = data_generator.generate_heterogeneous_data(seed=42)\n",
    "\n",
    "        # Initialize Phase 3 runner\n",
    "        runner = Phase3OnlyExperimentRunner(\n",
    "            config=config,\n",
    "            data=data,\n",
    "            existing_results_path=existing_results_file\n",
    "        )\n",
    "\n",
    "        # Run dynamic Phase 3 experiment\n",
    "        results = runner.run_dynamic_phase3_experiment(\n",
    "            optimization_metric=optimization_metric\n",
    "        )\n",
    "\n",
    "        if results:\n",
    "            # Save results\n",
    "            output_file = f\"dynamic_phase3_results_{optimization_metric}.json\"\n",
    "\n",
    "            # Convert results to serializable format\n",
    "            serializable_results = {\n",
    "                'dynamic_phase3': results['results'],\n",
    "                'analysis_summary': results['analysis_summary'],\n",
    "                'optimization_metric': optimization_metric\n",
    "            }\n",
    "\n",
    "            with open(output_file, 'w') as f:\n",
    "                json.dump(serializable_results, f, indent=2, default=str)\n",
    "\n",
    "            print(f\"\\nğŸ’¾ Results saved to: {output_file}\")\n",
    "            print(f\"ğŸ‰ DYNAMIC PHASE 3 EXPERIMENT COMPLETED SUCCESSFULLY!\")\n",
    "\n",
    "            return results\n",
    "        else:\n",
    "            print(f\"âŒ Dynamic Phase 3 experiment failed!\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in dynamic Phase 3 experiment: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# =============================================================================\n",
    "# EXAMPLE USAGE\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example: Run Phase 3 only using existing results\n",
    "\n",
    "    # Option 1: Use existing results file\n",
    "    results = run_dynamic_phase3_only(\n",
    "        existing_results_file=\"../results/fixed_lightgcn_experiments/improved_experiment_results.json\",\n",
    "        target_playlists=1500,\n",
    "        optimization_metric='ndcg@10'\n",
    "    )\n",
    "\n",
    "    # Option 2: If you want to try different optimization metrics\n",
    "    # results_precision = run_dynamic_phase3_only(\n",
    "    #     existing_results_file=\"../results/fixed_lightgcn_experiments/improved_experiment_results.json\",\n",
    "    #     optimization_metric='precision@10'\n",
    "    # )\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ¯ DYNAMIC PHASE 3 FRAMEWORK READY\")\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸš€ USAGE:\")\n",
    "print(\"   # Run Phase 3 only with empirically determined 'best' configuration\")\n",
    "print(\"   results = run_dynamic_phase3_only(\")\n",
    "print(\"       existing_results_file='path/to/your/phase1_phase2_results.json',\")\n",
    "print(\"       optimization_metric='ndcg@10'\")\n",
    "print(\"   )\")\n",
    "print()\n",
    "print(\"ğŸ”§ FEATURES:\")\n",
    "print(\"   âœ… Empirically determines best edge types from Phase 1 results\")\n",
    "print(\"   âœ… Empirically determines best feature types from Phase 2 results\")\n",
    "print(\"   âœ… Statistical significance testing for configuration selection\")\n",
    "print(\"   âœ… Effect size analysis for practical significance\")\n",
    "print(\"   âœ… Configurable optimization metrics\")\n",
    "print(\"   âœ… Comprehensive analysis and rationale reporting\")\n",
    "print(\"   âœ… Only runs Phase 3 - no need to repeat Phase 1 & 2\")\n",
    "print(\"=\"*80)"
   ],
   "id": "5b24ba4d89ef095b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Fixed Configuration loaded:\n",
      "   ğŸ“± Device: cpu\n",
      "   ğŸ² Seeds: 5 seeds\n",
      "   ğŸ“Š Target playlists: 1,500\n",
      "   ğŸ§  Embedding dim: 128\n",
      "   âš¡ Learning rate: 0.0005\n",
      "   ğŸ›¡ï¸ Regularization: 0.001\n",
      "ğŸµ Generating data for 1500 playlists...\n",
      "ğŸµ Improved Synthetic Data Generator:\n",
      "   ğŸ“Š Playlists: 1,500\n",
      "   ğŸµ Tracks: 4,500\n",
      "   ğŸ¤ Artists: 500\n",
      "   ğŸ’¿ Albums: 500\n",
      "   ğŸ‘¥ Users: 187\n",
      "ğŸ”§ Generating improved heterogeneous music data (seed=42)...\n",
      "   ğŸ”¢ Total nodes: 7,187\n",
      "   ğŸ”— Generating improved edge distributions...\n",
      "      âœ… playlist_track: 27,478 edges\n",
      "      âœ… track_artist: 5,171 edges\n",
      "      âœ… track_album: 4,500 edges\n",
      "      âœ… user_playlist: 981 edges\n",
      "   ğŸ“Š Generating balanced splits...\n",
      "      âœ… train: 18,579 edges\n",
      "      âœ… val: 4,024 edges\n",
      "      âœ… test: 4,875 edges\n",
      "   ğŸ¯ Generating correlated features...\n",
      "      âœ… Generated correlated features for all node types\n",
      "ğŸ¯ Improved Experiment Trainer initialized:\n",
      "   ğŸ‘¥ Playlists: 1,500\n",
      "   ğŸµ Tracks: 4,500\n",
      "   ğŸ”¢ Total nodes: 7,187\n",
      "ğŸš€ STARTING DYNAMIC PHASE 3 EXPERIMENT\n",
      "============================================================\n",
      "================================================================================\n",
      "ğŸ”¬ GENERATING DYNAMIC PHASE 3 CONFIGURATION\n",
      "================================================================================\n",
      "ğŸ” Analyzing Phase 1 results to determine best edge types...\n",
      "   ğŸ“Š Metric: ndcg@10\n",
      "   ğŸ“ˆ Significance threshold: 0.05\n",
      "   ğŸ“ Minimum effect size: 0.2\n",
      "      baseline: 0.4441 Â± 0.0082\n",
      "      with_artists: 0.4423 Â± 0.0110\n",
      "      with_users: 0.4432 Â± 0.0092\n",
      "      full_graph: 0.4377 Â± 0.0096\n",
      "\n",
      "   ğŸ† Highest performing: baseline (0.4441)\n",
      "   ğŸ”— Edge types: ['playlist_track']\n",
      "\n",
      "ğŸ” Analyzing Phase 2 results to determine best features...\n",
      "   ğŸ“Š Metric: ndcg@10\n",
      "   ğŸ“ˆ Minimum improvement threshold: 5.0%\n",
      "      features_basic: 0.4432 Â± 0.0037\n",
      "      features_audio: 0.4456 Â± 0.0042\n",
      "\n",
      "   ğŸ† Highest performing: features_audio (0.4456)\n",
      "   ğŸ¯ Feature types: ['audio']\n",
      "   ğŸ“ˆ Improvement vs structure-only baseline: +0.3%\n",
      "   âš ï¸  Feature improvement below threshold, not using features\n",
      "\n",
      "ğŸ¯ FINAL DYNAMIC CONFIGURATION:\n",
      "   ğŸ“Š Optimization metric: ndcg@10\n",
      "   ğŸ”— Selected edge types: ['playlist_track']\n",
      "   ğŸ¯ Selected feature types: []\n",
      "   ğŸ”„ Use features: False\n",
      "\n",
      "ğŸ§ª Running experiment with dynamic configuration...\n",
      "\n",
      "ğŸ² Seed 1/5 (seed=42):\n",
      "\n",
      "ğŸš€ Training: Dynamic Best Combined (seed=42)\n",
      "   ğŸ“ Empirically determined best configuration based on ndcg@10\n",
      "   ğŸ”— Building adjacency matrix: ['playlist_track']\n",
      "      ğŸ“Š Adding playlist_track: 27,478 edges\n",
      "      âœ… Total edges: 54,956\n",
      "      âœ… Adjacency matrix: torch.Size([7187, 7187]), nnz: 62143\n",
      "   ğŸ§  ImprovedLightGCN initialized:\n",
      "      ğŸ“ Total nodes: 7,187\n",
      "      ğŸ“ Embedding dim: 128\n",
      "      ğŸ”— Layers: 2\n",
      "      ğŸ‘¥ Playlist features: False\n",
      "      ğŸµ Track features: False\n",
      "      ğŸ“Š Improved training dataset: 18,579 positive pairs\n",
      "      ğŸ“Š Improved training dataset: 4,024 positive pairs\n",
      "   ğŸƒ Training with 18,579 samples, validating with 4,024...\n",
      "      Epoch 50: Train Loss = 0.3974, Val Loss = 0.4361\n",
      "      Epoch 100: Train Loss = 0.4000, Val Loss = 0.4376\n",
      "      Epoch 150: Train Loss = 0.3951, Val Loss = 0.4376\n",
      "      â° Early stopping at epoch 160\n",
      "   ğŸ“Š Evaluating on test set...\n",
      "      âœ… Evaluation completed: 500 valid playlists\n",
      "      ğŸ“Š NDCG@10: 0.4531\n",
      "      ğŸ“Š AUC: 0.8997\n",
      "      ğŸ“Š NDCG@10: 0.4531\n",
      "      ğŸ“Š AUC: 0.8997\n",
      "      â±ï¸ Time: 677.4s\n",
      "\n",
      "ğŸ² Seed 2/5 (seed=123):\n",
      "\n",
      "ğŸš€ Training: Dynamic Best Combined (seed=123)\n",
      "   ğŸ“ Empirically determined best configuration based on ndcg@10\n",
      "   ğŸ”— Building adjacency matrix: ['playlist_track']\n",
      "      ğŸ“Š Adding playlist_track: 27,478 edges\n",
      "      âœ… Total edges: 54,956\n",
      "      âœ… Adjacency matrix: torch.Size([7187, 7187]), nnz: 62143\n",
      "   ğŸ§  ImprovedLightGCN initialized:\n",
      "      ğŸ“ Total nodes: 7,187\n",
      "      ğŸ“ Embedding dim: 128\n",
      "      ğŸ”— Layers: 2\n",
      "      ğŸ‘¥ Playlist features: False\n",
      "      ğŸµ Track features: False\n",
      "      ğŸ“Š Improved training dataset: 18,579 positive pairs\n",
      "      ğŸ“Š Improved training dataset: 4,024 positive pairs\n",
      "   ğŸƒ Training with 18,579 samples, validating with 4,024...\n",
      "      Epoch 50: Train Loss = 0.3977, Val Loss = 0.4347\n",
      "      Epoch 100: Train Loss = 0.4000, Val Loss = 0.4334\n",
      "      Epoch 150: Train Loss = 0.3968, Val Loss = 0.4395\n",
      "      â° Early stopping at epoch 170\n",
      "   ğŸ“Š Evaluating on test set...\n",
      "      âœ… Evaluation completed: 500 valid playlists\n",
      "      ğŸ“Š NDCG@10: 0.4352\n",
      "      ğŸ“Š AUC: 0.8966\n",
      "      ğŸ“Š NDCG@10: 0.4352\n",
      "      ğŸ“Š AUC: 0.8966\n",
      "      â±ï¸ Time: 703.0s\n",
      "\n",
      "ğŸ² Seed 3/5 (seed=456):\n",
      "\n",
      "ğŸš€ Training: Dynamic Best Combined (seed=456)\n",
      "   ğŸ“ Empirically determined best configuration based on ndcg@10\n",
      "   ğŸ”— Building adjacency matrix: ['playlist_track']\n",
      "      ğŸ“Š Adding playlist_track: 27,478 edges\n",
      "      âœ… Total edges: 54,956\n",
      "      âœ… Adjacency matrix: torch.Size([7187, 7187]), nnz: 62143\n",
      "   ğŸ§  ImprovedLightGCN initialized:\n",
      "      ğŸ“ Total nodes: 7,187\n",
      "      ğŸ“ Embedding dim: 128\n",
      "      ğŸ”— Layers: 2\n",
      "      ğŸ‘¥ Playlist features: False\n",
      "      ğŸµ Track features: False\n",
      "      ğŸ“Š Improved training dataset: 18,579 positive pairs\n",
      "      ğŸ“Š Improved training dataset: 4,024 positive pairs\n",
      "   ğŸƒ Training with 18,579 samples, validating with 4,024...\n",
      "      Epoch 50: Train Loss = 0.3981, Val Loss = 0.4324\n",
      "      Epoch 100: Train Loss = 0.4011, Val Loss = 0.4348\n",
      "      Epoch 150: Train Loss = 0.3965, Val Loss = 0.4379\n",
      "      â° Early stopping at epoch 170\n",
      "   ğŸ“Š Evaluating on test set...\n",
      "      âœ… Evaluation completed: 500 valid playlists\n",
      "      ğŸ“Š NDCG@10: 0.4357\n",
      "      ğŸ“Š AUC: 0.9013\n",
      "      ğŸ“Š NDCG@10: 0.4357\n",
      "      ğŸ“Š AUC: 0.9013\n",
      "      â±ï¸ Time: 692.6s\n",
      "\n",
      "ğŸ² Seed 4/5 (seed=789):\n",
      "\n",
      "ğŸš€ Training: Dynamic Best Combined (seed=789)\n",
      "   ğŸ“ Empirically determined best configuration based on ndcg@10\n",
      "   ğŸ”— Building adjacency matrix: ['playlist_track']\n",
      "      ğŸ“Š Adding playlist_track: 27,478 edges\n",
      "      âœ… Total edges: 54,956\n",
      "      âœ… Adjacency matrix: torch.Size([7187, 7187]), nnz: 62143\n",
      "   ğŸ§  ImprovedLightGCN initialized:\n",
      "      ğŸ“ Total nodes: 7,187\n",
      "      ğŸ“ Embedding dim: 128\n",
      "      ğŸ”— Layers: 2\n",
      "      ğŸ‘¥ Playlist features: False\n",
      "      ğŸµ Track features: False\n",
      "      ğŸ“Š Improved training dataset: 18,579 positive pairs\n",
      "      ğŸ“Š Improved training dataset: 4,024 positive pairs\n",
      "   ğŸƒ Training with 18,579 samples, validating with 4,024...\n",
      "      Epoch 50: Train Loss = 0.3975, Val Loss = 0.4368\n",
      "      Epoch 100: Train Loss = 0.4004, Val Loss = 0.4328\n",
      "      Epoch 150: Train Loss = 0.4003, Val Loss = 0.4395\n",
      "      Epoch 200: Train Loss = 0.3995, Val Loss = 0.4389\n",
      "   ğŸ“Š Evaluating on test set...\n",
      "      âœ… Evaluation completed: 500 valid playlists\n",
      "      ğŸ“Š NDCG@10: 0.4502\n",
      "      ğŸ“Š AUC: 0.9061\n",
      "      ğŸ“Š NDCG@10: 0.4502\n",
      "      ğŸ“Š AUC: 0.9061\n",
      "      â±ï¸ Time: 813.2s\n",
      "\n",
      "ğŸ² Seed 5/5 (seed=999):\n",
      "\n",
      "ğŸš€ Training: Dynamic Best Combined (seed=999)\n",
      "   ğŸ“ Empirically determined best configuration based on ndcg@10\n",
      "   ğŸ”— Building adjacency matrix: ['playlist_track']\n",
      "      ğŸ“Š Adding playlist_track: 27,478 edges\n",
      "      âœ… Total edges: 54,956\n",
      "      âœ… Adjacency matrix: torch.Size([7187, 7187]), nnz: 62143\n",
      "   ğŸ§  ImprovedLightGCN initialized:\n",
      "      ğŸ“ Total nodes: 7,187\n",
      "      ğŸ“ Embedding dim: 128\n",
      "      ğŸ”— Layers: 2\n",
      "      ğŸ‘¥ Playlist features: False\n",
      "      ğŸµ Track features: False\n",
      "      ğŸ“Š Improved training dataset: 18,579 positive pairs\n",
      "      ğŸ“Š Improved training dataset: 4,024 positive pairs\n",
      "   ğŸƒ Training with 18,579 samples, validating with 4,024...\n",
      "      Epoch 50: Train Loss = 0.3974, Val Loss = 0.4364\n",
      "      Epoch 100: Train Loss = 0.3997, Val Loss = 0.4326\n",
      "      Epoch 150: Train Loss = 0.3980, Val Loss = 0.4416\n",
      "      â° Early stopping at epoch 170\n",
      "   ğŸ“Š Evaluating on test set...\n",
      "      âœ… Evaluation completed: 500 valid playlists\n",
      "      ğŸ“Š NDCG@10: 0.4461\n",
      "      ğŸ“Š AUC: 0.9010\n",
      "      ğŸ“Š NDCG@10: 0.4461\n",
      "      ğŸ“Š AUC: 0.9010\n",
      "      â±ï¸ Time: 679.0s\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š DYNAMIC PHASE 3 RESULTS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "ğŸ¯ CONFIGURATION USED:\n",
      "   ğŸ“Š Optimization metric: ndcg@10\n",
      "   ğŸ”— Edge types: ['playlist_track']\n",
      "   ğŸ¯ Feature types: []\n",
      "   ğŸ”„ Uses features: False\n",
      "\n",
      "ğŸ“ˆ PERFORMANCE RESULTS:\n",
      "   NDCG@10: 0.4441 Â± 0.0082\n",
      "   95% CI: [0.4338, 0.4543]\n",
      "   AUC: 0.9009 Â± 0.0034\n",
      "\n",
      "ğŸ” SELECTION RATIONALE:\n",
      "   ğŸ”— Edge Selection: baseline\n",
      "   ğŸ¯ Feature Selection: no_features\n",
      "\n",
      "ğŸ’¾ Results saved to: dynamic_phase3_results_ndcg@10.json\n",
      "ğŸ‰ DYNAMIC PHASE 3 EXPERIMENT COMPLETED SUCCESSFULLY!\n",
      "\n",
      "================================================================================\n",
      "ğŸ¯ DYNAMIC PHASE 3 FRAMEWORK READY\n",
      "================================================================================\n",
      "ğŸš€ USAGE:\n",
      "   # Run Phase 3 only with empirically determined 'best' configuration\n",
      "   results = run_dynamic_phase3_only(\n",
      "       existing_results_file='path/to/your/phase1_phase2_results.json',\n",
      "       optimization_metric='ndcg@10'\n",
      "   )\n",
      "\n",
      "ğŸ”§ FEATURES:\n",
      "   âœ… Empirically determines best edge types from Phase 1 results\n",
      "   âœ… Empirically determines best feature types from Phase 2 results\n",
      "   âœ… Statistical significance testing for configuration selection\n",
      "   âœ… Effect size analysis for practical significance\n",
      "   âœ… Configurable optimization metrics\n",
      "   âœ… Comprehensive analysis and rationale reporting\n",
      "   âœ… Only runs Phase 3 - no need to repeat Phase 1 & 2\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
