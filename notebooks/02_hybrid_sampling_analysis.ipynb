{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hybird Core-based + Stratified Sampling",
   "id": "784adb025faa243f"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-23T14:17:13.308394Z",
     "start_time": "2025-06-23T14:17:13.304617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "from typing import Dict, List, Tuple, Set, Iterator\n",
    "import gc\n",
    "import psutil\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T14:17:26.305944Z",
     "start_time": "2025-06-23T14:17:26.300810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"🎵 HYBRID CORE-BASED + STRATIFIED SAMPLING\")\n",
    "print(\"=\" * 70)\n",
    "print(\"💾 Memory-efficient streaming approach for large datasets\")\n",
    "print(\"🎯 Combines: Core filtering + Stratified sampling + Priority scoring\")\n",
    "print()"
   ],
   "id": "31b06b8340da4572",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎵 HYBRID CORE-BASED + STRATIFIED SAMPLING\n",
      "======================================================================\n",
      "💾 Memory-efficient streaming approach for large datasets\n",
      "🎯 Combines: Core filtering + Stratified sampling + Priority scoring\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Memory Monitoring Utilities",
   "id": "32ade12d48317531"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T14:18:26.778805Z",
     "start_time": "2025-06-23T14:18:26.773245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_memory_usage():\n",
    "    \"\"\"Get current memory usage in MB\"\"\"\n",
    "    try:\n",
    "        process = psutil.Process(os.getpid())\n",
    "        return process.memory_info().rss / 1024 / 1024  # MB\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def print_memory_status(stage: str):\n",
    "    \"\"\"Print current memory usage\"\"\"\n",
    "    memory_mb = get_memory_usage()\n",
    "    print(f\"💾 Memory usage after {stage}: {memory_mb:.1f} MB\")\n",
    "\n",
    "print(\"✅ Memory monitoring utilities loaded\")"
   ],
   "id": "918c792c48ade06c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Memory monitoring utilities loaded\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Streaming Sampler Class",
   "id": "64cd9936bbee5e60"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T16:00:13.587017Z",
     "start_time": "2025-06-23T16:00:13.423407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class HybridStreamingSampler:\n",
    "    \"\"\"\n",
    "    Hybrid Core-Based + Stratified Streaming Sampler\n",
    "    - Pass 1: Core-based filtering (length, user activity, track frequency)\n",
    "    - Pass 2: Stratified sampling with priority scoring\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 target_playlists: int = 50000,\n",
    "                 batch_size: int = 20,\n",
    "                 min_playlist_length: int = 10,\n",
    "                 max_playlist_length: int = 100,\n",
    "                 min_track_frequency: int = 5,\n",
    "                 min_user_playlists: int = 3):\n",
    "\n",
    "        self.target_playlists = target_playlists\n",
    "        self.batch_size = batch_size\n",
    "        self.min_playlist_length = min_playlist_length\n",
    "        self.max_playlist_length = max_playlist_length\n",
    "        self.min_track_frequency = min_track_frequency\n",
    "        self.min_user_playlists = min_user_playlists\n",
    "\n",
    "        # Statistics collectors\n",
    "        self.track_counts = Counter()\n",
    "        self.user_counts = Counter()\n",
    "        self.playlist_stats = []\n",
    "\n",
    "        print(f\"🎯 Hybrid Streaming Sampler Configuration:\")\n",
    "        print(f\"   • Target playlists: {target_playlists:,}\")\n",
    "        print(f\"   • Batch size: {batch_size} files at a time\")\n",
    "        print(f\"   • Playlist length: {min_playlist_length}-{max_playlist_length} tracks\")\n",
    "        print(f\"   • Min track frequency: {min_track_frequency} playlists\")\n",
    "        print(f\"   • Min user playlists: {min_user_playlists} playlists\")\n",
    "        print()\n",
    "\n",
    "    def get_file_batches(self, file_pattern: str) -> List[List[str]]:\n",
    "        \"\"\"Split files into manageable batches\"\"\"\n",
    "        file_paths = glob.glob(file_pattern)\n",
    "        file_paths.sort()\n",
    "\n",
    "        if not file_paths:\n",
    "            raise FileNotFoundError(f\"No files found: {file_pattern}\")\n",
    "\n",
    "        print(f\"📁 Found {len(file_paths)} files\")\n",
    "\n",
    "        # Split into batches\n",
    "        batches = []\n",
    "        for i in range(0, len(file_paths), self.batch_size):\n",
    "            batch = file_paths[i:i + self.batch_size]\n",
    "            batches.append(batch)\n",
    "\n",
    "        print(f\"📦 Created {len(batches)} batches of ~{self.batch_size} files each\")\n",
    "        return batches\n",
    "\n",
    "    def _extract_user_id(self, playlist: Dict) -> str:\n",
    "        \"\"\"Extract user identifier from playlist\"\"\"\n",
    "        # Method 1: Use name-based grouping\n",
    "        name = playlist.get('name', '').lower().strip()\n",
    "        if name:\n",
    "            # Use first word of playlist name as user identifier\n",
    "            words = name.split()\n",
    "            if words:\n",
    "                user_id = words[0]\n",
    "                # Clean user_id (keep only alphanumeric)\n",
    "                user_id = ''.join(c for c in user_id if c.isalnum())[:20]\n",
    "                return user_id if user_id else 'anonymous'\n",
    "\n",
    "        # Method 2: Use PID-based grouping (if no name)\n",
    "        pid = playlist.get('pid', 0)\n",
    "        return f\"user_{pid % 10000}\"  # Group into ~10k users\n",
    "\n",
    "    def pass1_core_filtering(self, file_pattern: str) -> Dict:\n",
    "        \"\"\"\n",
    "        PASS 1: Core-based filtering + Statistics collection\n",
    "        \"\"\"\n",
    "        print(\"🔍 PASS 1: HYBRID CORE-BASED FILTERING\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        batches = self.get_file_batches(file_pattern)\n",
    "\n",
    "        # Stage counts\n",
    "        stage_counts = {\n",
    "            'total_seen': 0,\n",
    "            'passed_length_filter': 0,\n",
    "            'passed_user_filter': 0,\n",
    "            'passed_track_frequency_filter': 0,\n",
    "            'final_valid': 0\n",
    "        }\n",
    "\n",
    "        print(\"🚀 Applying Core-Based Filters:\")\n",
    "        print(f\"   ✅ Step 1: Playlist length ({self.min_playlist_length}-{self.max_playlist_length} tracks)\")\n",
    "        print(f\"   ✅ Step 2: User activity (≥{self.min_user_playlists} playlists per user)\")\n",
    "        print(f\"   ✅ Step 3: Track frequency (≥{self.min_track_frequency} appearances)\")\n",
    "        print()\n",
    "\n",
    "        # Sub-pass 1a: Collect user activity statistics\n",
    "        print(\"📊 Sub-pass 1a: Collecting user activity statistics...\")\n",
    "        user_playlist_count = Counter()\n",
    "\n",
    "        for batch_idx, file_batch in enumerate(batches):\n",
    "            if batch_idx % 20 == 0:\n",
    "                print(f\"   User stats progress: {batch_idx + 1}/{len(batches)} batches\")\n",
    "\n",
    "            for file_path in file_batch:\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        data = json.load(f)\n",
    "\n",
    "                    file_playlists = data.get('playlists', [])\n",
    "\n",
    "                    for playlist in file_playlists:\n",
    "                        user_id = self._extract_user_id(playlist)\n",
    "                        user_playlist_count[user_id] += 1\n",
    "\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "\n",
    "        # Identify active users\n",
    "        active_users = {\n",
    "            user for user, count in user_playlist_count.items()\n",
    "            if count >= self.min_user_playlists\n",
    "        }\n",
    "\n",
    "        print(f\"   ✅ Identified {len(active_users):,} active users\")\n",
    "        print()\n",
    "\n",
    "        # Sub-pass 1b: Apply all core filters\n",
    "        print(\"🔍 Sub-pass 1b: Applying all core filters...\")\n",
    "\n",
    "        for batch_idx, file_batch in enumerate(batches):\n",
    "            print(f\"📦 Processing batch {batch_idx + 1}/{len(batches)}\")\n",
    "\n",
    "            batch_playlists = []\n",
    "\n",
    "            # Load batch\n",
    "            for file_path in file_batch:\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        data = json.load(f)\n",
    "\n",
    "                    file_playlists = data.get('playlists', [])\n",
    "\n",
    "                    # Add source file info\n",
    "                    for playlist in file_playlists:\n",
    "                        playlist['_source_file'] = file_path\n",
    "\n",
    "                    batch_playlists.extend(file_playlists)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"   ⚠️  Error loading {os.path.basename(file_path)}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            # Process batch with core filtering\n",
    "            for playlist_idx, playlist in enumerate(batch_playlists):\n",
    "                stage_counts['total_seen'] += 1\n",
    "\n",
    "                # CORE FILTER 1: Playlist length\n",
    "                tracks = playlist.get('tracks', [])\n",
    "                playlist_length = len(tracks)\n",
    "\n",
    "                if not (self.min_playlist_length <= playlist_length <= self.max_playlist_length):\n",
    "                    continue\n",
    "                stage_counts['passed_length_filter'] += 1\n",
    "\n",
    "                # CORE FILTER 2: User activity\n",
    "                user_id = self._extract_user_id(playlist)\n",
    "                if user_id not in active_users:\n",
    "                    continue\n",
    "                stage_counts['passed_user_filter'] += 1\n",
    "\n",
    "                # Count tracks for frequency analysis\n",
    "                playlist_tracks = set()\n",
    "                for track in tracks:\n",
    "                    track_uri = track.get('track_uri', '')\n",
    "                    if track_uri:\n",
    "                        self.track_counts[track_uri] += 1\n",
    "                        playlist_tracks.add(track_uri)\n",
    "\n",
    "                self.user_counts[user_id] += 1\n",
    "\n",
    "                # Store playlist metadata\n",
    "                playlist_metadata = {\n",
    "                    'file_path': playlist['_source_file'],\n",
    "                    'pid': playlist.get('pid'),\n",
    "                    'length': playlist_length,\n",
    "                    'modified_at': playlist.get('modified_at', 0),\n",
    "                    'user_id': user_id,\n",
    "                    'track_uris': list(playlist_tracks),\n",
    "                    'name': playlist.get('name', ''),\n",
    "                    'collaborative': playlist.get('collaborative', False),\n",
    "                    'num_followers': playlist.get('num_followers', 0)\n",
    "                }\n",
    "\n",
    "                self.playlist_stats.append(playlist_metadata)\n",
    "\n",
    "            # Clear batch from memory\n",
    "            del batch_playlists\n",
    "            gc.collect()\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"   Progress: {stage_counts['total_seen']:,} seen, {len(self.playlist_stats):,} valid so far\")\n",
    "                print_memory_status(f\"batch {batch_idx + 1}\")\n",
    "\n",
    "        # CORE FILTER 3: Track frequency\n",
    "        print(f\"\\n🔍 Applying final core filter: Track frequency\")\n",
    "\n",
    "        core_tracks = {\n",
    "            track for track, count in self.track_counts.items()\n",
    "            if count >= self.min_track_frequency\n",
    "        }\n",
    "\n",
    "        print(f\"   ✅ Identified {len(core_tracks):,} core tracks\")\n",
    "\n",
    "        # Filter playlists that have core tracks\n",
    "        filtered_playlist_stats = []\n",
    "        for playlist_meta in self.playlist_stats:\n",
    "            playlist_tracks = set(playlist_meta['track_uris'])\n",
    "            if playlist_tracks.intersection(core_tracks):\n",
    "                filtered_playlist_stats.append(playlist_meta)\n",
    "                stage_counts['passed_track_frequency_filter'] += 1\n",
    "\n",
    "        self.playlist_stats = filtered_playlist_stats\n",
    "        stage_counts['final_valid'] = len(filtered_playlist_stats)\n",
    "\n",
    "        print(f\"\\n✅ CORE-BASED FILTERING COMPLETE:\")\n",
    "        print(f\"   📊 Filtering Funnel:\")\n",
    "        print(f\"      • Total playlists: {stage_counts['total_seen']:,}\")\n",
    "        print(f\"      • Length filter: {stage_counts['passed_length_filter']:,} ({stage_counts['passed_length_filter']/stage_counts['total_seen']*100:.1f}%)\")\n",
    "        print(f\"      • User filter: {stage_counts['passed_user_filter']:,} ({stage_counts['passed_user_filter']/stage_counts['total_seen']*100:.1f}%)\")\n",
    "        print(f\"      • Track frequency: {stage_counts['passed_track_frequency_filter']:,} ({stage_counts['passed_track_frequency_filter']/stage_counts['total_seen']*100:.1f}%)\")\n",
    "        print(f\"      • 🎯 FINAL VALID: {stage_counts['final_valid']:,} ({stage_counts['final_valid']/stage_counts['total_seen']*100:.1f}%)\")\n",
    "        print()\n",
    "\n",
    "        return {\n",
    "            'total_playlists': stage_counts['total_seen'],\n",
    "            'valid_playlists': stage_counts['final_valid'],\n",
    "            'core_tracks': core_tracks,\n",
    "            'active_users': active_users,\n",
    "            'unique_tracks': len(self.track_counts),\n",
    "            'stage_counts': stage_counts\n",
    "        }\n",
    "\n",
    "    def create_strata(self) -> Dict[str, List[int]]:\n",
    "        \"\"\"Create comprehensive strata for stratified sampling\"\"\"\n",
    "        print(\"📊 CREATING STRATIFIED SAMPLING STRATA\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        # Get temporal split\n",
    "        timestamps = [p['modified_at'] for p in self.playlist_stats if p['modified_at'] > 0]\n",
    "        if timestamps:\n",
    "            median_time = np.median(timestamps)\n",
    "        else:\n",
    "            median_time = 1500000000  # Default\n",
    "\n",
    "        # Get user activity split\n",
    "        user_playlist_counts = {}\n",
    "        for playlist_meta in self.playlist_stats:\n",
    "            user_id = playlist_meta['user_id']\n",
    "            user_playlist_counts[user_id] = user_playlist_counts.get(user_id, 0) + 1\n",
    "\n",
    "        user_activity_median = np.median(list(user_playlist_counts.values())) if user_playlist_counts else 5\n",
    "\n",
    "        print(f\"   📅 Temporal split at timestamp: {median_time}\")\n",
    "        print(f\"   👥 User activity split at: {user_activity_median} playlists per user\")\n",
    "\n",
    "        # Create 12 comprehensive strata\n",
    "        strata = {\n",
    "            'short_old_casual': [], 'short_old_active': [],\n",
    "            'short_recent_casual': [], 'short_recent_active': [],\n",
    "            'medium_old_casual': [], 'medium_old_active': [],\n",
    "            'medium_recent_casual': [], 'medium_recent_active': [],\n",
    "            'long_old_casual': [], 'long_old_active': [],\n",
    "            'long_recent_casual': [], 'long_recent_active': []\n",
    "        }\n",
    "\n",
    "        for i, playlist_meta in enumerate(self.playlist_stats):\n",
    "            length = playlist_meta['length']\n",
    "            timestamp = playlist_meta['modified_at']\n",
    "            user_id = playlist_meta['user_id']\n",
    "            user_activity = user_playlist_counts.get(user_id, 1)\n",
    "\n",
    "            # Length category\n",
    "            if length <= 30:\n",
    "                length_cat = 'short'\n",
    "            elif length <= 60:\n",
    "                length_cat = 'medium'\n",
    "            else:\n",
    "                length_cat = 'long'\n",
    "\n",
    "            # Time category\n",
    "            time_cat = 'recent' if timestamp >= median_time else 'old'\n",
    "\n",
    "            # User activity category\n",
    "            activity_cat = 'active' if user_activity >= user_activity_median else 'casual'\n",
    "\n",
    "            # Combine into stratum\n",
    "            stratum_key = f\"{length_cat}_{time_cat}_{activity_cat}\"\n",
    "            strata[stratum_key].append(i)\n",
    "\n",
    "        # Print strata distribution\n",
    "        print(\"   📋 Strata Distribution:\")\n",
    "        total_playlists = len(self.playlist_stats)\n",
    "\n",
    "        for stratum, indices in strata.items():\n",
    "            if indices:  # Only show non-empty strata\n",
    "                percentage = len(indices) / total_playlists * 100\n",
    "                print(f\"      • {stratum:20s}: {len(indices):6,} ({percentage:4.1f}%)\")\n",
    "\n",
    "        print()\n",
    "        return strata\n",
    "\n",
    "    def _calculate_priority_score(self, playlist_meta: Dict) -> float:\n",
    "        \"\"\"Calculate priority score for playlist selection\"\"\"\n",
    "        score = 0.0\n",
    "\n",
    "        # Factor 1: Track diversity (30% weight)\n",
    "        unique_tracks = len(playlist_meta['track_uris'])\n",
    "        playlist_length = playlist_meta['length']\n",
    "        if playlist_length > 0:\n",
    "            track_diversity_ratio = unique_tracks / playlist_length\n",
    "            score += track_diversity_ratio * 3.0\n",
    "\n",
    "        # Factor 2: User engagement (25% weight)\n",
    "        num_followers = playlist_meta.get('num_followers', 0)\n",
    "        if num_followers > 0:\n",
    "            follower_score = min(np.log10(num_followers + 1), 3.0)\n",
    "            score += follower_score * 2.5\n",
    "\n",
    "        # Factor 3: Playlist completeness (20% weight)\n",
    "        name = playlist_meta.get('name', '')\n",
    "        has_good_name = len(name.strip()) > 3 and not name.lower().startswith('my playlist')\n",
    "        if has_good_name:\n",
    "            score += 2.0\n",
    "\n",
    "        # Factor 4: Collaborative playlists bonus (10% weight)\n",
    "        if playlist_meta.get('collaborative', False):\n",
    "            score += 1.0\n",
    "\n",
    "        # Factor 5: Length balance bonus (15% weight)\n",
    "        length = playlist_meta['length']\n",
    "        if 20 <= length <= 80:  # Sweet spot\n",
    "            score += 1.5\n",
    "\n",
    "        return score\n",
    "\n",
    "    def pass2_stratified_sampling(self, strata: Dict[str, List[int]]) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        PASS 2: Stratified sampling with priority scoring\n",
    "        \"\"\"\n",
    "        print(\"🎲 PASS 2: STRATIFIED SAMPLING WITH PRIORITY SCORING\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        total_available = len(self.playlist_stats)\n",
    "\n",
    "        if total_available <= self.target_playlists:\n",
    "            print(f\"   📝 Available ({total_available:,}) ≤ target ({self.target_playlists:,})\")\n",
    "            selected_indices = list(range(total_available))\n",
    "        else:\n",
    "            sampling_ratio = self.target_playlists / total_available\n",
    "            selected_indices = set()\n",
    "\n",
    "            print(f\"   📊 Global sampling ratio: {sampling_ratio:.3f}\")\n",
    "            print(f\"   🏆 Using priority scoring within strata\")\n",
    "            print()\n",
    "\n",
    "            for stratum, indices in strata.items():\n",
    "                if not indices:\n",
    "                    continue\n",
    "\n",
    "                stratum_target = max(1, int(len(indices) * sampling_ratio))\n",
    "                stratum_target = min(stratum_target, len(indices))\n",
    "\n",
    "                # Score playlists in this stratum\n",
    "                scored_playlists = []\n",
    "                for idx in indices:\n",
    "                    playlist_meta = self.playlist_stats[idx]\n",
    "                    score = self._calculate_priority_score(playlist_meta)\n",
    "                    scored_playlists.append((idx, score))\n",
    "\n",
    "                # Sort by score and sample\n",
    "                scored_playlists.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "                # Hybrid: 70% top-scored + 30% random\n",
    "                top_count = int(stratum_target * 0.7)\n",
    "                random_count = stratum_target - top_count\n",
    "\n",
    "                selected = [idx for idx, _ in scored_playlists[:top_count]]\n",
    "\n",
    "                if random_count > 0 and len(scored_playlists) > top_count:\n",
    "                    remaining = [idx for idx, _ in scored_playlists[top_count:]]\n",
    "                    if len(remaining) >= random_count:\n",
    "                        selected.extend(random.sample(remaining, random_count))\n",
    "                    else:\n",
    "                        selected.extend(remaining)\n",
    "\n",
    "                selected_indices.update(selected)\n",
    "\n",
    "                avg_score = np.mean([score for _, score in scored_playlists[:len(selected)]])\n",
    "                print(f\"      • {stratum:20s}: {len(selected):4,} / {len(indices):5,} (avg score: {avg_score:.2f})\")\n",
    "\n",
    "            selected_indices = list(selected_indices)\n",
    "\n",
    "        print(f\"\\n   🎯 Selected {len(selected_indices):,} playlists for final loading\")\n",
    "\n",
    "        # Load selected playlists\n",
    "        return self._load_selected_playlists(selected_indices)\n",
    "\n",
    "    def _load_selected_playlists(self, selected_indices: List[int]) -> List[Dict]:\n",
    "        \"\"\"Load only the selected playlists from files\"\"\"\n",
    "        print(\"   📁 Loading selected playlists...\")\n",
    "\n",
    "        # Group by file\n",
    "        file_to_playlists = defaultdict(list)\n",
    "        for idx in selected_indices:\n",
    "            playlist_meta = self.playlist_stats[idx]\n",
    "            file_path = playlist_meta['file_path']\n",
    "            file_to_playlists[file_path].append(playlist_meta)\n",
    "\n",
    "        print(f\"   📂 Loading from {len(file_to_playlists)} files\")\n",
    "\n",
    "        # Load playlists\n",
    "        final_playlists = []\n",
    "\n",
    "        for file_idx, (file_path, playlist_metas) in enumerate(file_to_playlists.items()):\n",
    "            if file_idx % 100 == 0:\n",
    "                print(f\"      📖 File {file_idx + 1}/{len(file_to_playlists)}\")\n",
    "\n",
    "            try:\n",
    "                with open(file_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                file_playlists = data.get('playlists', [])\n",
    "                pid_to_playlist = {p.get('pid'): p for p in file_playlists}\n",
    "\n",
    "                for meta in playlist_metas:\n",
    "                    pid = meta['pid']\n",
    "                    if pid in pid_to_playlist:\n",
    "                        playlist = pid_to_playlist[pid]\n",
    "                        playlist['_sampling_score'] = self._calculate_priority_score(meta)\n",
    "                        final_playlists.append(playlist)\n",
    "\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "        print(f\"   ✅ Loaded {len(final_playlists):,} final playlists\")\n",
    "        return final_playlists\n",
    "\n",
    "    def run_hybrid_sampling(self, file_pattern: str) -> Tuple[List[Dict], Dict]:\n",
    "        \"\"\"Main method: Complete hybrid sampling workflow\"\"\"\n",
    "        print(\"🚀 STARTING HYBRID CORE-BASED + STRATIFIED SAMPLING\")\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "        print_memory_status(\"start\")\n",
    "\n",
    "        # Pass 1: Core-based filtering\n",
    "        stats = self.pass1_core_filtering(file_pattern)\n",
    "        print_memory_status(\"pass 1 complete\")\n",
    "\n",
    "        # Create strata\n",
    "        strata = self.create_strata()\n",
    "        print_memory_status(\"strata created\")\n",
    "\n",
    "        # Pass 2: Stratified sampling\n",
    "        final_playlists = self.pass2_stratified_sampling(strata)\n",
    "        print_memory_status(\"pass 2 complete\")\n",
    "\n",
    "        # Final statistics\n",
    "        final_stats = {\n",
    "            'methodology': 'hybrid_core_based_stratified_streaming',\n",
    "            'original_total': stats['total_playlists'],\n",
    "            'final_sampled': len(final_playlists),\n",
    "            'retention_rate': len(final_playlists) / stats['total_playlists'],\n",
    "            'core_filtering_retention': stats['valid_playlists'] / stats['total_playlists'],\n",
    "            'unique_tracks': stats['unique_tracks'],\n",
    "            'core_tracks_count': len(stats['core_tracks']),\n",
    "            'active_users_count': len(stats['active_users']),\n",
    "            'stage_counts': stats['stage_counts']\n",
    "        }\n",
    "\n",
    "        print(\"\\n🎉 HYBRID SAMPLING COMPLETE!\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"📊 Results: {stats['total_playlists']:,} → {len(final_playlists):,} playlists\")\n",
    "        print(f\"📈 Overall retention: {len(final_playlists) / stats['total_playlists']:.1%}\")\n",
    "\n",
    "        return final_playlists, final_stats\n",
    "\n",
    "print(\"✅ HybridStreamingSampler class loaded\")"
   ],
   "id": "dc9f72ea9b2f9e4d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ HybridStreamingSampler class loaded\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Convenience Functions",
   "id": "d202d04239df59ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T16:01:14.580803Z",
     "start_time": "2025-06-23T16:01:14.555725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_hybrid_sampling(file_pattern: str,\n",
    "                       target_size: int = 50000,\n",
    "                       batch_size: int = 20):\n",
    "    \"\"\"\n",
    "    One-function call to run complete hybrid sampling\n",
    "\n",
    "    Args:\n",
    "        file_pattern: e.g., \"../data/raw/data/mpd.slice.*.json\"\n",
    "        target_size: Target number of playlists\n",
    "        batch_size: Files to process at once (adjust for RAM)\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize sampler\n",
    "    sampler = HybridStreamingSampler(\n",
    "        target_playlists=target_size,\n",
    "        batch_size=batch_size,\n",
    "        min_playlist_length=10,\n",
    "        max_playlist_length=100,\n",
    "        min_track_frequency=5,\n",
    "        min_user_playlists=3\n",
    "    )\n",
    "\n",
    "    # Run sampling\n",
    "    sampled_playlists, stats = sampler.run_hybrid_sampling(file_pattern)\n",
    "\n",
    "    # Save results\n",
    "    output_data = {\n",
    "        'info': {\n",
    "            'generated_on': datetime.now().isoformat(),\n",
    "            'sampling_method': 'hybrid_core_based_stratified_streaming',\n",
    "            'parameters': {\n",
    "                'target_playlists': target_size,\n",
    "                'batch_size': batch_size,\n",
    "                'min_playlist_length': 10,\n",
    "                'max_playlist_length': 100,\n",
    "                'min_track_frequency': 5,\n",
    "                'min_user_playlists': 3\n",
    "            }\n",
    "        },\n",
    "        'sampling_stats': stats,\n",
    "        'playlists': sampled_playlists\n",
    "    }\n",
    "\n",
    "    # Save\n",
    "    os.makedirs('../data/processed', exist_ok=True)\n",
    "    output_file = f'../data/processed/spotify_hybrid_sampled_{target_size}.json'\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(output_data, f, indent=2)\n",
    "\n",
    "    file_size_mb = os.path.getsize(output_file) / (1024 * 1024)\n",
    "    print(f\"\\n💾 Saved to: {output_file}\")\n",
    "    print(f\"📦 File size: {file_size_mb:.1f} MB\")\n",
    "\n",
    "    return sampled_playlists, stats, output_file\n",
    "\n",
    "print(\"✅ Convenience functions loaded\")"
   ],
   "id": "4153506b203e51d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Convenience functions loaded\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T16:23:52.030620Z",
     "start_time": "2025-06-23T16:01:17.976023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configure for your system\n",
    "file_pattern = \"../data/raw/data/mpd.slice.*.json\"  # Your file path\n",
    "target_size = 50000    # Target playlists\n",
    "batch_size = 20        # Adjust based on your RAM:\n",
    "                       # 20 for 8GB+ RAM\n",
    "                       # 10 for 4GB RAM\n",
    "                       # 5 for 2GB RAM\n",
    "\n",
    "# Run hybrid sampling\n",
    "sampled_playlists, stats, output_file = run_hybrid_sampling(\n",
    "    file_pattern=file_pattern,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size\n",
    ")"
   ],
   "id": "5d778bce1a7e4e33",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Hybrid Streaming Sampler Configuration:\n",
      "   • Target playlists: 50,000\n",
      "   • Batch size: 20 files at a time\n",
      "   • Playlist length: 10-100 tracks\n",
      "   • Min track frequency: 5 playlists\n",
      "   • Min user playlists: 3 playlists\n",
      "\n",
      "🚀 STARTING HYBRID CORE-BASED + STRATIFIED SAMPLING\n",
      "======================================================================\n",
      "💾 Memory usage after start: 39.9 MB\n",
      "🔍 PASS 1: HYBRID CORE-BASED FILTERING\n",
      "============================================================\n",
      "📁 Found 1000 files\n",
      "📦 Created 50 batches of ~20 files each\n",
      "🚀 Applying Core-Based Filters:\n",
      "   ✅ Step 1: Playlist length (10-100 tracks)\n",
      "   ✅ Step 2: User activity (≥3 playlists per user)\n",
      "   ✅ Step 3: Track frequency (≥5 appearances)\n",
      "\n",
      "📊 Sub-pass 1a: Collecting user activity statistics...\n",
      "   User stats progress: 1/50 batches\n",
      "   User stats progress: 21/50 batches\n",
      "   User stats progress: 41/50 batches\n",
      "   ✅ Identified 8,526 active users\n",
      "\n",
      "🔍 Sub-pass 1b: Applying all core filters...\n",
      "📦 Processing batch 1/50\n",
      "   Progress: 20,000 seen, 14,818 valid so far\n",
      "💾 Memory usage after batch 1: 4096.2 MB\n",
      "📦 Processing batch 2/50\n",
      "📦 Processing batch 3/50\n",
      "📦 Processing batch 4/50\n",
      "📦 Processing batch 5/50\n",
      "📦 Processing batch 6/50\n",
      "📦 Processing batch 7/50\n",
      "📦 Processing batch 8/50\n",
      "📦 Processing batch 9/50\n",
      "📦 Processing batch 10/50\n",
      "📦 Processing batch 11/50\n",
      "   Progress: 220,000 seen, 163,985 valid so far\n",
      "💾 Memory usage after batch 11: 4779.6 MB\n",
      "📦 Processing batch 12/50\n",
      "📦 Processing batch 13/50\n",
      "📦 Processing batch 14/50\n",
      "📦 Processing batch 15/50\n",
      "📦 Processing batch 16/50\n",
      "📦 Processing batch 17/50\n",
      "📦 Processing batch 18/50\n",
      "📦 Processing batch 19/50\n",
      "📦 Processing batch 20/50\n",
      "📦 Processing batch 21/50\n",
      "   Progress: 420,000 seen, 313,338 valid so far\n",
      "💾 Memory usage after batch 21: 5123.4 MB\n",
      "📦 Processing batch 22/50\n",
      "📦 Processing batch 23/50\n",
      "📦 Processing batch 24/50\n",
      "📦 Processing batch 25/50\n",
      "📦 Processing batch 26/50\n",
      "📦 Processing batch 27/50\n",
      "📦 Processing batch 28/50\n",
      "📦 Processing batch 29/50\n",
      "📦 Processing batch 30/50\n",
      "📦 Processing batch 31/50\n",
      "   Progress: 620,000 seen, 462,956 valid so far\n",
      "💾 Memory usage after batch 31: 5598.7 MB\n",
      "📦 Processing batch 32/50\n",
      "📦 Processing batch 33/50\n",
      "📦 Processing batch 34/50\n",
      "📦 Processing batch 35/50\n",
      "📦 Processing batch 36/50\n",
      "📦 Processing batch 37/50\n",
      "📦 Processing batch 38/50\n",
      "📦 Processing batch 39/50\n",
      "📦 Processing batch 40/50\n",
      "📦 Processing batch 41/50\n",
      "   Progress: 820,000 seen, 611,692 valid so far\n",
      "💾 Memory usage after batch 41: 6003.3 MB\n",
      "📦 Processing batch 42/50\n",
      "📦 Processing batch 43/50\n",
      "📦 Processing batch 44/50\n",
      "📦 Processing batch 45/50\n",
      "📦 Processing batch 46/50\n",
      "📦 Processing batch 47/50\n",
      "📦 Processing batch 48/50\n",
      "📦 Processing batch 49/50\n",
      "📦 Processing batch 50/50\n",
      "\n",
      "🔍 Applying final core filter: Track frequency\n",
      "   ✅ Identified 374,533 core tracks\n",
      "\n",
      "✅ CORE-BASED FILTERING COMPLETE:\n",
      "   📊 Filtering Funnel:\n",
      "      • Total playlists: 1,000,000\n",
      "      • Length filter: 747,510 (74.8%)\n",
      "      • User filter: 746,005 (74.6%)\n",
      "      • Track frequency: 745,332 (74.5%)\n",
      "      • 🎯 FINAL VALID: 745,332 (74.5%)\n",
      "\n",
      "💾 Memory usage after pass 1 complete: 4643.7 MB\n",
      "📊 CREATING STRATIFIED SAMPLING STRATA\n",
      "==================================================\n",
      "   📅 Temporal split at timestamp: 1487980800.0\n",
      "   👥 User activity split at: 17.0 playlists per user\n",
      "   📋 Strata Distribution:\n",
      "      • short_old_casual    :  7,956 ( 1.1%)\n",
      "      • short_old_active    : 146,944 (19.7%)\n",
      "      • short_recent_casual :  5,408 ( 0.7%)\n",
      "      • short_recent_active : 111,591 (15.0%)\n",
      "      • medium_old_casual   :  6,033 ( 0.8%)\n",
      "      • medium_old_active   : 129,209 (17.3%)\n",
      "      • medium_recent_casual:  5,683 ( 0.8%)\n",
      "      • medium_recent_active: 137,781 (18.5%)\n",
      "      • long_old_casual     :  3,609 ( 0.5%)\n",
      "      • long_old_active     : 78,844 (10.6%)\n",
      "      • long_recent_casual  :  4,165 ( 0.6%)\n",
      "      • long_recent_active  : 108,109 (14.5%)\n",
      "\n",
      "💾 Memory usage after strata created: 4420.6 MB\n",
      "🎲 PASS 2: STRATIFIED SAMPLING WITH PRIORITY SCORING\n",
      "============================================================\n",
      "   📊 Global sampling ratio: 0.067\n",
      "   🏆 Using priority scoring within strata\n",
      "\n",
      "      • short_old_casual    :  533 / 7,956 (avg score: 9.06)\n",
      "      • short_old_active    : 9,857 / 146,944 (avg score: 8.98)\n",
      "      • short_recent_casual :  362 / 5,408 (avg score: 9.01)\n",
      "      • short_recent_active : 7,485 / 111,591 (avg score: 8.98)\n",
      "      • medium_old_casual   :  404 / 6,033 (avg score: 9.51)\n",
      "      • medium_old_active   : 8,667 / 129,209 (avg score: 9.31)\n",
      "      • medium_recent_casual:  381 / 5,683 (avg score: 9.42)\n",
      "      • medium_recent_active: 9,242 / 137,781 (avg score: 9.31)\n",
      "      • long_old_casual     :  242 / 3,609 (avg score: 9.53)\n",
      "      • long_old_active     : 5,289 / 78,844 (avg score: 9.23)\n",
      "      • long_recent_casual  :  279 / 4,165 (avg score: 9.43)\n",
      "      • long_recent_active  : 7,252 / 108,109 (avg score: 9.24)\n",
      "\n",
      "   🎯 Selected 49,993 playlists for final loading\n",
      "   📁 Loading selected playlists...\n",
      "   📂 Loading from 1000 files\n",
      "      📖 File 1/1000\n",
      "      📖 File 101/1000\n",
      "      📖 File 201/1000\n",
      "      📖 File 301/1000\n",
      "      📖 File 401/1000\n",
      "      📖 File 501/1000\n",
      "      📖 File 601/1000\n",
      "      📖 File 701/1000\n",
      "      📖 File 801/1000\n",
      "      📖 File 901/1000\n",
      "   ✅ Loaded 49,993 final playlists\n",
      "💾 Memory usage after pass 2 complete: 1282.1 MB\n",
      "\n",
      "🎉 HYBRID SAMPLING COMPLETE!\n",
      "======================================================================\n",
      "📊 Results: 1,000,000 → 49,993 playlists\n",
      "📈 Overall retention: 5.0%\n",
      "\n",
      "💾 Saved to: ../data/processed/spotify_hybrid_sampled_50000.json\n",
      "📦 File size: 852.3 MB\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
